{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-insurance-linear.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac14761c82c64bd48bcd052559ed226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03b920ba696443e2b126a920fa25b3cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3a38ea7427449bb804c2469fe875d10",
              "IPY_MODEL_0af69900457a4e43b5b73794eb9a8b7b"
            ]
          }
        },
        "03b920ba696443e2b126a920fa25b3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3a38ea7427449bb804c2469fe875d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_104b953fe2d9450297c575b094f54ae5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e32b17def6c4580ae4fb51003e63cf5"
          }
        },
        "0af69900457a4e43b5b73794eb9a8b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52c59c6abf2b4fe3b5b5b34251a081b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 57344/? [00:20&lt;00:00, 135127.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f8e245a8b1b4eb2b5041d0d01ac8758"
          }
        },
        "104b953fe2d9450297c575b094f54ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e32b17def6c4580ae4fb51003e63cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52c59c6abf2b4fe3b5b5b34251a081b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f8e245a8b1b4eb2b5041d0d01ac8758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulgarg95/pytorch_jovian/blob/main/02_insurance_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AhehUfgsFBo",
        "outputId": "14d32705-7528-492a-8284-f8cea6342438"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1MY0TfaPQTk7nykEmcytWFgCiA1DtiF43')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 20kB 27.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 51kB 15.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 61kB 14.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 5.4MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "pFRCfbyv1iQ_"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "Make a submisson here: https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-2-train-your-first-model\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from [Kaggle](https://www.kaggle.com/mirichoi0218/insurance).\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lessons. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ai/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ai/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ai/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq4FotBb1iRB"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy matplotlib pandas torch torchvision torchaudio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1i8VLaO1iRC"
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn6TLTq11iRD"
      },
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDOu6P2n1iRD"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ac14761c82c64bd48bcd052559ed226d",
            "03b920ba696443e2b126a920fa25b3cd",
            "f3a38ea7427449bb804c2469fe875d10",
            "0af69900457a4e43b5b73794eb9a8b7b",
            "104b953fe2d9450297c575b094f54ae5",
            "3e32b17def6c4580ae4fb51003e63cf5",
            "52c59c6abf2b4fe3b5b5b34251a081b0",
            "5f8e245a8b1b4eb2b5041d0d01ac8758"
          ]
        },
        "id": "nsZl8sNg1iRE",
        "outputId": "00fe3d51-2451-448c-fbfd-ae6039fb6e1f"
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac14761c82c64bd48bcd052559ed226d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mKAn0OH1iRH"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Ws9ysMEp1iRH",
        "outputId": "82ca8dde-c270-4e21-d363-b32f5d57f4e1"
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lp2nU0g1iRI"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocp_PvaW1iRJ"
      },
      "source": [
        "your_name = 'Rahul' # at least 5 characters"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xntDnhEO1iRK"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JITd3QUQ1iRK"
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "wH_EkqDg1iRL",
        "outputId": "ff2fc6a5-df4b-4888-e444-a2f21bc70a39"
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>29.58015</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>12314.406052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>44</td>\n",
              "      <td>female</td>\n",
              "      <td>35.84635</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>8344.060868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>58</td>\n",
              "      <td>female</td>\n",
              "      <td>30.87025</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>14151.663500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>23.95900</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>1806.871040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288</th>\n",
              "      <td>20</td>\n",
              "      <td>male</td>\n",
              "      <td>38.21800</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>39878.348640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex       bmi  children smoker       charges\n",
              "457    57  female  29.58015         0     no  12314.406052\n",
              "1050   44  female  35.84635         1     no   8344.060868\n",
              "56     58  female  30.87025         2     no  14151.663500\n",
              "311    19  female  23.95900         0     no   1806.871040\n",
              "1288   20    male  38.21800         2    yes  39878.348640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2uiMoQN1iRL"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywJ18ofl1iRM",
        "outputId": "dd66a8ef-5edb-4380-a8d2-31332864ae39"
      },
      "source": [
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxWFaLD1iRM"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpoeom3p1iRN",
        "outputId": "40fcb00b-b82d-4652-ed74-3cbd0a8ee3d9"
      },
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD8Sw4mD1iRN"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAon-czO1iRO"
      },
      "source": [
        "input_cols = dataframe.columns.to_list()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEL2HgBa3HaY"
      },
      "source": [
        "input_cols.remove('charges')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58xvrFW0_qzb",
        "outputId": "96fc00c5-f1f4-4cb4-fecc-59e7578149cf"
      },
      "source": [
        "input_cols"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'children', 'smoker']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm86ILCG5KWJ",
        "outputId": "21d2750c-795e-463a-8ddc-26bb0c56f4f6"
      },
      "source": [
        "dataframe.dtypes"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age           int64\n",
              "sex          object\n",
              "bmi         float64\n",
              "children      int64\n",
              "smoker       object\n",
              "charges     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhwishwd1iRO"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEfPw9bx1iRP"
      },
      "source": [
        "categorical_cols = ['smoker','sex']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_kQeoQV1iRP"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7DOOuz1iRQ"
      },
      "source": [
        "output_cols = ['charges']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXsWrZ6I1iRQ"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "AI0Wwl_p1iRR",
        "outputId": "88445733-3c8f-45ff-bfa8-ab101e8f54a9"
      },
      "source": [
        "# Write your answer here\r\n",
        "print('Min Charges: ',dataframe['charges'].min())\r\n",
        "print('Max Charges: ',dataframe['charges'].max())\r\n",
        "print('Mean Charges: ',dataframe['charges'].mean())\r\n",
        "dataframe.boxplot('charges')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min Charges:  1166.7488560000002\n",
            "Max Charges:  66321.2451304\n",
            "Mean Charges:  13645.824006566623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c27e8b940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYFbjU4i1iRR"
      },
      "source": [
        "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwkyWcYr1iRS"
      },
      "source": [
        "!pip install jovian --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gB2ToIz1iRS"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "v2bLy-091iRT",
        "outputId": "fceb7c69-b59d-494b-e893-c8c187bdc211"
      },
      "source": [
        "jovian.commit(project=project_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/rahulgarg95/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/rahulgarg95/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42pbUZ7s1iRU"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5oYv4vh1iRU"
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjW1BgUB1iRW"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfjipVae1iRW",
        "outputId": "9b6aa880-99c9-4cb5-8a99-5ab5c335255f"
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "print(inputs_array.shape,targets_array.shape)\n",
        "inputs_array, targets_array"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1271, 5) (1271, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[57.     ,  0.     , 29.58015,  0.     ,  0.     ],\n",
              "        [44.     ,  0.     , 35.84635,  1.     ,  0.     ],\n",
              "        [58.     ,  0.     , 30.87025,  2.     ,  0.     ],\n",
              "        ...,\n",
              "        [59.     ,  0.     , 33.756  ,  2.     ,  0.     ],\n",
              "        [41.     ,  1.     , 27.936  ,  1.     ,  0.     ],\n",
              "        [36.     ,  0.     , 29.1194 ,  0.     ,  0.     ]]),\n",
              " array([[12314.406052 ],\n",
              "        [ 8344.060868 ],\n",
              "        [14151.6635   ],\n",
              "        ...,\n",
              "        [38387.0323512],\n",
              "        [ 6533.5244   ],\n",
              "        [ 5483.062832 ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFcIZUPz1iRX"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u074Zt9c1iRX"
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array.astype('float32'))\n",
        "targets = torch.from_numpy(targets_array.astype('float32'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Ly4l5V1iRY",
        "outputId": "0f3ef01c-6c67-4f1e-d2b0-a8777037809c"
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc4l1mtN1iRY"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTePygaE1iRZ"
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO18Ql7K-CDo",
        "outputId": "a54390d8-13a2-4e51-cdf6-0cc88e95ccbd"
      },
      "source": [
        "dataset[:]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[57.0000,  0.0000, 29.5802,  0.0000,  0.0000],\n",
              "         [44.0000,  0.0000, 35.8464,  1.0000,  0.0000],\n",
              "         [58.0000,  0.0000, 30.8703,  2.0000,  0.0000],\n",
              "         ...,\n",
              "         [59.0000,  0.0000, 33.7560,  2.0000,  0.0000],\n",
              "         [41.0000,  1.0000, 27.9360,  1.0000,  0.0000],\n",
              "         [36.0000,  0.0000, 29.1194,  0.0000,  0.0000]]), tensor([[12314.4062],\n",
              "         [ 8344.0605],\n",
              "         [14151.6631],\n",
              "         ...,\n",
              "         [38387.0312],\n",
              "         [ 6533.5244],\n",
              "         [ 5483.0630]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgd0MTfjtx5q",
        "outputId": "ca47e6c3-7059-43e6-8dcf-30823ce9ab15"
      },
      "source": [
        "dataset[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([44.0000,  0.0000, 35.8464,  1.0000,  0.0000]), tensor([8344.0605]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ0WHPjutnbw",
        "outputId": "65a353cb-285b-4bda-be28-561286ef4954"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([57.0000,  0.0000, 29.5802,  0.0000,  0.0000]), tensor([12314.4062]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XLGj3Qo1iRZ"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB5XGcVB1iRZ",
        "outputId": "5c87db5c-a1da-4ca6-8dae-2529eda19f2c"
      },
      "source": [
        "val_percent = 0.12 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "print(train_size,val_size)\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1119 152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXOJ7y1D1iRa"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szg0-lQm1iRa"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPKQKvs1iRb"
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO5J9CcP1iRc"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBwYyLI1iRc",
        "outputId": "c9859df6-bd89-482d-eb06-59b0e8b4405e"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[50.0000,  0.0000, 27.3152,  3.0000,  0.0000],\n",
            "        [62.0000,  0.0000, 30.7781,  0.0000,  0.0000],\n",
            "        [46.0000,  0.0000, 34.4641,  0.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 22.3003,  0.0000,  0.0000],\n",
            "        [39.0000,  1.0000, 34.2410,  2.0000,  1.0000],\n",
            "        [61.0000,  1.0000, 34.7842,  0.0000,  1.0000],\n",
            "        [41.0000,  0.0000, 30.6859,  1.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 27.4607,  0.0000,  1.0000],\n",
            "        [26.0000,  1.0000, 31.5153,  1.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 26.1900,  2.0000,  0.0000],\n",
            "        [50.0000,  0.0000, 26.2628,  1.0000,  0.0000],\n",
            "        [51.0000,  1.0000, 22.5137,  1.0000,  1.0000],\n",
            "        [58.0000,  0.0000, 31.4231,  1.0000,  0.0000],\n",
            "        [63.0000,  0.0000, 35.2110,  0.0000,  0.0000],\n",
            "        [56.0000,  0.0000, 31.3310,  3.0000,  0.0000],\n",
            "        [60.0000,  1.0000, 32.1167,  3.0000,  0.0000],\n",
            "        [36.0000,  0.0000, 21.9220,  2.0000,  1.0000],\n",
            "        [31.0000,  0.0000, 25.8214,  0.0000,  0.0000],\n",
            "        [46.0000,  0.0000, 19.3515,  2.0000,  0.0000],\n",
            "        [36.0000,  1.0000, 28.0136,  3.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 23.4061,  1.0000,  0.0000],\n",
            "        [22.0000,  1.0000, 33.7560,  3.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 23.2606,  3.0000,  1.0000],\n",
            "        [24.0000,  0.0000, 26.8884,  0.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 30.1961,  2.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 22.4846,  0.0000,  0.0000],\n",
            "        [56.0000,  1.0000, 38.4120,  0.0000,  0.0000],\n",
            "        [41.0000,  0.0000, 31.2340,  1.0000,  0.0000],\n",
            "        [22.0000,  1.0000, 38.3150,  0.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 28.1979,  0.0000,  1.0000],\n",
            "        [46.0000,  1.0000, 24.9727,  3.0000,  0.0000],\n",
            "        [32.0000,  1.0000, 34.1440,  2.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 35.7542,  0.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 28.0330,  3.0000,  0.0000],\n",
            "        [33.0000,  0.0000, 17.9450,  1.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 35.3856,  0.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 28.9157,  2.0000,  0.0000],\n",
            "        [21.0000,  0.0000, 16.3106,  1.0000,  0.0000],\n",
            "        [57.0000,  0.0000, 30.8703,  0.0000,  0.0000],\n",
            "        [39.0000,  1.0000, 21.1945,  1.0000,  0.0000],\n",
            "        [59.0000,  1.0000, 35.9870,  1.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 22.2082,  2.0000,  1.0000],\n",
            "        [40.0000,  1.0000, 28.4743,  1.0000,  0.0000],\n",
            "        [26.0000,  1.0000, 30.1331,  0.0000,  0.0000],\n",
            "        [53.0000,  1.0000, 20.2730,  0.0000,  1.0000],\n",
            "        [41.0000,  1.0000, 23.2218,  1.0000,  0.0000],\n",
            "        [53.0000,  0.0000, 36.9182,  3.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 28.0330,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 32.6211,  1.0000,  0.0000],\n",
            "        [58.0000,  1.0000, 24.4198,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 38.9795,  0.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 29.5802,  2.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 31.3310,  1.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 28.1300,  0.0000,  0.0000],\n",
            "        [23.0000,  1.0000, 23.1297,  0.0000,  0.0000],\n",
            "        [39.0000,  0.0000, 23.1539,  5.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 17.2660,  0.0000,  0.0000],\n",
            "        [62.0000,  1.0000, 36.2780,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 39.7166,  0.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 20.6416,  3.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 35.6620,  0.0000,  0.0000],\n",
            "        [61.0000,  0.0000, 42.6800,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 33.9112,  3.0000,  0.0000],\n",
            "        [20.0000,  0.0000, 23.6874,  0.0000,  1.0000],\n",
            "        [32.0000,  0.0000, 28.8430,  0.0000,  0.0000],\n",
            "        [60.0000,  1.0000, 28.0330,  0.0000,  0.0000],\n",
            "        [37.0000,  0.0000, 46.1720,  2.0000,  1.0000],\n",
            "        [22.0000,  0.0000, 19.6280,  0.0000,  0.0000],\n",
            "        [43.0000,  1.0000, 36.9182,  2.0000,  1.0000],\n",
            "        [25.0000,  0.0000, 20.1760,  1.0000,  0.0000],\n",
            "        [55.0000,  0.0000, 29.5850,  0.0000,  0.0000],\n",
            "        [52.0000,  1.0000, 37.4420,  2.0000,  0.0000],\n",
            "        [58.0000,  1.0000, 47.5882,  0.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 22.2082,  0.0000,  1.0000],\n",
            "        [37.0000,  0.0000, 33.0818,  1.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 38.5187,  4.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 31.8160,  1.0000,  0.0000],\n",
            "        [36.0000,  0.0000, 25.0648,  0.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 31.4231,  1.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 35.9870,  1.0000,  0.0000],\n",
            "        [29.0000,  0.0000, 25.2491,  0.0000,  0.0000],\n",
            "        [24.0000,  1.0000, 30.1331,  0.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 34.1440,  1.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 19.2060,  0.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 22.5137,  0.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 33.1837,  0.0000,  0.0000],\n",
            "        [40.0000,  1.0000, 29.9487,  4.0000,  0.0000],\n",
            "        [33.0000,  1.0000, 22.0238,  0.0000,  0.0000],\n",
            "        [21.0000,  1.0000, 24.9727,  2.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 32.3301,  0.0000,  0.0000],\n",
            "        [27.0000,  1.0000, 22.4070,  0.0000,  0.0000],\n",
            "        [26.0000,  1.0000, 22.9890,  2.0000,  0.0000],\n",
            "        [57.0000,  0.0000, 33.2662,  2.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 25.3412,  0.0000,  0.0000],\n",
            "        [60.0000,  1.0000, 38.7030,  0.0000,  1.0000],\n",
            "        [59.0000,  0.0000, 22.9454,  0.0000,  1.0000],\n",
            "        [25.0000,  0.0000, 29.2940,  0.0000,  1.0000],\n",
            "        [54.0000,  0.0000, 45.2990,  2.0000,  0.0000],\n",
            "        [52.0000,  1.0000, 25.6080,  3.0000,  0.0000],\n",
            "        [50.0000,  0.0000, 29.2115,  1.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 23.8668,  3.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 33.3680,  3.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 27.1018,  1.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 27.0000,  0.0000,  0.0000],\n",
            "        [24.0000,  1.0000, 27.6450,  0.0000,  1.0000],\n",
            "        [34.0000,  1.0000, 40.8661,  2.0000,  0.0000],\n",
            "        [30.0000,  0.0000, 29.9730,  3.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 32.0100,  1.0000,  0.0000],\n",
            "        [55.0000,  0.0000, 25.9960,  1.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 24.6477,  1.0000,  1.0000],\n",
            "        [46.0000,  1.0000, 38.2422,  1.0000,  0.0000],\n",
            "        [52.0000,  0.0000, 45.3475,  5.0000,  0.0000],\n",
            "        [57.0000,  0.0000, 27.9214,  4.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 27.5480,  1.0000,  0.0000],\n",
            "        [49.0000,  1.0000, 25.0648,  2.0000,  1.0000],\n",
            "        [19.0000,  0.0000, 38.4266,  1.0000,  0.0000],\n",
            "        [58.0000,  1.0000, 34.9976,  0.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 22.0869,  0.0000,  0.0000],\n",
            "        [40.0000,  1.0000, 29.0030,  2.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 42.0398,  2.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 34.9976,  1.0000,  1.0000],\n",
            "        [50.0000,  0.0000, 26.7720,  1.0000,  1.0000],\n",
            "        [59.0000,  0.0000, 26.8884,  3.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 36.3071,  0.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 16.9556,  0.0000,  0.0000],\n",
            "        [39.0000,  1.0000, 23.7747,  2.0000,  0.0000],\n",
            "        [63.0000,  0.0000, 30.8460,  0.0000,  0.0000],\n",
            "        [28.0000,  1.0000, 36.9182,  0.0000,  0.0000]])\n",
            "targets: tensor([[11130.7480],\n",
            "        [14605.2158],\n",
            "        [43796.1328],\n",
            "        [ 1772.7509],\n",
            "        [41708.0469],\n",
            "        [48463.0742],\n",
            "        [ 7652.5024],\n",
            "        [18755.3262],\n",
            "        [ 3630.1711],\n",
            "        [12207.3633],\n",
            "        [10510.3799],\n",
            "        [23106.8398],\n",
            "        [13539.9277],\n",
            "        [14442.6924],\n",
            "        [13967.4756],\n",
            "        [14476.6162],\n",
            "        [19352.5918],\n",
            "        [ 3908.1587],\n",
            "        [ 9561.5918],\n",
            "        [ 7018.5347],\n",
            "        [ 5330.2241],\n",
            "        [ 3580.7866],\n",
            "        [18369.6699],\n",
            "        [ 2563.2036],\n",
            "        [ 2669.1296],\n",
            "        [ 2841.1887],\n",
            "        [11025.4688],\n",
            "        [ 7046.9995],\n",
            "        [ 1749.9009],\n",
            "        [18046.7871],\n",
            "        [ 9673.9697],\n",
            "        [ 4857.4658],\n",
            "        [ 1994.0111],\n",
            "        [ 6163.9199],\n",
            "        [ 4956.6631],\n",
            "        [12725.2725],\n",
            "        [ 8547.9717],\n",
            "        [ 3294.1541],\n",
            "        [12316.3291],\n",
            "        [ 6362.1943],\n",
            "        [12841.0586],\n",
            "        [21942.4961],\n",
            "        [ 6649.3477],\n",
            "        [ 2807.5510],\n",
            "        [22043.6504],\n",
            "        [ 7132.8188],\n",
            "        [21281.5176],\n",
            "        [ 1812.9425],\n",
            "        [12422.9385],\n",
            "        [12408.3701],\n",
            "        [ 2306.1680],\n",
            "        [ 8750.0020],\n",
            "        [ 8385.2744],\n",
            "        [12316.1396],\n",
            "        [ 2490.9785],\n",
            "        [ 8925.5947],\n",
            "        [ 1796.8964],\n",
            "        [13498.5322],\n",
            "        [12028.9521],\n",
            "        [ 4468.1221],\n",
            "        [14541.1240],\n",
            "        [13586.4385],\n",
            "        [ 4645.2861],\n",
            "        [27170.7012],\n",
            "        [ 4531.3252],\n",
            "        [12632.8496],\n",
            "        [47958.0508],\n",
            "        [ 2628.9314],\n",
            "        [44262.8477],\n",
            "        [ 3337.1384],\n",
            "        [11132.6484],\n",
            "        [10738.2139],\n",
            "        [11836.5781],\n",
            "        [16784.3125],\n",
            "        [ 6356.8472],\n",
            "        [20276.5879],\n",
            "        [14932.6992],\n",
            "        [ 5477.0200],\n",
            "        [19659.6309],\n",
            "        [ 3408.2476],\n",
            "        [ 3885.9233],\n",
            "        [35624.2148],\n",
            "        [ 1796.6416],\n",
            "        [ 1291.2275],\n",
            "        [ 1575.9587],\n",
            "        [ 4092.5872],\n",
            "        [ 8489.2246],\n",
            "        [22863.8496],\n",
            "        [ 3411.0632],\n",
            "        [ 1181.3783],\n",
            "        [ 2583.0854],\n",
            "        [ 3623.7043],\n",
            "        [13753.0195],\n",
            "        [ 5437.1084],\n",
            "        [50100.2969],\n",
            "        [26705.9297],\n",
            "        [35256.6797],\n",
            "        [11999.9580],\n",
            "        [27032.5332],\n",
            "        [10306.7744],\n",
            "        [12978.8975],\n",
            "        [ 8862.8828],\n",
            "        [12016.3926],\n",
            "        [ 1701.1630],\n",
            "        [36553.4297],\n",
            "        [ 5329.1562],\n",
            "        [ 5538.6772],\n",
            "        [ 2059.2727],\n",
            "        [36566.5391],\n",
            "        [22857.8242],\n",
            "        [ 8676.6250],\n",
            "        [13096.2363],\n",
            "        [14970.1738],\n",
            "        [ 2424.7798],\n",
            "        [24759.5293],\n",
            "        [ 2839.3123],\n",
            "        [11817.8145],\n",
            "        [12307.1338],\n",
            "        [ 6864.3755],\n",
            "        [ 6080.7944],\n",
            "        [43899.5820],\n",
            "        [25501.0742],\n",
            "        [14561.1787],\n",
            "        [ 2223.5935],\n",
            "        [ 1686.1938],\n",
            "        [ 6978.5996],\n",
            "        [14436.1865],\n",
            "        [ 2797.0752]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqFxvMZB1iRc"
      },
      "source": [
        "Let's save our work by committing to Jovian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "2vMkot0x1iRd",
        "outputId": "b36f4e6c-4843-4dfa-fcaa-8a023b8d60aa"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/rahulgarg95/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/rahulgarg95/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRKrTWln1iRd"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TLwJbqj1iRe"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltTwwnHTCu7K",
        "outputId": "a6d91ff9-8c19-46c6-e24a-95e817ce386e"
      },
      "source": [
        "print(input_size,output_size)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3RtYDhU1iRe"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUmPFarg1iRe"
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size,output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.l1_loss(out,targets)                          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out,targets)                           # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgFfksKq1iRf"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxV5sVsB1iRg"
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT9JNOfP1iRh"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2zUbjCF1iRh",
        "outputId": "3019cc1b-ab94-481a-dcba-9d3259df746e"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2803,  0.0168, -0.0196,  0.3051, -0.2850]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1238], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LPBCsqb1iRh"
      },
      "source": [
        "One final commit before we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Wi6zJNbO1iRi",
        "outputId": "c42270b7-2bb8-4b8d-c25a-a7f1218d3205"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/rahulgarg95/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/rahulgarg95/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oui9hRjx1iRi"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxGFcQPp1iRj"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iikhoTsw1iRj"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62f3ogze1iRk",
        "outputId": "33c68a24-b9cf-4101-f325-7264792337be"
      },
      "source": [
        "result = evaluate(model,val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 13582.3525390625}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiZlqr6EE1ug"
      },
      "source": [
        "#model = InsuranceModel()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8fG73HT1iRk"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxyjN5O41iRk"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMTqBddA1iRl",
        "outputId": "ccdb92c6-9747-4913-d69b-520e7355f600"
      },
      "source": [
        "epochs = 10000\n",
        "lr = 1e-1\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 7241.5835\n",
            "Epoch [40], val_loss: 7011.8936\n",
            "Epoch [60], val_loss: 6841.7349\n",
            "Epoch [80], val_loss: 6741.4316\n",
            "Epoch [100], val_loss: 6697.5366\n",
            "Epoch [120], val_loss: 6679.2715\n",
            "Epoch [140], val_loss: 6673.2173\n",
            "Epoch [160], val_loss: 6668.1572\n",
            "Epoch [180], val_loss: 6665.0630\n",
            "Epoch [200], val_loss: 6663.3784\n",
            "Epoch [220], val_loss: 6660.8857\n",
            "Epoch [240], val_loss: 6655.8359\n",
            "Epoch [260], val_loss: 6653.2427\n",
            "Epoch [280], val_loss: 6653.8818\n",
            "Epoch [300], val_loss: 6649.1440\n",
            "Epoch [320], val_loss: 6647.1606\n",
            "Epoch [340], val_loss: 6647.2363\n",
            "Epoch [360], val_loss: 6643.1147\n",
            "Epoch [380], val_loss: 6641.7676\n",
            "Epoch [400], val_loss: 6640.1528\n",
            "Epoch [420], val_loss: 6638.6611\n",
            "Epoch [440], val_loss: 6636.8237\n",
            "Epoch [460], val_loss: 6635.3652\n",
            "Epoch [480], val_loss: 6632.6680\n",
            "Epoch [500], val_loss: 6631.6826\n",
            "Epoch [520], val_loss: 6629.7197\n",
            "Epoch [540], val_loss: 6627.9678\n",
            "Epoch [560], val_loss: 6627.1650\n",
            "Epoch [580], val_loss: 6625.0269\n",
            "Epoch [600], val_loss: 6622.6074\n",
            "Epoch [620], val_loss: 6621.3594\n",
            "Epoch [640], val_loss: 6619.9365\n",
            "Epoch [660], val_loss: 6618.5571\n",
            "Epoch [680], val_loss: 6616.9727\n",
            "Epoch [700], val_loss: 6614.4033\n",
            "Epoch [720], val_loss: 6614.1611\n",
            "Epoch [740], val_loss: 6613.0020\n",
            "Epoch [760], val_loss: 6610.1123\n",
            "Epoch [780], val_loss: 6608.0820\n",
            "Epoch [800], val_loss: 6606.9902\n",
            "Epoch [820], val_loss: 6605.1660\n",
            "Epoch [840], val_loss: 6603.7012\n",
            "Epoch [860], val_loss: 6601.7017\n",
            "Epoch [880], val_loss: 6600.9736\n",
            "Epoch [900], val_loss: 6598.9668\n",
            "Epoch [920], val_loss: 6597.4531\n",
            "Epoch [940], val_loss: 6595.1631\n",
            "Epoch [960], val_loss: 6594.4917\n",
            "Epoch [980], val_loss: 6592.6797\n",
            "Epoch [1000], val_loss: 6589.4600\n",
            "Epoch [1020], val_loss: 6588.4946\n",
            "Epoch [1040], val_loss: 6587.0762\n",
            "Epoch [1060], val_loss: 6585.6221\n",
            "Epoch [1080], val_loss: 6583.9238\n",
            "Epoch [1100], val_loss: 6581.6172\n",
            "Epoch [1120], val_loss: 6580.4170\n",
            "Epoch [1140], val_loss: 6579.4355\n",
            "Epoch [1160], val_loss: 6577.8262\n",
            "Epoch [1180], val_loss: 6576.0127\n",
            "Epoch [1200], val_loss: 6574.8027\n",
            "Epoch [1220], val_loss: 6573.6704\n",
            "Epoch [1240], val_loss: 6573.5635\n",
            "Epoch [1260], val_loss: 6571.0605\n",
            "Epoch [1280], val_loss: 6569.5811\n",
            "Epoch [1300], val_loss: 6568.7119\n",
            "Epoch [1320], val_loss: 6567.1768\n",
            "Epoch [1340], val_loss: 6565.7939\n",
            "Epoch [1360], val_loss: 6564.6157\n",
            "Epoch [1380], val_loss: 6563.9531\n",
            "Epoch [1400], val_loss: 6562.2061\n",
            "Epoch [1420], val_loss: 6561.1289\n",
            "Epoch [1440], val_loss: 6559.9932\n",
            "Epoch [1460], val_loss: 6558.6113\n",
            "Epoch [1480], val_loss: 6557.5762\n",
            "Epoch [1500], val_loss: 6556.1904\n",
            "Epoch [1520], val_loss: 6554.5322\n",
            "Epoch [1540], val_loss: 6553.3394\n",
            "Epoch [1560], val_loss: 6552.2715\n",
            "Epoch [1580], val_loss: 6550.8848\n",
            "Epoch [1600], val_loss: 6549.4722\n",
            "Epoch [1620], val_loss: 6548.3452\n",
            "Epoch [1640], val_loss: 6547.5264\n",
            "Epoch [1660], val_loss: 6545.4482\n",
            "Epoch [1680], val_loss: 6544.3633\n",
            "Epoch [1700], val_loss: 6543.7183\n",
            "Epoch [1720], val_loss: 6542.3545\n",
            "Epoch [1740], val_loss: 6541.5625\n",
            "Epoch [1760], val_loss: 6539.6606\n",
            "Epoch [1780], val_loss: 6538.9668\n",
            "Epoch [1800], val_loss: 6536.5698\n",
            "Epoch [1820], val_loss: 6536.5947\n",
            "Epoch [1840], val_loss: 6534.6318\n",
            "Epoch [1860], val_loss: 6533.1006\n",
            "Epoch [1880], val_loss: 6532.4575\n",
            "Epoch [1900], val_loss: 6531.0132\n",
            "Epoch [1920], val_loss: 6530.3105\n",
            "Epoch [1940], val_loss: 6529.7510\n",
            "Epoch [1960], val_loss: 6527.4282\n",
            "Epoch [1980], val_loss: 6527.1895\n",
            "Epoch [2000], val_loss: 6525.7236\n",
            "Epoch [2020], val_loss: 6523.9951\n",
            "Epoch [2040], val_loss: 6523.5957\n",
            "Epoch [2060], val_loss: 6521.3076\n",
            "Epoch [2080], val_loss: 6520.0889\n",
            "Epoch [2100], val_loss: 6518.9219\n",
            "Epoch [2120], val_loss: 6518.4023\n",
            "Epoch [2140], val_loss: 6516.1699\n",
            "Epoch [2160], val_loss: 6516.9131\n",
            "Epoch [2180], val_loss: 6516.4258\n",
            "Epoch [2200], val_loss: 6513.8389\n",
            "Epoch [2220], val_loss: 6512.3848\n",
            "Epoch [2240], val_loss: 6512.1094\n",
            "Epoch [2260], val_loss: 6509.8184\n",
            "Epoch [2280], val_loss: 6509.9580\n",
            "Epoch [2300], val_loss: 6508.8228\n",
            "Epoch [2320], val_loss: 6507.4307\n",
            "Epoch [2340], val_loss: 6506.7373\n",
            "Epoch [2360], val_loss: 6506.4453\n",
            "Epoch [2380], val_loss: 6504.3740\n",
            "Epoch [2400], val_loss: 6504.2192\n",
            "Epoch [2420], val_loss: 6502.4688\n",
            "Epoch [2440], val_loss: 6502.2739\n",
            "Epoch [2460], val_loss: 6500.9155\n",
            "Epoch [2480], val_loss: 6500.3154\n",
            "Epoch [2500], val_loss: 6499.1348\n",
            "Epoch [2520], val_loss: 6496.8896\n",
            "Epoch [2540], val_loss: 6497.1880\n",
            "Epoch [2560], val_loss: 6495.4795\n",
            "Epoch [2580], val_loss: 6494.9282\n",
            "Epoch [2600], val_loss: 6493.4126\n",
            "Epoch [2620], val_loss: 6492.9307\n",
            "Epoch [2640], val_loss: 6490.1455\n",
            "Epoch [2660], val_loss: 6490.0908\n",
            "Epoch [2680], val_loss: 6489.9282\n",
            "Epoch [2700], val_loss: 6489.1104\n",
            "Epoch [2720], val_loss: 6487.2920\n",
            "Epoch [2740], val_loss: 6486.6313\n",
            "Epoch [2760], val_loss: 6486.3062\n",
            "Epoch [2780], val_loss: 6483.3750\n",
            "Epoch [2800], val_loss: 6482.6582\n",
            "Epoch [2820], val_loss: 6483.6895\n",
            "Epoch [2840], val_loss: 6481.9028\n",
            "Epoch [2860], val_loss: 6480.2197\n",
            "Epoch [2880], val_loss: 6479.4844\n",
            "Epoch [2900], val_loss: 6478.3760\n",
            "Epoch [2920], val_loss: 6476.3130\n",
            "Epoch [2940], val_loss: 6475.3506\n",
            "Epoch [2960], val_loss: 6474.8203\n",
            "Epoch [2980], val_loss: 6474.7246\n",
            "Epoch [3000], val_loss: 6473.6982\n",
            "Epoch [3020], val_loss: 6472.2930\n",
            "Epoch [3040], val_loss: 6472.1523\n",
            "Epoch [3060], val_loss: 6471.0776\n",
            "Epoch [3080], val_loss: 6469.7881\n",
            "Epoch [3100], val_loss: 6468.4165\n",
            "Epoch [3120], val_loss: 6466.9341\n",
            "Epoch [3140], val_loss: 6465.5801\n",
            "Epoch [3160], val_loss: 6464.7090\n",
            "Epoch [3180], val_loss: 6463.4619\n",
            "Epoch [3200], val_loss: 6462.5342\n",
            "Epoch [3220], val_loss: 6461.2622\n",
            "Epoch [3240], val_loss: 6462.0615\n",
            "Epoch [3260], val_loss: 6459.9980\n",
            "Epoch [3280], val_loss: 6457.9907\n",
            "Epoch [3300], val_loss: 6456.4531\n",
            "Epoch [3320], val_loss: 6455.4766\n",
            "Epoch [3340], val_loss: 6454.8691\n",
            "Epoch [3360], val_loss: 6454.3120\n",
            "Epoch [3380], val_loss: 6453.7827\n",
            "Epoch [3400], val_loss: 6451.0273\n",
            "Epoch [3420], val_loss: 6451.9663\n",
            "Epoch [3440], val_loss: 6450.2314\n",
            "Epoch [3460], val_loss: 6449.3545\n",
            "Epoch [3480], val_loss: 6447.8242\n",
            "Epoch [3500], val_loss: 6446.5508\n",
            "Epoch [3520], val_loss: 6446.4023\n",
            "Epoch [3540], val_loss: 6444.5215\n",
            "Epoch [3560], val_loss: 6444.4414\n",
            "Epoch [3580], val_loss: 6443.5752\n",
            "Epoch [3600], val_loss: 6442.2344\n",
            "Epoch [3620], val_loss: 6440.8164\n",
            "Epoch [3640], val_loss: 6438.9043\n",
            "Epoch [3660], val_loss: 6439.0068\n",
            "Epoch [3680], val_loss: 6438.9688\n",
            "Epoch [3700], val_loss: 6437.2695\n",
            "Epoch [3720], val_loss: 6436.2549\n",
            "Epoch [3740], val_loss: 6434.3594\n",
            "Epoch [3760], val_loss: 6435.3154\n",
            "Epoch [3780], val_loss: 6432.9829\n",
            "Epoch [3800], val_loss: 6432.8623\n",
            "Epoch [3820], val_loss: 6431.2373\n",
            "Epoch [3840], val_loss: 6430.2285\n",
            "Epoch [3860], val_loss: 6429.2671\n",
            "Epoch [3880], val_loss: 6428.3428\n",
            "Epoch [3900], val_loss: 6427.2148\n",
            "Epoch [3920], val_loss: 6425.9463\n",
            "Epoch [3940], val_loss: 6426.3486\n",
            "Epoch [3960], val_loss: 6424.4995\n",
            "Epoch [3980], val_loss: 6424.8535\n",
            "Epoch [4000], val_loss: 6421.8770\n",
            "Epoch [4020], val_loss: 6420.2871\n",
            "Epoch [4040], val_loss: 6419.4316\n",
            "Epoch [4060], val_loss: 6419.3335\n",
            "Epoch [4080], val_loss: 6419.5205\n",
            "Epoch [4100], val_loss: 6418.9062\n",
            "Epoch [4120], val_loss: 6416.2090\n",
            "Epoch [4140], val_loss: 6416.5234\n",
            "Epoch [4160], val_loss: 6414.2168\n",
            "Epoch [4180], val_loss: 6414.0532\n",
            "Epoch [4200], val_loss: 6412.7231\n",
            "Epoch [4220], val_loss: 6411.1846\n",
            "Epoch [4240], val_loss: 6409.9287\n",
            "Epoch [4260], val_loss: 6409.7275\n",
            "Epoch [4280], val_loss: 6409.2632\n",
            "Epoch [4300], val_loss: 6407.0557\n",
            "Epoch [4320], val_loss: 6406.1133\n",
            "Epoch [4340], val_loss: 6405.2549\n",
            "Epoch [4360], val_loss: 6404.2368\n",
            "Epoch [4380], val_loss: 6402.9688\n",
            "Epoch [4400], val_loss: 6402.5391\n",
            "Epoch [4420], val_loss: 6402.3633\n",
            "Epoch [4440], val_loss: 6401.8721\n",
            "Epoch [4460], val_loss: 6399.7334\n",
            "Epoch [4480], val_loss: 6398.7300\n",
            "Epoch [4500], val_loss: 6399.6113\n",
            "Epoch [4520], val_loss: 6396.2793\n",
            "Epoch [4540], val_loss: 6396.4736\n",
            "Epoch [4560], val_loss: 6394.6143\n",
            "Epoch [4580], val_loss: 6394.8286\n",
            "Epoch [4600], val_loss: 6394.1260\n",
            "Epoch [4620], val_loss: 6391.8418\n",
            "Epoch [4640], val_loss: 6392.1094\n",
            "Epoch [4660], val_loss: 6390.7588\n",
            "Epoch [4680], val_loss: 6390.2671\n",
            "Epoch [4700], val_loss: 6388.7964\n",
            "Epoch [4720], val_loss: 6387.3252\n",
            "Epoch [4740], val_loss: 6386.6357\n",
            "Epoch [4760], val_loss: 6386.7485\n",
            "Epoch [4780], val_loss: 6384.1572\n",
            "Epoch [4800], val_loss: 6383.3867\n",
            "Epoch [4820], val_loss: 6382.3452\n",
            "Epoch [4840], val_loss: 6381.6738\n",
            "Epoch [4860], val_loss: 6380.4395\n",
            "Epoch [4880], val_loss: 6381.3569\n",
            "Epoch [4900], val_loss: 6379.6250\n",
            "Epoch [4920], val_loss: 6378.4473\n",
            "Epoch [4940], val_loss: 6376.6543\n",
            "Epoch [4960], val_loss: 6375.5566\n",
            "Epoch [4980], val_loss: 6375.0283\n",
            "Epoch [5000], val_loss: 6374.0522\n",
            "Epoch [5020], val_loss: 6373.4316\n",
            "Epoch [5040], val_loss: 6372.5996\n",
            "Epoch [5060], val_loss: 6371.7456\n",
            "Epoch [5080], val_loss: 6371.2607\n",
            "Epoch [5100], val_loss: 6369.7803\n",
            "Epoch [5120], val_loss: 6369.6055\n",
            "Epoch [5140], val_loss: 6367.6270\n",
            "Epoch [5160], val_loss: 6366.6572\n",
            "Epoch [5180], val_loss: 6366.2803\n",
            "Epoch [5200], val_loss: 6365.1621\n",
            "Epoch [5220], val_loss: 6364.8359\n",
            "Epoch [5240], val_loss: 6363.6938\n",
            "Epoch [5260], val_loss: 6361.8223\n",
            "Epoch [5280], val_loss: 6361.0493\n",
            "Epoch [5300], val_loss: 6360.0049\n",
            "Epoch [5320], val_loss: 6359.2793\n",
            "Epoch [5340], val_loss: 6358.0605\n",
            "Epoch [5360], val_loss: 6358.2100\n",
            "Epoch [5380], val_loss: 6356.8564\n",
            "Epoch [5400], val_loss: 6355.5088\n",
            "Epoch [5420], val_loss: 6355.4619\n",
            "Epoch [5440], val_loss: 6354.4712\n",
            "Epoch [5460], val_loss: 6353.0444\n",
            "Epoch [5480], val_loss: 6353.0635\n",
            "Epoch [5500], val_loss: 6351.1216\n",
            "Epoch [5520], val_loss: 6350.2549\n",
            "Epoch [5540], val_loss: 6349.3394\n",
            "Epoch [5560], val_loss: 6348.9971\n",
            "Epoch [5580], val_loss: 6347.5117\n",
            "Epoch [5600], val_loss: 6346.3994\n",
            "Epoch [5620], val_loss: 6345.7646\n",
            "Epoch [5640], val_loss: 6344.3906\n",
            "Epoch [5660], val_loss: 6344.3477\n",
            "Epoch [5680], val_loss: 6343.1919\n",
            "Epoch [5700], val_loss: 6342.7041\n",
            "Epoch [5720], val_loss: 6341.4268\n",
            "Epoch [5740], val_loss: 6339.5957\n",
            "Epoch [5760], val_loss: 6338.9888\n",
            "Epoch [5780], val_loss: 6338.4482\n",
            "Epoch [5800], val_loss: 6336.7842\n",
            "Epoch [5820], val_loss: 6336.5342\n",
            "Epoch [5840], val_loss: 6335.6006\n",
            "Epoch [5860], val_loss: 6335.2793\n",
            "Epoch [5880], val_loss: 6333.3657\n",
            "Epoch [5900], val_loss: 6332.7197\n",
            "Epoch [5920], val_loss: 6331.7344\n",
            "Epoch [5940], val_loss: 6330.8579\n",
            "Epoch [5960], val_loss: 6330.2646\n",
            "Epoch [5980], val_loss: 6329.5664\n",
            "Epoch [6000], val_loss: 6329.6602\n",
            "Epoch [6020], val_loss: 6328.2070\n",
            "Epoch [6040], val_loss: 6326.5674\n",
            "Epoch [6060], val_loss: 6325.7725\n",
            "Epoch [6080], val_loss: 6325.1045\n",
            "Epoch [6100], val_loss: 6324.2500\n",
            "Epoch [6120], val_loss: 6322.9531\n",
            "Epoch [6140], val_loss: 6322.4316\n",
            "Epoch [6160], val_loss: 6322.0166\n",
            "Epoch [6180], val_loss: 6319.9912\n",
            "Epoch [6200], val_loss: 6319.1934\n",
            "Epoch [6220], val_loss: 6318.6797\n",
            "Epoch [6240], val_loss: 6317.0005\n",
            "Epoch [6260], val_loss: 6316.2539\n",
            "Epoch [6280], val_loss: 6315.8320\n",
            "Epoch [6300], val_loss: 6314.8481\n",
            "Epoch [6320], val_loss: 6314.4321\n",
            "Epoch [6340], val_loss: 6313.5078\n",
            "Epoch [6360], val_loss: 6313.1553\n",
            "Epoch [6380], val_loss: 6311.2354\n",
            "Epoch [6400], val_loss: 6310.0645\n",
            "Epoch [6420], val_loss: 6308.9365\n",
            "Epoch [6440], val_loss: 6307.7900\n",
            "Epoch [6460], val_loss: 6307.5947\n",
            "Epoch [6480], val_loss: 6306.2676\n",
            "Epoch [6500], val_loss: 6305.8672\n",
            "Epoch [6520], val_loss: 6304.6133\n",
            "Epoch [6540], val_loss: 6303.6133\n",
            "Epoch [6560], val_loss: 6302.5669\n",
            "Epoch [6580], val_loss: 6301.9541\n",
            "Epoch [6600], val_loss: 6300.7686\n",
            "Epoch [6620], val_loss: 6300.9717\n",
            "Epoch [6640], val_loss: 6299.7939\n",
            "Epoch [6660], val_loss: 6298.5703\n",
            "Epoch [6680], val_loss: 6297.6289\n",
            "Epoch [6700], val_loss: 6296.2236\n",
            "Epoch [6720], val_loss: 6295.4727\n",
            "Epoch [6740], val_loss: 6294.6836\n",
            "Epoch [6760], val_loss: 6294.0762\n",
            "Epoch [6780], val_loss: 6293.0566\n",
            "Epoch [6800], val_loss: 6292.3428\n",
            "Epoch [6820], val_loss: 6291.6753\n",
            "Epoch [6840], val_loss: 6290.1357\n",
            "Epoch [6860], val_loss: 6289.5566\n",
            "Epoch [6880], val_loss: 6288.9951\n",
            "Epoch [6900], val_loss: 6287.7402\n",
            "Epoch [6920], val_loss: 6286.8345\n",
            "Epoch [6940], val_loss: 6286.3408\n",
            "Epoch [6960], val_loss: 6285.1802\n",
            "Epoch [6980], val_loss: 6284.4961\n",
            "Epoch [7000], val_loss: 6283.0503\n",
            "Epoch [7020], val_loss: 6282.6182\n",
            "Epoch [7040], val_loss: 6281.0557\n",
            "Epoch [7060], val_loss: 6280.5879\n",
            "Epoch [7080], val_loss: 6279.8359\n",
            "Epoch [7100], val_loss: 6279.5762\n",
            "Epoch [7120], val_loss: 6278.0923\n",
            "Epoch [7140], val_loss: 6276.6611\n",
            "Epoch [7160], val_loss: 6278.1689\n",
            "Epoch [7180], val_loss: 6275.4375\n",
            "Epoch [7200], val_loss: 6274.2324\n",
            "Epoch [7220], val_loss: 6275.1406\n",
            "Epoch [7240], val_loss: 6274.0791\n",
            "Epoch [7260], val_loss: 6271.5664\n",
            "Epoch [7280], val_loss: 6270.8018\n",
            "Epoch [7300], val_loss: 6269.9053\n",
            "Epoch [7320], val_loss: 6269.0410\n",
            "Epoch [7340], val_loss: 6269.3154\n",
            "Epoch [7360], val_loss: 6267.2261\n",
            "Epoch [7380], val_loss: 6267.6982\n",
            "Epoch [7400], val_loss: 6265.2129\n",
            "Epoch [7420], val_loss: 6264.6475\n",
            "Epoch [7440], val_loss: 6264.0298\n",
            "Epoch [7460], val_loss: 6262.7319\n",
            "Epoch [7480], val_loss: 6262.2021\n",
            "Epoch [7500], val_loss: 6260.8887\n",
            "Epoch [7520], val_loss: 6260.5293\n",
            "Epoch [7540], val_loss: 6259.9570\n",
            "Epoch [7560], val_loss: 6258.7236\n",
            "Epoch [7580], val_loss: 6258.5244\n",
            "Epoch [7600], val_loss: 6257.5464\n",
            "Epoch [7620], val_loss: 6256.6963\n",
            "Epoch [7640], val_loss: 6254.8545\n",
            "Epoch [7660], val_loss: 6254.1562\n",
            "Epoch [7680], val_loss: 6254.0244\n",
            "Epoch [7700], val_loss: 6253.4131\n",
            "Epoch [7720], val_loss: 6251.6074\n",
            "Epoch [7740], val_loss: 6250.5190\n",
            "Epoch [7760], val_loss: 6250.3994\n",
            "Epoch [7780], val_loss: 6249.1748\n",
            "Epoch [7800], val_loss: 6248.7432\n",
            "Epoch [7820], val_loss: 6248.3076\n",
            "Epoch [7840], val_loss: 6246.6353\n",
            "Epoch [7860], val_loss: 6245.9355\n",
            "Epoch [7880], val_loss: 6244.4600\n",
            "Epoch [7900], val_loss: 6243.8442\n",
            "Epoch [7920], val_loss: 6243.0400\n",
            "Epoch [7940], val_loss: 6242.8975\n",
            "Epoch [7960], val_loss: 6241.1494\n",
            "Epoch [7980], val_loss: 6241.9580\n",
            "Epoch [8000], val_loss: 6240.4834\n",
            "Epoch [8020], val_loss: 6238.7363\n",
            "Epoch [8040], val_loss: 6237.3052\n",
            "Epoch [8060], val_loss: 6236.8945\n",
            "Epoch [8080], val_loss: 6236.3945\n",
            "Epoch [8100], val_loss: 6235.2012\n",
            "Epoch [8120], val_loss: 6234.8599\n",
            "Epoch [8140], val_loss: 6233.9980\n",
            "Epoch [8160], val_loss: 6234.6689\n",
            "Epoch [8180], val_loss: 6231.7344\n",
            "Epoch [8200], val_loss: 6231.2979\n",
            "Epoch [8220], val_loss: 6230.8984\n",
            "Epoch [8240], val_loss: 6228.9639\n",
            "Epoch [8260], val_loss: 6229.1514\n",
            "Epoch [8280], val_loss: 6227.6201\n",
            "Epoch [8300], val_loss: 6227.4121\n",
            "Epoch [8320], val_loss: 6229.0195\n",
            "Epoch [8340], val_loss: 6225.2778\n",
            "Epoch [8360], val_loss: 6224.3662\n",
            "Epoch [8380], val_loss: 6224.5371\n",
            "Epoch [8400], val_loss: 6222.5493\n",
            "Epoch [8420], val_loss: 6221.7261\n",
            "Epoch [8440], val_loss: 6220.7500\n",
            "Epoch [8460], val_loss: 6219.6436\n",
            "Epoch [8480], val_loss: 6219.5498\n",
            "Epoch [8500], val_loss: 6217.8462\n",
            "Epoch [8520], val_loss: 6217.4678\n",
            "Epoch [8540], val_loss: 6216.8086\n",
            "Epoch [8560], val_loss: 6216.9375\n",
            "Epoch [8580], val_loss: 6216.3955\n",
            "Epoch [8600], val_loss: 6215.7207\n",
            "Epoch [8620], val_loss: 6213.0059\n",
            "Epoch [8640], val_loss: 6211.8076\n",
            "Epoch [8660], val_loss: 6210.8301\n",
            "Epoch [8680], val_loss: 6210.7642\n",
            "Epoch [8700], val_loss: 6211.1094\n",
            "Epoch [8720], val_loss: 6211.9912\n",
            "Epoch [8740], val_loss: 6208.8506\n",
            "Epoch [8760], val_loss: 6210.1387\n",
            "Epoch [8780], val_loss: 6208.7588\n",
            "Epoch [8800], val_loss: 6205.9248\n",
            "Epoch [8820], val_loss: 6206.9346\n",
            "Epoch [8840], val_loss: 6205.0625\n",
            "Epoch [8860], val_loss: 6204.1748\n",
            "Epoch [8880], val_loss: 6205.2256\n",
            "Epoch [8900], val_loss: 6201.9512\n",
            "Epoch [8920], val_loss: 6199.9004\n",
            "Epoch [8940], val_loss: 6198.7954\n",
            "Epoch [8960], val_loss: 6198.7607\n",
            "Epoch [8980], val_loss: 6197.1147\n",
            "Epoch [9000], val_loss: 6196.5171\n",
            "Epoch [9020], val_loss: 6195.4492\n",
            "Epoch [9040], val_loss: 6194.3501\n",
            "Epoch [9060], val_loss: 6194.1670\n",
            "Epoch [9080], val_loss: 6192.9531\n",
            "Epoch [9100], val_loss: 6194.5786\n",
            "Epoch [9120], val_loss: 6192.2754\n",
            "Epoch [9140], val_loss: 6191.6270\n",
            "Epoch [9160], val_loss: 6189.4805\n",
            "Epoch [9180], val_loss: 6190.1885\n",
            "Epoch [9200], val_loss: 6187.8696\n",
            "Epoch [9220], val_loss: 6187.3770\n",
            "Epoch [9240], val_loss: 6185.8789\n",
            "Epoch [9260], val_loss: 6184.7002\n",
            "Epoch [9280], val_loss: 6187.7744\n",
            "Epoch [9300], val_loss: 6183.4775\n",
            "Epoch [9320], val_loss: 6183.2188\n",
            "Epoch [9340], val_loss: 6182.1729\n",
            "Epoch [9360], val_loss: 6180.8574\n",
            "Epoch [9380], val_loss: 6181.3716\n",
            "Epoch [9400], val_loss: 6180.1040\n",
            "Epoch [9420], val_loss: 6178.6470\n",
            "Epoch [9440], val_loss: 6178.3555\n",
            "Epoch [9460], val_loss: 6176.5889\n",
            "Epoch [9480], val_loss: 6176.2925\n",
            "Epoch [9500], val_loss: 6175.6250\n",
            "Epoch [9520], val_loss: 6174.3989\n",
            "Epoch [9540], val_loss: 6175.1304\n",
            "Epoch [9560], val_loss: 6178.4854\n",
            "Epoch [9580], val_loss: 6172.2598\n",
            "Epoch [9600], val_loss: 6170.6704\n",
            "Epoch [9620], val_loss: 6171.1821\n",
            "Epoch [9640], val_loss: 6170.0293\n",
            "Epoch [9660], val_loss: 6172.0894\n",
            "Epoch [9680], val_loss: 6170.5850\n",
            "Epoch [9700], val_loss: 6167.1284\n",
            "Epoch [9720], val_loss: 6166.3115\n",
            "Epoch [9740], val_loss: 6165.6733\n",
            "Epoch [9760], val_loss: 6164.0537\n",
            "Epoch [9780], val_loss: 6165.2544\n",
            "Epoch [9800], val_loss: 6164.0234\n",
            "Epoch [9820], val_loss: 6164.7627\n",
            "Epoch [9840], val_loss: 6161.4453\n",
            "Epoch [9860], val_loss: 6160.0811\n",
            "Epoch [9880], val_loss: 6160.1255\n",
            "Epoch [9900], val_loss: 6160.2866\n",
            "Epoch [9920], val_loss: 6157.1812\n",
            "Epoch [9940], val_loss: 6158.6733\n",
            "Epoch [9960], val_loss: 6157.6792\n",
            "Epoch [9980], val_loss: 6155.0947\n",
            "Epoch [10000], val_loss: 6157.1924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axq_76qc1iRl",
        "outputId": "5e1c550d-1a48-41d7-dfe4-1c141eb3dae0"
      },
      "source": [
        "epochs = 2000\n",
        "lr = 1e-2\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6155.5283\n",
            "Epoch [40], val_loss: 6155.4683\n",
            "Epoch [60], val_loss: 6155.3359\n",
            "Epoch [80], val_loss: 6155.2764\n",
            "Epoch [100], val_loss: 6155.2773\n",
            "Epoch [120], val_loss: 6155.2974\n",
            "Epoch [140], val_loss: 6155.0239\n",
            "Epoch [160], val_loss: 6154.8574\n",
            "Epoch [180], val_loss: 6154.8018\n",
            "Epoch [200], val_loss: 6154.6680\n",
            "Epoch [220], val_loss: 6154.7930\n",
            "Epoch [240], val_loss: 6154.6660\n",
            "Epoch [260], val_loss: 6154.4697\n",
            "Epoch [280], val_loss: 6154.5000\n",
            "Epoch [300], val_loss: 6154.4473\n",
            "Epoch [320], val_loss: 6154.2852\n",
            "Epoch [340], val_loss: 6154.3188\n",
            "Epoch [360], val_loss: 6154.1416\n",
            "Epoch [380], val_loss: 6153.9922\n",
            "Epoch [400], val_loss: 6153.9624\n",
            "Epoch [420], val_loss: 6153.8760\n",
            "Epoch [440], val_loss: 6153.5615\n",
            "Epoch [460], val_loss: 6153.6641\n",
            "Epoch [480], val_loss: 6153.4404\n",
            "Epoch [500], val_loss: 6153.4482\n",
            "Epoch [520], val_loss: 6153.4697\n",
            "Epoch [540], val_loss: 6153.3872\n",
            "Epoch [560], val_loss: 6153.1377\n",
            "Epoch [580], val_loss: 6153.1738\n",
            "Epoch [600], val_loss: 6153.0522\n",
            "Epoch [620], val_loss: 6153.0396\n",
            "Epoch [640], val_loss: 6152.7607\n",
            "Epoch [660], val_loss: 6153.0068\n",
            "Epoch [680], val_loss: 6152.7529\n",
            "Epoch [700], val_loss: 6152.6113\n",
            "Epoch [720], val_loss: 6152.4395\n",
            "Epoch [740], val_loss: 6152.5776\n",
            "Epoch [760], val_loss: 6152.2754\n",
            "Epoch [780], val_loss: 6152.2324\n",
            "Epoch [800], val_loss: 6152.0527\n",
            "Epoch [820], val_loss: 6152.1538\n",
            "Epoch [840], val_loss: 6152.1963\n",
            "Epoch [860], val_loss: 6151.9028\n",
            "Epoch [880], val_loss: 6151.7153\n",
            "Epoch [900], val_loss: 6151.7891\n",
            "Epoch [920], val_loss: 6151.7583\n",
            "Epoch [940], val_loss: 6151.7061\n",
            "Epoch [960], val_loss: 6151.5908\n",
            "Epoch [980], val_loss: 6151.5757\n",
            "Epoch [1000], val_loss: 6151.1484\n",
            "Epoch [1020], val_loss: 6151.3188\n",
            "Epoch [1040], val_loss: 6151.0557\n",
            "Epoch [1060], val_loss: 6151.0659\n",
            "Epoch [1080], val_loss: 6150.9980\n",
            "Epoch [1100], val_loss: 6150.8384\n",
            "Epoch [1120], val_loss: 6150.8281\n",
            "Epoch [1140], val_loss: 6150.7061\n",
            "Epoch [1160], val_loss: 6150.8535\n",
            "Epoch [1180], val_loss: 6150.5547\n",
            "Epoch [1200], val_loss: 6150.4590\n",
            "Epoch [1220], val_loss: 6150.3467\n",
            "Epoch [1240], val_loss: 6150.3330\n",
            "Epoch [1260], val_loss: 6150.4160\n",
            "Epoch [1280], val_loss: 6149.9316\n",
            "Epoch [1300], val_loss: 6149.9707\n",
            "Epoch [1320], val_loss: 6149.9131\n",
            "Epoch [1340], val_loss: 6149.8101\n",
            "Epoch [1360], val_loss: 6149.7344\n",
            "Epoch [1380], val_loss: 6149.6040\n",
            "Epoch [1400], val_loss: 6149.6968\n",
            "Epoch [1420], val_loss: 6149.4194\n",
            "Epoch [1440], val_loss: 6149.4932\n",
            "Epoch [1460], val_loss: 6149.3750\n",
            "Epoch [1480], val_loss: 6149.2812\n",
            "Epoch [1500], val_loss: 6149.1543\n",
            "Epoch [1520], val_loss: 6149.1128\n",
            "Epoch [1540], val_loss: 6148.9819\n",
            "Epoch [1560], val_loss: 6149.0830\n",
            "Epoch [1580], val_loss: 6148.9805\n",
            "Epoch [1600], val_loss: 6148.6572\n",
            "Epoch [1620], val_loss: 6148.6562\n",
            "Epoch [1640], val_loss: 6148.5596\n",
            "Epoch [1660], val_loss: 6148.4893\n",
            "Epoch [1680], val_loss: 6148.4326\n",
            "Epoch [1700], val_loss: 6148.2827\n",
            "Epoch [1720], val_loss: 6148.1880\n",
            "Epoch [1740], val_loss: 6148.1328\n",
            "Epoch [1760], val_loss: 6148.1328\n",
            "Epoch [1780], val_loss: 6147.8721\n",
            "Epoch [1800], val_loss: 6148.0664\n",
            "Epoch [1820], val_loss: 6147.7607\n",
            "Epoch [1840], val_loss: 6147.8682\n",
            "Epoch [1860], val_loss: 6147.6992\n",
            "Epoch [1880], val_loss: 6147.3125\n",
            "Epoch [1900], val_loss: 6147.6826\n",
            "Epoch [1920], val_loss: 6147.2979\n",
            "Epoch [1940], val_loss: 6147.3599\n",
            "Epoch [1960], val_loss: 6147.1738\n",
            "Epoch [1980], val_loss: 6147.2451\n",
            "Epoch [2000], val_loss: 6147.0713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJNmw5O1iRm",
        "outputId": "c93c2f8d-66a8-476d-d96e-011207fb7a06"
      },
      "source": [
        "epochs = 15000\n",
        "lr = 1e-3\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6147.0459\n",
            "Epoch [40], val_loss: 6147.0332\n",
            "Epoch [60], val_loss: 6147.0298\n",
            "Epoch [80], val_loss: 6147.0376\n",
            "Epoch [100], val_loss: 6147.0078\n",
            "Epoch [120], val_loss: 6147.0015\n",
            "Epoch [140], val_loss: 6146.9844\n",
            "Epoch [160], val_loss: 6146.9639\n",
            "Epoch [180], val_loss: 6146.9629\n",
            "Epoch [200], val_loss: 6146.9634\n",
            "Epoch [220], val_loss: 6146.9780\n",
            "Epoch [240], val_loss: 6146.9521\n",
            "Epoch [260], val_loss: 6146.9512\n",
            "Epoch [280], val_loss: 6146.9355\n",
            "Epoch [300], val_loss: 6146.9238\n",
            "Epoch [320], val_loss: 6146.9043\n",
            "Epoch [340], val_loss: 6146.9077\n",
            "Epoch [360], val_loss: 6146.8940\n",
            "Epoch [380], val_loss: 6146.8867\n",
            "Epoch [400], val_loss: 6146.8965\n",
            "Epoch [420], val_loss: 6146.8691\n",
            "Epoch [440], val_loss: 6146.8496\n",
            "Epoch [460], val_loss: 6146.8613\n",
            "Epoch [480], val_loss: 6146.8408\n",
            "Epoch [500], val_loss: 6146.8418\n",
            "Epoch [520], val_loss: 6146.8540\n",
            "Epoch [540], val_loss: 6146.8262\n",
            "Epoch [560], val_loss: 6146.7988\n",
            "Epoch [580], val_loss: 6146.7979\n",
            "Epoch [600], val_loss: 6146.7715\n",
            "Epoch [620], val_loss: 6146.7744\n",
            "Epoch [640], val_loss: 6146.7827\n",
            "Epoch [660], val_loss: 6146.7573\n",
            "Epoch [680], val_loss: 6146.7397\n",
            "Epoch [700], val_loss: 6146.7383\n",
            "Epoch [720], val_loss: 6146.7119\n",
            "Epoch [740], val_loss: 6146.6787\n",
            "Epoch [760], val_loss: 6146.7051\n",
            "Epoch [780], val_loss: 6146.7026\n",
            "Epoch [800], val_loss: 6146.7139\n",
            "Epoch [820], val_loss: 6146.6914\n",
            "Epoch [840], val_loss: 6146.6895\n",
            "Epoch [860], val_loss: 6146.6753\n",
            "Epoch [880], val_loss: 6146.6641\n",
            "Epoch [900], val_loss: 6146.6597\n",
            "Epoch [920], val_loss: 6146.6426\n",
            "Epoch [940], val_loss: 6146.6406\n",
            "Epoch [960], val_loss: 6146.6055\n",
            "Epoch [980], val_loss: 6146.6245\n",
            "Epoch [1000], val_loss: 6146.6040\n",
            "Epoch [1020], val_loss: 6146.5933\n",
            "Epoch [1040], val_loss: 6146.5903\n",
            "Epoch [1060], val_loss: 6146.6006\n",
            "Epoch [1080], val_loss: 6146.5664\n",
            "Epoch [1100], val_loss: 6146.5640\n",
            "Epoch [1120], val_loss: 6146.5596\n",
            "Epoch [1140], val_loss: 6146.5469\n",
            "Epoch [1160], val_loss: 6146.5200\n",
            "Epoch [1180], val_loss: 6146.5352\n",
            "Epoch [1200], val_loss: 6146.5176\n",
            "Epoch [1220], val_loss: 6146.5137\n",
            "Epoch [1240], val_loss: 6146.4878\n",
            "Epoch [1260], val_loss: 6146.4980\n",
            "Epoch [1280], val_loss: 6146.4883\n",
            "Epoch [1300], val_loss: 6146.4590\n",
            "Epoch [1320], val_loss: 6146.4570\n",
            "Epoch [1340], val_loss: 6146.4570\n",
            "Epoch [1360], val_loss: 6146.4473\n",
            "Epoch [1380], val_loss: 6146.4385\n",
            "Epoch [1400], val_loss: 6146.4390\n",
            "Epoch [1420], val_loss: 6146.4102\n",
            "Epoch [1440], val_loss: 6146.4189\n",
            "Epoch [1460], val_loss: 6146.3896\n",
            "Epoch [1480], val_loss: 6146.4043\n",
            "Epoch [1500], val_loss: 6146.3574\n",
            "Epoch [1520], val_loss: 6146.3613\n",
            "Epoch [1540], val_loss: 6146.3633\n",
            "Epoch [1560], val_loss: 6146.3682\n",
            "Epoch [1580], val_loss: 6146.3506\n",
            "Epoch [1600], val_loss: 6146.3462\n",
            "Epoch [1620], val_loss: 6146.3398\n",
            "Epoch [1640], val_loss: 6146.3286\n",
            "Epoch [1660], val_loss: 6146.3057\n",
            "Epoch [1680], val_loss: 6146.3066\n",
            "Epoch [1700], val_loss: 6146.2812\n",
            "Epoch [1720], val_loss: 6146.2686\n",
            "Epoch [1740], val_loss: 6146.2734\n",
            "Epoch [1760], val_loss: 6146.2842\n",
            "Epoch [1780], val_loss: 6146.2754\n",
            "Epoch [1800], val_loss: 6146.2383\n",
            "Epoch [1820], val_loss: 6146.2246\n",
            "Epoch [1840], val_loss: 6146.2080\n",
            "Epoch [1860], val_loss: 6146.2100\n",
            "Epoch [1880], val_loss: 6146.2119\n",
            "Epoch [1900], val_loss: 6146.2080\n",
            "Epoch [1920], val_loss: 6146.1860\n",
            "Epoch [1940], val_loss: 6146.1802\n",
            "Epoch [1960], val_loss: 6146.1680\n",
            "Epoch [1980], val_loss: 6146.1743\n",
            "Epoch [2000], val_loss: 6146.1699\n",
            "Epoch [2020], val_loss: 6146.1621\n",
            "Epoch [2040], val_loss: 6146.1191\n",
            "Epoch [2060], val_loss: 6146.1201\n",
            "Epoch [2080], val_loss: 6146.1104\n",
            "Epoch [2100], val_loss: 6146.0898\n",
            "Epoch [2120], val_loss: 6146.0898\n",
            "Epoch [2140], val_loss: 6146.1035\n",
            "Epoch [2160], val_loss: 6146.0830\n",
            "Epoch [2180], val_loss: 6146.0557\n",
            "Epoch [2200], val_loss: 6146.0664\n",
            "Epoch [2220], val_loss: 6146.0562\n",
            "Epoch [2240], val_loss: 6146.0400\n",
            "Epoch [2260], val_loss: 6146.0283\n",
            "Epoch [2280], val_loss: 6146.0342\n",
            "Epoch [2300], val_loss: 6146.0137\n",
            "Epoch [2320], val_loss: 6146.0254\n",
            "Epoch [2340], val_loss: 6146.0024\n",
            "Epoch [2360], val_loss: 6146.0176\n",
            "Epoch [2380], val_loss: 6145.9961\n",
            "Epoch [2400], val_loss: 6145.9775\n",
            "Epoch [2420], val_loss: 6145.9897\n",
            "Epoch [2440], val_loss: 6145.9531\n",
            "Epoch [2460], val_loss: 6145.9697\n",
            "Epoch [2480], val_loss: 6145.9609\n",
            "Epoch [2500], val_loss: 6145.9307\n",
            "Epoch [2520], val_loss: 6145.9170\n",
            "Epoch [2540], val_loss: 6145.9194\n",
            "Epoch [2560], val_loss: 6145.9194\n",
            "Epoch [2580], val_loss: 6145.9229\n",
            "Epoch [2600], val_loss: 6145.8955\n",
            "Epoch [2620], val_loss: 6145.8828\n",
            "Epoch [2640], val_loss: 6145.8726\n",
            "Epoch [2660], val_loss: 6145.8750\n",
            "Epoch [2680], val_loss: 6145.8633\n",
            "Epoch [2700], val_loss: 6145.8535\n",
            "Epoch [2720], val_loss: 6145.8398\n",
            "Epoch [2740], val_loss: 6145.8140\n",
            "Epoch [2760], val_loss: 6145.8198\n",
            "Epoch [2780], val_loss: 6145.8164\n",
            "Epoch [2800], val_loss: 6145.8086\n",
            "Epoch [2820], val_loss: 6145.7817\n",
            "Epoch [2840], val_loss: 6145.7920\n",
            "Epoch [2860], val_loss: 6145.7646\n",
            "Epoch [2880], val_loss: 6145.7930\n",
            "Epoch [2900], val_loss: 6145.7520\n",
            "Epoch [2920], val_loss: 6145.7363\n",
            "Epoch [2940], val_loss: 6145.7480\n",
            "Epoch [2960], val_loss: 6145.7051\n",
            "Epoch [2980], val_loss: 6145.7041\n",
            "Epoch [3000], val_loss: 6145.7251\n",
            "Epoch [3020], val_loss: 6145.7104\n",
            "Epoch [3040], val_loss: 6145.6797\n",
            "Epoch [3060], val_loss: 6145.6919\n",
            "Epoch [3080], val_loss: 6145.6665\n",
            "Epoch [3100], val_loss: 6145.6582\n",
            "Epoch [3120], val_loss: 6145.6675\n",
            "Epoch [3140], val_loss: 6145.6616\n",
            "Epoch [3160], val_loss: 6145.6406\n",
            "Epoch [3180], val_loss: 6145.6328\n",
            "Epoch [3200], val_loss: 6145.6338\n",
            "Epoch [3220], val_loss: 6145.6143\n",
            "Epoch [3240], val_loss: 6145.6133\n",
            "Epoch [3260], val_loss: 6145.5869\n",
            "Epoch [3280], val_loss: 6145.5879\n",
            "Epoch [3300], val_loss: 6145.5918\n",
            "Epoch [3320], val_loss: 6145.5762\n",
            "Epoch [3340], val_loss: 6145.5664\n",
            "Epoch [3360], val_loss: 6145.5220\n",
            "Epoch [3380], val_loss: 6145.5430\n",
            "Epoch [3400], val_loss: 6145.5420\n",
            "Epoch [3420], val_loss: 6145.5254\n",
            "Epoch [3440], val_loss: 6145.5156\n",
            "Epoch [3460], val_loss: 6145.4971\n",
            "Epoch [3480], val_loss: 6145.4956\n",
            "Epoch [3500], val_loss: 6145.5078\n",
            "Epoch [3520], val_loss: 6145.4766\n",
            "Epoch [3540], val_loss: 6145.4668\n",
            "Epoch [3560], val_loss: 6145.4736\n",
            "Epoch [3580], val_loss: 6145.4609\n",
            "Epoch [3600], val_loss: 6145.4453\n",
            "Epoch [3620], val_loss: 6145.4248\n",
            "Epoch [3640], val_loss: 6145.4409\n",
            "Epoch [3660], val_loss: 6145.4111\n",
            "Epoch [3680], val_loss: 6145.3994\n",
            "Epoch [3700], val_loss: 6145.3984\n",
            "Epoch [3720], val_loss: 6145.3882\n",
            "Epoch [3740], val_loss: 6145.3691\n",
            "Epoch [3760], val_loss: 6145.3906\n",
            "Epoch [3780], val_loss: 6145.3623\n",
            "Epoch [3800], val_loss: 6145.3770\n",
            "Epoch [3820], val_loss: 6145.3574\n",
            "Epoch [3840], val_loss: 6145.3320\n",
            "Epoch [3860], val_loss: 6145.3286\n",
            "Epoch [3880], val_loss: 6145.3301\n",
            "Epoch [3900], val_loss: 6145.3164\n",
            "Epoch [3920], val_loss: 6145.2969\n",
            "Epoch [3940], val_loss: 6145.2979\n",
            "Epoch [3960], val_loss: 6145.2930\n",
            "Epoch [3980], val_loss: 6145.2666\n",
            "Epoch [4000], val_loss: 6145.2686\n",
            "Epoch [4020], val_loss: 6145.2573\n",
            "Epoch [4040], val_loss: 6145.2588\n",
            "Epoch [4060], val_loss: 6145.2397\n",
            "Epoch [4080], val_loss: 6145.2441\n",
            "Epoch [4100], val_loss: 6145.2432\n",
            "Epoch [4120], val_loss: 6145.2246\n",
            "Epoch [4140], val_loss: 6145.2031\n",
            "Epoch [4160], val_loss: 6145.1855\n",
            "Epoch [4180], val_loss: 6145.1655\n",
            "Epoch [4200], val_loss: 6145.1694\n",
            "Epoch [4220], val_loss: 6145.1787\n",
            "Epoch [4240], val_loss: 6145.1709\n",
            "Epoch [4260], val_loss: 6145.1660\n",
            "Epoch [4280], val_loss: 6145.1377\n",
            "Epoch [4300], val_loss: 6145.1270\n",
            "Epoch [4320], val_loss: 6145.1104\n",
            "Epoch [4340], val_loss: 6145.1064\n",
            "Epoch [4360], val_loss: 6145.1143\n",
            "Epoch [4380], val_loss: 6145.0879\n",
            "Epoch [4400], val_loss: 6145.0723\n",
            "Epoch [4420], val_loss: 6145.0869\n",
            "Epoch [4440], val_loss: 6145.0732\n",
            "Epoch [4460], val_loss: 6145.0801\n",
            "Epoch [4480], val_loss: 6145.0566\n",
            "Epoch [4500], val_loss: 6145.0513\n",
            "Epoch [4520], val_loss: 6145.0615\n",
            "Epoch [4540], val_loss: 6145.0322\n",
            "Epoch [4560], val_loss: 6145.0078\n",
            "Epoch [4580], val_loss: 6145.0181\n",
            "Epoch [4600], val_loss: 6144.9946\n",
            "Epoch [4620], val_loss: 6144.9912\n",
            "Epoch [4640], val_loss: 6144.9805\n",
            "Epoch [4660], val_loss: 6144.9648\n",
            "Epoch [4680], val_loss: 6144.9736\n",
            "Epoch [4700], val_loss: 6144.9712\n",
            "Epoch [4720], val_loss: 6144.9531\n",
            "Epoch [4740], val_loss: 6144.9380\n",
            "Epoch [4760], val_loss: 6144.9326\n",
            "Epoch [4780], val_loss: 6144.9111\n",
            "Epoch [4800], val_loss: 6144.9204\n",
            "Epoch [4820], val_loss: 6144.9053\n",
            "Epoch [4840], val_loss: 6144.8867\n",
            "Epoch [4860], val_loss: 6144.8770\n",
            "Epoch [4880], val_loss: 6144.8779\n",
            "Epoch [4900], val_loss: 6144.8574\n",
            "Epoch [4920], val_loss: 6144.8525\n",
            "Epoch [4940], val_loss: 6144.8501\n",
            "Epoch [4960], val_loss: 6144.8477\n",
            "Epoch [4980], val_loss: 6144.8340\n",
            "Epoch [5000], val_loss: 6144.8096\n",
            "Epoch [5020], val_loss: 6144.8203\n",
            "Epoch [5040], val_loss: 6144.8057\n",
            "Epoch [5060], val_loss: 6144.8066\n",
            "Epoch [5080], val_loss: 6144.7920\n",
            "Epoch [5100], val_loss: 6144.7744\n",
            "Epoch [5120], val_loss: 6144.7627\n",
            "Epoch [5140], val_loss: 6144.7622\n",
            "Epoch [5160], val_loss: 6144.7471\n",
            "Epoch [5180], val_loss: 6144.7310\n",
            "Epoch [5200], val_loss: 6144.6924\n",
            "Epoch [5220], val_loss: 6144.6973\n",
            "Epoch [5240], val_loss: 6144.6943\n",
            "Epoch [5260], val_loss: 6144.6904\n",
            "Epoch [5280], val_loss: 6144.6924\n",
            "Epoch [5300], val_loss: 6144.6807\n",
            "Epoch [5320], val_loss: 6144.6768\n",
            "Epoch [5340], val_loss: 6144.6719\n",
            "Epoch [5360], val_loss: 6144.6562\n",
            "Epoch [5380], val_loss: 6144.6494\n",
            "Epoch [5400], val_loss: 6144.6426\n",
            "Epoch [5420], val_loss: 6144.6396\n",
            "Epoch [5440], val_loss: 6144.6338\n",
            "Epoch [5460], val_loss: 6144.6274\n",
            "Epoch [5480], val_loss: 6144.6045\n",
            "Epoch [5500], val_loss: 6144.5889\n",
            "Epoch [5520], val_loss: 6144.5898\n",
            "Epoch [5540], val_loss: 6144.5635\n",
            "Epoch [5560], val_loss: 6144.5605\n",
            "Epoch [5580], val_loss: 6144.5547\n",
            "Epoch [5600], val_loss: 6144.5635\n",
            "Epoch [5620], val_loss: 6144.5522\n",
            "Epoch [5640], val_loss: 6144.5322\n",
            "Epoch [5660], val_loss: 6144.5342\n",
            "Epoch [5680], val_loss: 6144.5288\n",
            "Epoch [5700], val_loss: 6144.5225\n",
            "Epoch [5720], val_loss: 6144.4824\n",
            "Epoch [5740], val_loss: 6144.4907\n",
            "Epoch [5760], val_loss: 6144.4766\n",
            "Epoch [5780], val_loss: 6144.4775\n",
            "Epoch [5800], val_loss: 6144.4624\n",
            "Epoch [5820], val_loss: 6144.4746\n",
            "Epoch [5840], val_loss: 6144.4385\n",
            "Epoch [5860], val_loss: 6144.4375\n",
            "Epoch [5880], val_loss: 6144.4258\n",
            "Epoch [5900], val_loss: 6144.4106\n",
            "Epoch [5920], val_loss: 6144.3867\n",
            "Epoch [5940], val_loss: 6144.4150\n",
            "Epoch [5960], val_loss: 6144.3799\n",
            "Epoch [5980], val_loss: 6144.3516\n",
            "Epoch [6000], val_loss: 6144.3564\n",
            "Epoch [6020], val_loss: 6144.3574\n",
            "Epoch [6040], val_loss: 6144.3711\n",
            "Epoch [6060], val_loss: 6144.3789\n",
            "Epoch [6080], val_loss: 6144.3276\n",
            "Epoch [6100], val_loss: 6144.3315\n",
            "Epoch [6120], val_loss: 6144.3271\n",
            "Epoch [6140], val_loss: 6144.2988\n",
            "Epoch [6160], val_loss: 6144.2964\n",
            "Epoch [6180], val_loss: 6144.2842\n",
            "Epoch [6200], val_loss: 6144.2930\n",
            "Epoch [6220], val_loss: 6144.2739\n",
            "Epoch [6240], val_loss: 6144.2637\n",
            "Epoch [6260], val_loss: 6144.2627\n",
            "Epoch [6280], val_loss: 6144.2446\n",
            "Epoch [6300], val_loss: 6144.2354\n",
            "Epoch [6320], val_loss: 6144.2109\n",
            "Epoch [6340], val_loss: 6144.2266\n",
            "Epoch [6360], val_loss: 6144.2109\n",
            "Epoch [6380], val_loss: 6144.2070\n",
            "Epoch [6400], val_loss: 6144.1909\n",
            "Epoch [6420], val_loss: 6144.1919\n",
            "Epoch [6440], val_loss: 6144.1436\n",
            "Epoch [6460], val_loss: 6144.1406\n",
            "Epoch [6480], val_loss: 6144.1431\n",
            "Epoch [6500], val_loss: 6144.1621\n",
            "Epoch [6520], val_loss: 6144.1543\n",
            "Epoch [6540], val_loss: 6144.1372\n",
            "Epoch [6560], val_loss: 6144.1128\n",
            "Epoch [6580], val_loss: 6144.1240\n",
            "Epoch [6600], val_loss: 6144.1104\n",
            "Epoch [6620], val_loss: 6144.1191\n",
            "Epoch [6640], val_loss: 6144.1064\n",
            "Epoch [6660], val_loss: 6144.0806\n",
            "Epoch [6680], val_loss: 6144.0688\n",
            "Epoch [6700], val_loss: 6144.0752\n",
            "Epoch [6720], val_loss: 6144.0625\n",
            "Epoch [6740], val_loss: 6144.0361\n",
            "Epoch [6760], val_loss: 6144.0464\n",
            "Epoch [6780], val_loss: 6144.0322\n",
            "Epoch [6800], val_loss: 6144.0171\n",
            "Epoch [6820], val_loss: 6144.0156\n",
            "Epoch [6840], val_loss: 6143.9932\n",
            "Epoch [6860], val_loss: 6143.9932\n",
            "Epoch [6880], val_loss: 6143.9941\n",
            "Epoch [6900], val_loss: 6143.9834\n",
            "Epoch [6920], val_loss: 6143.9658\n",
            "Epoch [6940], val_loss: 6143.9688\n",
            "Epoch [6960], val_loss: 6143.9590\n",
            "Epoch [6980], val_loss: 6143.9316\n",
            "Epoch [7000], val_loss: 6143.9390\n",
            "Epoch [7020], val_loss: 6143.9214\n",
            "Epoch [7040], val_loss: 6143.9028\n",
            "Epoch [7060], val_loss: 6143.8940\n",
            "Epoch [7080], val_loss: 6143.8945\n",
            "Epoch [7100], val_loss: 6143.8926\n",
            "Epoch [7120], val_loss: 6143.8799\n",
            "Epoch [7140], val_loss: 6143.8428\n",
            "Epoch [7160], val_loss: 6143.8525\n",
            "Epoch [7180], val_loss: 6143.8438\n",
            "Epoch [7200], val_loss: 6143.8320\n",
            "Epoch [7220], val_loss: 6143.8052\n",
            "Epoch [7240], val_loss: 6143.8135\n",
            "Epoch [7260], val_loss: 6143.8232\n",
            "Epoch [7280], val_loss: 6143.8130\n",
            "Epoch [7300], val_loss: 6143.7979\n",
            "Epoch [7320], val_loss: 6143.7959\n",
            "Epoch [7340], val_loss: 6143.7759\n",
            "Epoch [7360], val_loss: 6143.7549\n",
            "Epoch [7380], val_loss: 6143.7593\n",
            "Epoch [7400], val_loss: 6143.7358\n",
            "Epoch [7420], val_loss: 6143.7568\n",
            "Epoch [7440], val_loss: 6143.7490\n",
            "Epoch [7460], val_loss: 6143.7168\n",
            "Epoch [7480], val_loss: 6143.7012\n",
            "Epoch [7500], val_loss: 6143.7070\n",
            "Epoch [7520], val_loss: 6143.7109\n",
            "Epoch [7540], val_loss: 6143.7061\n",
            "Epoch [7560], val_loss: 6143.6982\n",
            "Epoch [7580], val_loss: 6143.6621\n",
            "Epoch [7600], val_loss: 6143.6675\n",
            "Epoch [7620], val_loss: 6143.6680\n",
            "Epoch [7640], val_loss: 6143.6450\n",
            "Epoch [7660], val_loss: 6143.6025\n",
            "Epoch [7680], val_loss: 6143.6279\n",
            "Epoch [7700], val_loss: 6143.6108\n",
            "Epoch [7720], val_loss: 6143.6230\n",
            "Epoch [7740], val_loss: 6143.6147\n",
            "Epoch [7760], val_loss: 6143.6035\n",
            "Epoch [7780], val_loss: 6143.5811\n",
            "Epoch [7800], val_loss: 6143.5693\n",
            "Epoch [7820], val_loss: 6143.5557\n",
            "Epoch [7840], val_loss: 6143.5518\n",
            "Epoch [7860], val_loss: 6143.5449\n",
            "Epoch [7880], val_loss: 6143.5430\n",
            "Epoch [7900], val_loss: 6143.5308\n",
            "Epoch [7920], val_loss: 6143.5342\n",
            "Epoch [7940], val_loss: 6143.5127\n",
            "Epoch [7960], val_loss: 6143.5020\n",
            "Epoch [7980], val_loss: 6143.4971\n",
            "Epoch [8000], val_loss: 6143.5107\n",
            "Epoch [8020], val_loss: 6143.4941\n",
            "Epoch [8040], val_loss: 6143.4492\n",
            "Epoch [8060], val_loss: 6143.4502\n",
            "Epoch [8080], val_loss: 6143.4507\n",
            "Epoch [8100], val_loss: 6143.4355\n",
            "Epoch [8120], val_loss: 6143.4443\n",
            "Epoch [8140], val_loss: 6143.4326\n",
            "Epoch [8160], val_loss: 6143.4150\n",
            "Epoch [8180], val_loss: 6143.4165\n",
            "Epoch [8200], val_loss: 6143.4082\n",
            "Epoch [8220], val_loss: 6143.3784\n",
            "Epoch [8240], val_loss: 6143.4097\n",
            "Epoch [8260], val_loss: 6143.3643\n",
            "Epoch [8280], val_loss: 6143.3691\n",
            "Epoch [8300], val_loss: 6143.3613\n",
            "Epoch [8320], val_loss: 6143.3359\n",
            "Epoch [8340], val_loss: 6143.3447\n",
            "Epoch [8360], val_loss: 6143.3135\n",
            "Epoch [8380], val_loss: 6143.3101\n",
            "Epoch [8400], val_loss: 6143.3076\n",
            "Epoch [8420], val_loss: 6143.3062\n",
            "Epoch [8440], val_loss: 6143.2939\n",
            "Epoch [8460], val_loss: 6143.2920\n",
            "Epoch [8480], val_loss: 6143.2949\n",
            "Epoch [8500], val_loss: 6143.2539\n",
            "Epoch [8520], val_loss: 6143.2642\n",
            "Epoch [8540], val_loss: 6143.2344\n",
            "Epoch [8560], val_loss: 6143.2334\n",
            "Epoch [8580], val_loss: 6143.2412\n",
            "Epoch [8600], val_loss: 6143.2153\n",
            "Epoch [8620], val_loss: 6143.2041\n",
            "Epoch [8640], val_loss: 6143.1934\n",
            "Epoch [8660], val_loss: 6143.1968\n",
            "Epoch [8680], val_loss: 6143.1963\n",
            "Epoch [8700], val_loss: 6143.1826\n",
            "Epoch [8720], val_loss: 6143.1650\n",
            "Epoch [8740], val_loss: 6143.1533\n",
            "Epoch [8760], val_loss: 6143.1504\n",
            "Epoch [8780], val_loss: 6143.1553\n",
            "Epoch [8800], val_loss: 6143.1196\n",
            "Epoch [8820], val_loss: 6143.1250\n",
            "Epoch [8840], val_loss: 6143.0967\n",
            "Epoch [8860], val_loss: 6143.1128\n",
            "Epoch [8880], val_loss: 6143.1138\n",
            "Epoch [8900], val_loss: 6143.0889\n",
            "Epoch [8920], val_loss: 6143.0815\n",
            "Epoch [8940], val_loss: 6143.0688\n",
            "Epoch [8960], val_loss: 6143.0649\n",
            "Epoch [8980], val_loss: 6143.0527\n",
            "Epoch [9000], val_loss: 6143.0293\n",
            "Epoch [9020], val_loss: 6143.0444\n",
            "Epoch [9040], val_loss: 6143.0464\n",
            "Epoch [9060], val_loss: 6143.0215\n",
            "Epoch [9080], val_loss: 6143.0054\n",
            "Epoch [9100], val_loss: 6143.0103\n",
            "Epoch [9120], val_loss: 6142.9961\n",
            "Epoch [9140], val_loss: 6142.9897\n",
            "Epoch [9160], val_loss: 6142.9600\n",
            "Epoch [9180], val_loss: 6142.9653\n",
            "Epoch [9200], val_loss: 6142.9746\n",
            "Epoch [9220], val_loss: 6142.9531\n",
            "Epoch [9240], val_loss: 6142.9385\n",
            "Epoch [9260], val_loss: 6142.9189\n",
            "Epoch [9280], val_loss: 6142.9243\n",
            "Epoch [9300], val_loss: 6142.9199\n",
            "Epoch [9320], val_loss: 6142.8984\n",
            "Epoch [9340], val_loss: 6142.8906\n",
            "Epoch [9360], val_loss: 6142.8887\n",
            "Epoch [9380], val_loss: 6142.8843\n",
            "Epoch [9400], val_loss: 6142.8711\n",
            "Epoch [9420], val_loss: 6142.8589\n",
            "Epoch [9440], val_loss: 6142.8521\n",
            "Epoch [9460], val_loss: 6142.8564\n",
            "Epoch [9480], val_loss: 6142.8271\n",
            "Epoch [9500], val_loss: 6142.8208\n",
            "Epoch [9520], val_loss: 6142.8179\n",
            "Epoch [9540], val_loss: 6142.8203\n",
            "Epoch [9560], val_loss: 6142.7920\n",
            "Epoch [9580], val_loss: 6142.7915\n",
            "Epoch [9600], val_loss: 6142.7920\n",
            "Epoch [9620], val_loss: 6142.7681\n",
            "Epoch [9640], val_loss: 6142.7681\n",
            "Epoch [9660], val_loss: 6142.7559\n",
            "Epoch [9680], val_loss: 6142.7632\n",
            "Epoch [9700], val_loss: 6142.7510\n",
            "Epoch [9720], val_loss: 6142.7266\n",
            "Epoch [9740], val_loss: 6142.7168\n",
            "Epoch [9760], val_loss: 6142.7100\n",
            "Epoch [9780], val_loss: 6142.7070\n",
            "Epoch [9800], val_loss: 6142.6904\n",
            "Epoch [9820], val_loss: 6142.6631\n",
            "Epoch [9840], val_loss: 6142.6768\n",
            "Epoch [9860], val_loss: 6142.6792\n",
            "Epoch [9880], val_loss: 6142.6875\n",
            "Epoch [9900], val_loss: 6142.6694\n",
            "Epoch [9920], val_loss: 6142.6421\n",
            "Epoch [9940], val_loss: 6142.6416\n",
            "Epoch [9960], val_loss: 6142.6191\n",
            "Epoch [9980], val_loss: 6142.6006\n",
            "Epoch [10000], val_loss: 6142.6133\n",
            "Epoch [10020], val_loss: 6142.6045\n",
            "Epoch [10040], val_loss: 6142.5933\n",
            "Epoch [10060], val_loss: 6142.5732\n",
            "Epoch [10080], val_loss: 6142.5674\n",
            "Epoch [10100], val_loss: 6142.5620\n",
            "Epoch [10120], val_loss: 6142.5449\n",
            "Epoch [10140], val_loss: 6142.5356\n",
            "Epoch [10160], val_loss: 6142.5547\n",
            "Epoch [10180], val_loss: 6142.5332\n",
            "Epoch [10200], val_loss: 6142.5259\n",
            "Epoch [10220], val_loss: 6142.5215\n",
            "Epoch [10240], val_loss: 6142.4985\n",
            "Epoch [10260], val_loss: 6142.4971\n",
            "Epoch [10280], val_loss: 6142.4785\n",
            "Epoch [10300], val_loss: 6142.4751\n",
            "Epoch [10320], val_loss: 6142.4702\n",
            "Epoch [10340], val_loss: 6142.4492\n",
            "Epoch [10360], val_loss: 6142.4678\n",
            "Epoch [10380], val_loss: 6142.4551\n",
            "Epoch [10400], val_loss: 6142.4321\n",
            "Epoch [10420], val_loss: 6142.4482\n",
            "Epoch [10440], val_loss: 6142.4263\n",
            "Epoch [10460], val_loss: 6142.4136\n",
            "Epoch [10480], val_loss: 6142.4092\n",
            "Epoch [10500], val_loss: 6142.3955\n",
            "Epoch [10520], val_loss: 6142.3672\n",
            "Epoch [10540], val_loss: 6142.3770\n",
            "Epoch [10560], val_loss: 6142.3584\n",
            "Epoch [10580], val_loss: 6142.3711\n",
            "Epoch [10600], val_loss: 6142.3608\n",
            "Epoch [10620], val_loss: 6142.3506\n",
            "Epoch [10640], val_loss: 6142.3350\n",
            "Epoch [10660], val_loss: 6142.3184\n",
            "Epoch [10680], val_loss: 6142.3110\n",
            "Epoch [10700], val_loss: 6142.2979\n",
            "Epoch [10720], val_loss: 6142.3066\n",
            "Epoch [10740], val_loss: 6142.2959\n",
            "Epoch [10760], val_loss: 6142.2734\n",
            "Epoch [10780], val_loss: 6142.2734\n",
            "Epoch [10800], val_loss: 6142.2534\n",
            "Epoch [10820], val_loss: 6142.2334\n",
            "Epoch [10840], val_loss: 6142.2305\n",
            "Epoch [10860], val_loss: 6142.2256\n",
            "Epoch [10880], val_loss: 6142.2314\n",
            "Epoch [10900], val_loss: 6142.2334\n",
            "Epoch [10920], val_loss: 6142.2012\n",
            "Epoch [10940], val_loss: 6142.1924\n",
            "Epoch [10960], val_loss: 6142.2036\n",
            "Epoch [10980], val_loss: 6142.1875\n",
            "Epoch [11000], val_loss: 6142.1880\n",
            "Epoch [11020], val_loss: 6142.1543\n",
            "Epoch [11040], val_loss: 6142.1636\n",
            "Epoch [11060], val_loss: 6142.1621\n",
            "Epoch [11080], val_loss: 6142.1396\n",
            "Epoch [11100], val_loss: 6142.1328\n",
            "Epoch [11120], val_loss: 6142.1377\n",
            "Epoch [11140], val_loss: 6142.1113\n",
            "Epoch [11160], val_loss: 6142.1011\n",
            "Epoch [11180], val_loss: 6142.1006\n",
            "Epoch [11200], val_loss: 6142.0957\n",
            "Epoch [11220], val_loss: 6142.0781\n",
            "Epoch [11240], val_loss: 6142.0674\n",
            "Epoch [11260], val_loss: 6142.0762\n",
            "Epoch [11280], val_loss: 6142.0537\n",
            "Epoch [11300], val_loss: 6142.0508\n",
            "Epoch [11320], val_loss: 6142.0405\n",
            "Epoch [11340], val_loss: 6142.0229\n",
            "Epoch [11360], val_loss: 6142.0205\n",
            "Epoch [11380], val_loss: 6142.0127\n",
            "Epoch [11400], val_loss: 6142.0068\n",
            "Epoch [11420], val_loss: 6142.0068\n",
            "Epoch [11440], val_loss: 6141.9810\n",
            "Epoch [11460], val_loss: 6141.9863\n",
            "Epoch [11480], val_loss: 6141.9707\n",
            "Epoch [11500], val_loss: 6141.9678\n",
            "Epoch [11520], val_loss: 6141.9512\n",
            "Epoch [11540], val_loss: 6141.9434\n",
            "Epoch [11560], val_loss: 6141.9482\n",
            "Epoch [11580], val_loss: 6141.9395\n",
            "Epoch [11600], val_loss: 6141.9121\n",
            "Epoch [11620], val_loss: 6141.9048\n",
            "Epoch [11640], val_loss: 6141.8975\n",
            "Epoch [11660], val_loss: 6141.8892\n",
            "Epoch [11680], val_loss: 6141.8901\n",
            "Epoch [11700], val_loss: 6141.8667\n",
            "Epoch [11720], val_loss: 6141.8730\n",
            "Epoch [11740], val_loss: 6141.8613\n",
            "Epoch [11760], val_loss: 6141.8330\n",
            "Epoch [11780], val_loss: 6141.8472\n",
            "Epoch [11800], val_loss: 6141.8350\n",
            "Epoch [11820], val_loss: 6141.8281\n",
            "Epoch [11840], val_loss: 6141.8271\n",
            "Epoch [11860], val_loss: 6141.8164\n",
            "Epoch [11880], val_loss: 6141.8018\n",
            "Epoch [11900], val_loss: 6141.7910\n",
            "Epoch [11920], val_loss: 6141.7861\n",
            "Epoch [11940], val_loss: 6141.7734\n",
            "Epoch [11960], val_loss: 6141.7671\n",
            "Epoch [11980], val_loss: 6141.7607\n",
            "Epoch [12000], val_loss: 6141.7529\n",
            "Epoch [12020], val_loss: 6141.7441\n",
            "Epoch [12040], val_loss: 6141.7354\n",
            "Epoch [12060], val_loss: 6141.7236\n",
            "Epoch [12080], val_loss: 6141.7178\n",
            "Epoch [12100], val_loss: 6141.6865\n",
            "Epoch [12120], val_loss: 6141.6885\n",
            "Epoch [12140], val_loss: 6141.6846\n",
            "Epoch [12160], val_loss: 6141.6875\n",
            "Epoch [12180], val_loss: 6141.6855\n",
            "Epoch [12200], val_loss: 6141.6582\n",
            "Epoch [12220], val_loss: 6141.6528\n",
            "Epoch [12240], val_loss: 6141.6445\n",
            "Epoch [12260], val_loss: 6141.6270\n",
            "Epoch [12280], val_loss: 6141.6221\n",
            "Epoch [12300], val_loss: 6141.6406\n",
            "Epoch [12320], val_loss: 6141.5991\n",
            "Epoch [12340], val_loss: 6141.5957\n",
            "Epoch [12360], val_loss: 6141.5859\n",
            "Epoch [12380], val_loss: 6141.5679\n",
            "Epoch [12400], val_loss: 6141.5752\n",
            "Epoch [12420], val_loss: 6141.5771\n",
            "Epoch [12440], val_loss: 6141.5674\n",
            "Epoch [12460], val_loss: 6141.5479\n",
            "Epoch [12480], val_loss: 6141.5317\n",
            "Epoch [12500], val_loss: 6141.5317\n",
            "Epoch [12520], val_loss: 6141.5127\n",
            "Epoch [12540], val_loss: 6141.4990\n",
            "Epoch [12560], val_loss: 6141.5059\n",
            "Epoch [12580], val_loss: 6141.5044\n",
            "Epoch [12600], val_loss: 6141.4971\n",
            "Epoch [12620], val_loss: 6141.4678\n",
            "Epoch [12640], val_loss: 6141.4727\n",
            "Epoch [12660], val_loss: 6141.4551\n",
            "Epoch [12680], val_loss: 6141.4434\n",
            "Epoch [12700], val_loss: 6141.4248\n",
            "Epoch [12720], val_loss: 6141.4355\n",
            "Epoch [12740], val_loss: 6141.4258\n",
            "Epoch [12760], val_loss: 6141.4170\n",
            "Epoch [12780], val_loss: 6141.4111\n",
            "Epoch [12800], val_loss: 6141.3896\n",
            "Epoch [12820], val_loss: 6141.3809\n",
            "Epoch [12840], val_loss: 6141.3804\n",
            "Epoch [12860], val_loss: 6141.3721\n",
            "Epoch [12880], val_loss: 6141.3750\n",
            "Epoch [12900], val_loss: 6141.3525\n",
            "Epoch [12920], val_loss: 6141.3408\n",
            "Epoch [12940], val_loss: 6141.3516\n",
            "Epoch [12960], val_loss: 6141.3291\n",
            "Epoch [12980], val_loss: 6141.3218\n",
            "Epoch [13000], val_loss: 6141.3154\n",
            "Epoch [13020], val_loss: 6141.3135\n",
            "Epoch [13040], val_loss: 6141.2852\n",
            "Epoch [13060], val_loss: 6141.2793\n",
            "Epoch [13080], val_loss: 6141.2603\n",
            "Epoch [13100], val_loss: 6141.2666\n",
            "Epoch [13120], val_loss: 6141.2617\n",
            "Epoch [13140], val_loss: 6141.2627\n",
            "Epoch [13160], val_loss: 6141.2500\n",
            "Epoch [13180], val_loss: 6141.2461\n",
            "Epoch [13200], val_loss: 6141.2490\n",
            "Epoch [13220], val_loss: 6141.2275\n",
            "Epoch [13240], val_loss: 6141.2002\n",
            "Epoch [13260], val_loss: 6141.2119\n",
            "Epoch [13280], val_loss: 6141.1899\n",
            "Epoch [13300], val_loss: 6141.1924\n",
            "Epoch [13320], val_loss: 6141.1816\n",
            "Epoch [13340], val_loss: 6141.1865\n",
            "Epoch [13360], val_loss: 6141.1768\n",
            "Epoch [13380], val_loss: 6141.1582\n",
            "Epoch [13400], val_loss: 6141.1387\n",
            "Epoch [13420], val_loss: 6141.1396\n",
            "Epoch [13440], val_loss: 6141.1299\n",
            "Epoch [13460], val_loss: 6141.1279\n",
            "Epoch [13480], val_loss: 6141.1260\n",
            "Epoch [13500], val_loss: 6141.1094\n",
            "Epoch [13520], val_loss: 6141.0996\n",
            "Epoch [13540], val_loss: 6141.1064\n",
            "Epoch [13560], val_loss: 6141.0918\n",
            "Epoch [13580], val_loss: 6141.0786\n",
            "Epoch [13600], val_loss: 6141.0566\n",
            "Epoch [13620], val_loss: 6141.0527\n",
            "Epoch [13640], val_loss: 6141.0298\n",
            "Epoch [13660], val_loss: 6141.0391\n",
            "Epoch [13680], val_loss: 6141.0078\n",
            "Epoch [13700], val_loss: 6141.0176\n",
            "Epoch [13720], val_loss: 6141.0034\n",
            "Epoch [13740], val_loss: 6141.0015\n",
            "Epoch [13760], val_loss: 6140.9893\n",
            "Epoch [13780], val_loss: 6140.9932\n",
            "Epoch [13800], val_loss: 6140.9854\n",
            "Epoch [13820], val_loss: 6140.9756\n",
            "Epoch [13840], val_loss: 6140.9634\n",
            "Epoch [13860], val_loss: 6140.9766\n",
            "Epoch [13880], val_loss: 6140.9404\n",
            "Epoch [13900], val_loss: 6140.9365\n",
            "Epoch [13920], val_loss: 6140.9238\n",
            "Epoch [13940], val_loss: 6140.9092\n",
            "Epoch [13960], val_loss: 6140.8965\n",
            "Epoch [13980], val_loss: 6140.8994\n",
            "Epoch [14000], val_loss: 6140.8936\n",
            "Epoch [14020], val_loss: 6140.8931\n",
            "Epoch [14040], val_loss: 6140.8809\n",
            "Epoch [14060], val_loss: 6140.8804\n",
            "Epoch [14080], val_loss: 6140.8740\n",
            "Epoch [14100], val_loss: 6140.8545\n",
            "Epoch [14120], val_loss: 6140.8330\n",
            "Epoch [14140], val_loss: 6140.8369\n",
            "Epoch [14160], val_loss: 6140.8218\n",
            "Epoch [14180], val_loss: 6140.8076\n",
            "Epoch [14200], val_loss: 6140.8013\n",
            "Epoch [14220], val_loss: 6140.8125\n",
            "Epoch [14240], val_loss: 6140.8008\n",
            "Epoch [14260], val_loss: 6140.7930\n",
            "Epoch [14280], val_loss: 6140.7734\n",
            "Epoch [14300], val_loss: 6140.7837\n",
            "Epoch [14320], val_loss: 6140.7593\n",
            "Epoch [14340], val_loss: 6140.7559\n",
            "Epoch [14360], val_loss: 6140.7363\n",
            "Epoch [14380], val_loss: 6140.7134\n",
            "Epoch [14400], val_loss: 6140.7090\n",
            "Epoch [14420], val_loss: 6140.7100\n",
            "Epoch [14440], val_loss: 6140.7012\n",
            "Epoch [14460], val_loss: 6140.7148\n",
            "Epoch [14480], val_loss: 6140.6826\n",
            "Epoch [14500], val_loss: 6140.6797\n",
            "Epoch [14520], val_loss: 6140.6729\n",
            "Epoch [14540], val_loss: 6140.6631\n",
            "Epoch [14560], val_loss: 6140.6509\n",
            "Epoch [14580], val_loss: 6140.6372\n",
            "Epoch [14600], val_loss: 6140.6401\n",
            "Epoch [14620], val_loss: 6140.6309\n",
            "Epoch [14640], val_loss: 6140.6021\n",
            "Epoch [14660], val_loss: 6140.6099\n",
            "Epoch [14680], val_loss: 6140.6055\n",
            "Epoch [14700], val_loss: 6140.6001\n",
            "Epoch [14720], val_loss: 6140.5898\n",
            "Epoch [14740], val_loss: 6140.5771\n",
            "Epoch [14760], val_loss: 6140.5605\n",
            "Epoch [14780], val_loss: 6140.5664\n",
            "Epoch [14800], val_loss: 6140.5674\n",
            "Epoch [14820], val_loss: 6140.5381\n",
            "Epoch [14840], val_loss: 6140.5537\n",
            "Epoch [14860], val_loss: 6140.5225\n",
            "Epoch [14880], val_loss: 6140.5244\n",
            "Epoch [14900], val_loss: 6140.5215\n",
            "Epoch [14920], val_loss: 6140.5234\n",
            "Epoch [14940], val_loss: 6140.4863\n",
            "Epoch [14960], val_loss: 6140.4927\n",
            "Epoch [14980], val_loss: 6140.4814\n",
            "Epoch [15000], val_loss: 6140.4717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUiGFm-r1iRm",
        "outputId": "4e7e7f7e-c023-44c3-c1a6-40fb009a7774"
      },
      "source": [
        "epochs = 15000\n",
        "lr = 1e-2\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [4760], val_loss: 6120.6328\n",
            "Epoch [4780], val_loss: 6120.7114\n",
            "Epoch [4800], val_loss: 6120.7373\n",
            "Epoch [4820], val_loss: 6120.5439\n",
            "Epoch [4840], val_loss: 6120.5752\n",
            "Epoch [4860], val_loss: 6120.4043\n",
            "Epoch [4880], val_loss: 6120.2681\n",
            "Epoch [4900], val_loss: 6120.2539\n",
            "Epoch [4920], val_loss: 6120.2051\n",
            "Epoch [4940], val_loss: 6120.0957\n",
            "Epoch [4960], val_loss: 6120.0264\n",
            "Epoch [4980], val_loss: 6120.0098\n",
            "Epoch [5000], val_loss: 6119.8477\n",
            "Epoch [5020], val_loss: 6119.6357\n",
            "Epoch [5040], val_loss: 6119.5830\n",
            "Epoch [5060], val_loss: 6119.5396\n",
            "Epoch [5080], val_loss: 6119.5273\n",
            "Epoch [5100], val_loss: 6119.3159\n",
            "Epoch [5120], val_loss: 6119.3159\n",
            "Epoch [5140], val_loss: 6119.0669\n",
            "Epoch [5160], val_loss: 6119.1426\n",
            "Epoch [5180], val_loss: 6119.0391\n",
            "Epoch [5200], val_loss: 6118.9736\n",
            "Epoch [5220], val_loss: 6118.9189\n",
            "Epoch [5240], val_loss: 6118.8716\n",
            "Epoch [5260], val_loss: 6118.6758\n",
            "Epoch [5280], val_loss: 6118.6621\n",
            "Epoch [5300], val_loss: 6118.5254\n",
            "Epoch [5320], val_loss: 6118.5229\n",
            "Epoch [5340], val_loss: 6118.4121\n",
            "Epoch [5360], val_loss: 6118.1909\n",
            "Epoch [5380], val_loss: 6118.2227\n",
            "Epoch [5400], val_loss: 6118.1294\n",
            "Epoch [5420], val_loss: 6117.9912\n",
            "Epoch [5440], val_loss: 6117.9424\n",
            "Epoch [5460], val_loss: 6117.8345\n",
            "Epoch [5480], val_loss: 6117.8569\n",
            "Epoch [5500], val_loss: 6117.6494\n",
            "Epoch [5520], val_loss: 6117.6279\n",
            "Epoch [5540], val_loss: 6117.5557\n",
            "Epoch [5560], val_loss: 6117.4766\n",
            "Epoch [5580], val_loss: 6117.3955\n",
            "Epoch [5600], val_loss: 6117.5078\n",
            "Epoch [5620], val_loss: 6117.3237\n",
            "Epoch [5640], val_loss: 6117.1567\n",
            "Epoch [5660], val_loss: 6117.0425\n",
            "Epoch [5680], val_loss: 6116.9912\n",
            "Epoch [5700], val_loss: 6117.1230\n",
            "Epoch [5720], val_loss: 6116.9424\n",
            "Epoch [5740], val_loss: 6116.8569\n",
            "Epoch [5760], val_loss: 6116.7715\n",
            "Epoch [5780], val_loss: 6116.4863\n",
            "Epoch [5800], val_loss: 6116.4707\n",
            "Epoch [5820], val_loss: 6116.2852\n",
            "Epoch [5840], val_loss: 6116.3945\n",
            "Epoch [5860], val_loss: 6116.2070\n",
            "Epoch [5880], val_loss: 6116.2720\n",
            "Epoch [5900], val_loss: 6116.0664\n",
            "Epoch [5920], val_loss: 6116.0830\n",
            "Epoch [5940], val_loss: 6115.9702\n",
            "Epoch [5960], val_loss: 6115.8003\n",
            "Epoch [5980], val_loss: 6115.6904\n",
            "Epoch [6000], val_loss: 6115.6523\n",
            "Epoch [6020], val_loss: 6115.5869\n",
            "Epoch [6040], val_loss: 6115.3623\n",
            "Epoch [6060], val_loss: 6115.3184\n",
            "Epoch [6080], val_loss: 6115.3267\n",
            "Epoch [6100], val_loss: 6115.4019\n",
            "Epoch [6120], val_loss: 6115.1670\n",
            "Epoch [6140], val_loss: 6115.1260\n",
            "Epoch [6160], val_loss: 6114.9702\n",
            "Epoch [6180], val_loss: 6114.8760\n",
            "Epoch [6200], val_loss: 6115.0039\n",
            "Epoch [6220], val_loss: 6114.6797\n",
            "Epoch [6240], val_loss: 6114.6973\n",
            "Epoch [6260], val_loss: 6114.5840\n",
            "Epoch [6280], val_loss: 6114.4678\n",
            "Epoch [6300], val_loss: 6114.4141\n",
            "Epoch [6320], val_loss: 6114.4229\n",
            "Epoch [6340], val_loss: 6114.4170\n",
            "Epoch [6360], val_loss: 6114.2012\n",
            "Epoch [6380], val_loss: 6114.1553\n",
            "Epoch [6400], val_loss: 6113.9961\n",
            "Epoch [6420], val_loss: 6113.8374\n",
            "Epoch [6440], val_loss: 6113.9336\n",
            "Epoch [6460], val_loss: 6113.8076\n",
            "Epoch [6480], val_loss: 6113.7041\n",
            "Epoch [6500], val_loss: 6113.5996\n",
            "Epoch [6520], val_loss: 6113.5254\n",
            "Epoch [6540], val_loss: 6113.3330\n",
            "Epoch [6560], val_loss: 6113.4219\n",
            "Epoch [6580], val_loss: 6113.2832\n",
            "Epoch [6600], val_loss: 6113.2778\n",
            "Epoch [6620], val_loss: 6113.1304\n",
            "Epoch [6640], val_loss: 6112.9600\n",
            "Epoch [6660], val_loss: 6112.9541\n",
            "Epoch [6680], val_loss: 6112.9297\n",
            "Epoch [6700], val_loss: 6112.7603\n",
            "Epoch [6720], val_loss: 6112.8047\n",
            "Epoch [6740], val_loss: 6112.5605\n",
            "Epoch [6760], val_loss: 6112.5371\n",
            "Epoch [6780], val_loss: 6112.2754\n",
            "Epoch [6800], val_loss: 6112.2915\n",
            "Epoch [6820], val_loss: 6112.1914\n",
            "Epoch [6840], val_loss: 6112.2324\n",
            "Epoch [6860], val_loss: 6112.0259\n",
            "Epoch [6880], val_loss: 6111.9316\n",
            "Epoch [6900], val_loss: 6111.8848\n",
            "Epoch [6920], val_loss: 6111.9126\n",
            "Epoch [6940], val_loss: 6111.7529\n",
            "Epoch [6960], val_loss: 6111.7866\n",
            "Epoch [6980], val_loss: 6111.6631\n",
            "Epoch [7000], val_loss: 6111.4395\n",
            "Epoch [7020], val_loss: 6111.3413\n",
            "Epoch [7040], val_loss: 6111.3223\n",
            "Epoch [7060], val_loss: 6111.2349\n",
            "Epoch [7080], val_loss: 6111.1602\n",
            "Epoch [7100], val_loss: 6111.1318\n",
            "Epoch [7120], val_loss: 6111.0947\n",
            "Epoch [7140], val_loss: 6110.7891\n",
            "Epoch [7160], val_loss: 6110.8291\n",
            "Epoch [7180], val_loss: 6110.7832\n",
            "Epoch [7200], val_loss: 6110.6973\n",
            "Epoch [7220], val_loss: 6110.5493\n",
            "Epoch [7240], val_loss: 6110.5425\n",
            "Epoch [7260], val_loss: 6110.4580\n",
            "Epoch [7280], val_loss: 6110.4639\n",
            "Epoch [7300], val_loss: 6110.4214\n",
            "Epoch [7320], val_loss: 6110.2070\n",
            "Epoch [7340], val_loss: 6110.0615\n",
            "Epoch [7360], val_loss: 6110.0415\n",
            "Epoch [7380], val_loss: 6110.0728\n",
            "Epoch [7400], val_loss: 6109.9170\n",
            "Epoch [7420], val_loss: 6109.6602\n",
            "Epoch [7440], val_loss: 6109.6182\n",
            "Epoch [7460], val_loss: 6109.6621\n",
            "Epoch [7480], val_loss: 6109.5527\n",
            "Epoch [7500], val_loss: 6109.4912\n",
            "Epoch [7520], val_loss: 6109.3555\n",
            "Epoch [7540], val_loss: 6109.3486\n",
            "Epoch [7560], val_loss: 6109.1484\n",
            "Epoch [7580], val_loss: 6109.0479\n",
            "Epoch [7600], val_loss: 6109.0303\n",
            "Epoch [7620], val_loss: 6108.9375\n",
            "Epoch [7640], val_loss: 6108.7227\n",
            "Epoch [7660], val_loss: 6108.8193\n",
            "Epoch [7680], val_loss: 6108.6909\n",
            "Epoch [7700], val_loss: 6108.6577\n",
            "Epoch [7720], val_loss: 6108.6895\n",
            "Epoch [7740], val_loss: 6108.3823\n",
            "Epoch [7760], val_loss: 6108.5225\n",
            "Epoch [7780], val_loss: 6108.4082\n",
            "Epoch [7800], val_loss: 6108.2974\n",
            "Epoch [7820], val_loss: 6108.2217\n",
            "Epoch [7840], val_loss: 6108.0205\n",
            "Epoch [7860], val_loss: 6108.0122\n",
            "Epoch [7880], val_loss: 6107.9717\n",
            "Epoch [7900], val_loss: 6107.8174\n",
            "Epoch [7920], val_loss: 6107.7510\n",
            "Epoch [7940], val_loss: 6107.7842\n",
            "Epoch [7960], val_loss: 6107.6099\n",
            "Epoch [7980], val_loss: 6107.4707\n",
            "Epoch [8000], val_loss: 6107.4590\n",
            "Epoch [8020], val_loss: 6107.3652\n",
            "Epoch [8040], val_loss: 6107.3652\n",
            "Epoch [8060], val_loss: 6107.2993\n",
            "Epoch [8080], val_loss: 6107.0244\n",
            "Epoch [8100], val_loss: 6106.9131\n",
            "Epoch [8120], val_loss: 6106.9307\n",
            "Epoch [8140], val_loss: 6106.9004\n",
            "Epoch [8160], val_loss: 6106.7935\n",
            "Epoch [8180], val_loss: 6106.6172\n",
            "Epoch [8200], val_loss: 6106.5596\n",
            "Epoch [8220], val_loss: 6106.5273\n",
            "Epoch [8240], val_loss: 6106.3691\n",
            "Epoch [8260], val_loss: 6106.2324\n",
            "Epoch [8280], val_loss: 6106.2671\n",
            "Epoch [8300], val_loss: 6106.1895\n",
            "Epoch [8320], val_loss: 6106.0410\n",
            "Epoch [8340], val_loss: 6106.0420\n",
            "Epoch [8360], val_loss: 6105.7861\n",
            "Epoch [8380], val_loss: 6106.0859\n",
            "Epoch [8400], val_loss: 6105.9072\n",
            "Epoch [8420], val_loss: 6105.6338\n",
            "Epoch [8440], val_loss: 6105.5796\n",
            "Epoch [8460], val_loss: 6105.6123\n",
            "Epoch [8480], val_loss: 6105.5020\n",
            "Epoch [8500], val_loss: 6105.4424\n",
            "Epoch [8520], val_loss: 6105.2344\n",
            "Epoch [8540], val_loss: 6105.2656\n",
            "Epoch [8560], val_loss: 6105.0928\n",
            "Epoch [8580], val_loss: 6105.0859\n",
            "Epoch [8600], val_loss: 6104.9385\n",
            "Epoch [8620], val_loss: 6104.8003\n",
            "Epoch [8640], val_loss: 6104.7456\n",
            "Epoch [8660], val_loss: 6104.6626\n",
            "Epoch [8680], val_loss: 6104.6074\n",
            "Epoch [8700], val_loss: 6104.4722\n",
            "Epoch [8720], val_loss: 6104.3975\n",
            "Epoch [8740], val_loss: 6104.4238\n",
            "Epoch [8760], val_loss: 6104.3164\n",
            "Epoch [8780], val_loss: 6104.2285\n",
            "Epoch [8800], val_loss: 6104.1357\n",
            "Epoch [8820], val_loss: 6104.1338\n",
            "Epoch [8840], val_loss: 6104.0264\n",
            "Epoch [8860], val_loss: 6103.9341\n",
            "Epoch [8880], val_loss: 6103.9219\n",
            "Epoch [8900], val_loss: 6103.6191\n",
            "Epoch [8920], val_loss: 6103.4849\n",
            "Epoch [8940], val_loss: 6103.4360\n",
            "Epoch [8960], val_loss: 6103.3936\n",
            "Epoch [8980], val_loss: 6103.3691\n",
            "Epoch [9000], val_loss: 6103.2871\n",
            "Epoch [9020], val_loss: 6103.1289\n",
            "Epoch [9040], val_loss: 6103.1826\n",
            "Epoch [9060], val_loss: 6103.0024\n",
            "Epoch [9080], val_loss: 6102.9619\n",
            "Epoch [9100], val_loss: 6102.8970\n",
            "Epoch [9120], val_loss: 6102.6953\n",
            "Epoch [9140], val_loss: 6102.8032\n",
            "Epoch [9160], val_loss: 6102.6348\n",
            "Epoch [9180], val_loss: 6102.5967\n",
            "Epoch [9200], val_loss: 6102.6680\n",
            "Epoch [9220], val_loss: 6102.4854\n",
            "Epoch [9240], val_loss: 6102.2969\n",
            "Epoch [9260], val_loss: 6102.2549\n",
            "Epoch [9280], val_loss: 6102.2207\n",
            "Epoch [9300], val_loss: 6102.0801\n",
            "Epoch [9320], val_loss: 6101.9854\n",
            "Epoch [9340], val_loss: 6101.8975\n",
            "Epoch [9360], val_loss: 6101.9575\n",
            "Epoch [9380], val_loss: 6101.8154\n",
            "Epoch [9400], val_loss: 6101.5142\n",
            "Epoch [9420], val_loss: 6101.5996\n",
            "Epoch [9440], val_loss: 6101.4707\n",
            "Epoch [9460], val_loss: 6101.2676\n",
            "Epoch [9480], val_loss: 6101.2949\n",
            "Epoch [9500], val_loss: 6101.3374\n",
            "Epoch [9520], val_loss: 6101.2979\n",
            "Epoch [9540], val_loss: 6100.9531\n",
            "Epoch [9560], val_loss: 6100.9858\n",
            "Epoch [9580], val_loss: 6100.9302\n",
            "Epoch [9600], val_loss: 6100.8633\n",
            "Epoch [9620], val_loss: 6100.7495\n",
            "Epoch [9640], val_loss: 6100.6982\n",
            "Epoch [9660], val_loss: 6100.5723\n",
            "Epoch [9680], val_loss: 6100.4077\n",
            "Epoch [9700], val_loss: 6100.3506\n",
            "Epoch [9720], val_loss: 6100.4619\n",
            "Epoch [9740], val_loss: 6100.2856\n",
            "Epoch [9760], val_loss: 6100.1650\n",
            "Epoch [9780], val_loss: 6100.0400\n",
            "Epoch [9800], val_loss: 6100.0400\n",
            "Epoch [9820], val_loss: 6099.9434\n",
            "Epoch [9840], val_loss: 6099.9229\n",
            "Epoch [9860], val_loss: 6099.7490\n",
            "Epoch [9880], val_loss: 6099.6133\n",
            "Epoch [9900], val_loss: 6099.5723\n",
            "Epoch [9920], val_loss: 6099.6045\n",
            "Epoch [9940], val_loss: 6099.3921\n",
            "Epoch [9960], val_loss: 6099.3457\n",
            "Epoch [9980], val_loss: 6099.3301\n",
            "Epoch [10000], val_loss: 6099.2617\n",
            "Epoch [10020], val_loss: 6099.1973\n",
            "Epoch [10040], val_loss: 6099.0322\n",
            "Epoch [10060], val_loss: 6098.8896\n",
            "Epoch [10080], val_loss: 6098.8550\n",
            "Epoch [10100], val_loss: 6098.7471\n",
            "Epoch [10120], val_loss: 6098.7441\n",
            "Epoch [10140], val_loss: 6098.6064\n",
            "Epoch [10160], val_loss: 6098.6348\n",
            "Epoch [10180], val_loss: 6098.4775\n",
            "Epoch [10200], val_loss: 6098.3115\n",
            "Epoch [10220], val_loss: 6098.1436\n",
            "Epoch [10240], val_loss: 6098.2051\n",
            "Epoch [10260], val_loss: 6098.0586\n",
            "Epoch [10280], val_loss: 6097.9243\n",
            "Epoch [10300], val_loss: 6097.8398\n",
            "Epoch [10320], val_loss: 6097.8662\n",
            "Epoch [10340], val_loss: 6097.8745\n",
            "Epoch [10360], val_loss: 6097.7534\n",
            "Epoch [10380], val_loss: 6097.6895\n",
            "Epoch [10400], val_loss: 6097.5356\n",
            "Epoch [10420], val_loss: 6097.6104\n",
            "Epoch [10440], val_loss: 6097.4199\n",
            "Epoch [10460], val_loss: 6097.3691\n",
            "Epoch [10480], val_loss: 6097.2002\n",
            "Epoch [10500], val_loss: 6097.1006\n",
            "Epoch [10520], val_loss: 6097.1885\n",
            "Epoch [10540], val_loss: 6096.8271\n",
            "Epoch [10560], val_loss: 6096.8359\n",
            "Epoch [10580], val_loss: 6096.8740\n",
            "Epoch [10600], val_loss: 6096.7251\n",
            "Epoch [10620], val_loss: 6096.5938\n",
            "Epoch [10640], val_loss: 6096.7817\n",
            "Epoch [10660], val_loss: 6096.4238\n",
            "Epoch [10680], val_loss: 6096.2964\n",
            "Epoch [10700], val_loss: 6096.3496\n",
            "Epoch [10720], val_loss: 6096.1035\n",
            "Epoch [10740], val_loss: 6096.0498\n",
            "Epoch [10760], val_loss: 6095.9424\n",
            "Epoch [10780], val_loss: 6096.1016\n",
            "Epoch [10800], val_loss: 6095.8877\n",
            "Epoch [10820], val_loss: 6095.8994\n",
            "Epoch [10840], val_loss: 6095.6777\n",
            "Epoch [10860], val_loss: 6095.6943\n",
            "Epoch [10880], val_loss: 6095.6455\n",
            "Epoch [10900], val_loss: 6095.5586\n",
            "Epoch [10920], val_loss: 6095.4058\n",
            "Epoch [10940], val_loss: 6095.4170\n",
            "Epoch [10960], val_loss: 6095.2031\n",
            "Epoch [10980], val_loss: 6095.1465\n",
            "Epoch [11000], val_loss: 6095.0537\n",
            "Epoch [11020], val_loss: 6095.0244\n",
            "Epoch [11040], val_loss: 6094.9746\n",
            "Epoch [11060], val_loss: 6094.9385\n",
            "Epoch [11080], val_loss: 6094.8262\n",
            "Epoch [11100], val_loss: 6094.8271\n",
            "Epoch [11120], val_loss: 6094.7383\n",
            "Epoch [11140], val_loss: 6094.4131\n",
            "Epoch [11160], val_loss: 6094.5566\n",
            "Epoch [11180], val_loss: 6094.4004\n",
            "Epoch [11200], val_loss: 6094.2212\n",
            "Epoch [11220], val_loss: 6094.2588\n",
            "Epoch [11240], val_loss: 6094.0894\n",
            "Epoch [11260], val_loss: 6094.0791\n",
            "Epoch [11280], val_loss: 6094.1338\n",
            "Epoch [11300], val_loss: 6093.9941\n",
            "Epoch [11320], val_loss: 6093.9570\n",
            "Epoch [11340], val_loss: 6093.6621\n",
            "Epoch [11360], val_loss: 6093.6426\n",
            "Epoch [11380], val_loss: 6093.7163\n",
            "Epoch [11400], val_loss: 6093.5547\n",
            "Epoch [11420], val_loss: 6093.4995\n",
            "Epoch [11440], val_loss: 6093.5059\n",
            "Epoch [11460], val_loss: 6093.4707\n",
            "Epoch [11480], val_loss: 6093.2065\n",
            "Epoch [11500], val_loss: 6093.0645\n",
            "Epoch [11520], val_loss: 6093.0449\n",
            "Epoch [11540], val_loss: 6093.0396\n",
            "Epoch [11560], val_loss: 6092.8467\n",
            "Epoch [11580], val_loss: 6092.7979\n",
            "Epoch [11600], val_loss: 6092.8735\n",
            "Epoch [11620], val_loss: 6092.6235\n",
            "Epoch [11640], val_loss: 6092.4795\n",
            "Epoch [11660], val_loss: 6092.4697\n",
            "Epoch [11680], val_loss: 6092.3779\n",
            "Epoch [11700], val_loss: 6092.2324\n",
            "Epoch [11720], val_loss: 6092.2339\n",
            "Epoch [11740], val_loss: 6092.1885\n",
            "Epoch [11760], val_loss: 6092.0176\n",
            "Epoch [11780], val_loss: 6091.8857\n",
            "Epoch [11800], val_loss: 6091.8350\n",
            "Epoch [11820], val_loss: 6091.7305\n",
            "Epoch [11840], val_loss: 6091.7432\n",
            "Epoch [11860], val_loss: 6091.6104\n",
            "Epoch [11880], val_loss: 6091.4824\n",
            "Epoch [11900], val_loss: 6091.5312\n",
            "Epoch [11920], val_loss: 6091.3105\n",
            "Epoch [11940], val_loss: 6091.2734\n",
            "Epoch [11960], val_loss: 6091.2236\n",
            "Epoch [11980], val_loss: 6091.1655\n",
            "Epoch [12000], val_loss: 6091.1787\n",
            "Epoch [12020], val_loss: 6090.9580\n",
            "Epoch [12040], val_loss: 6090.9111\n",
            "Epoch [12060], val_loss: 6090.7861\n",
            "Epoch [12080], val_loss: 6090.6279\n",
            "Epoch [12100], val_loss: 6090.5659\n",
            "Epoch [12120], val_loss: 6090.7524\n",
            "Epoch [12140], val_loss: 6090.4238\n",
            "Epoch [12160], val_loss: 6090.4048\n",
            "Epoch [12180], val_loss: 6090.4224\n",
            "Epoch [12200], val_loss: 6090.2983\n",
            "Epoch [12220], val_loss: 6090.2617\n",
            "Epoch [12240], val_loss: 6090.0576\n",
            "Epoch [12260], val_loss: 6090.1172\n",
            "Epoch [12280], val_loss: 6089.9580\n",
            "Epoch [12300], val_loss: 6089.7910\n",
            "Epoch [12320], val_loss: 6089.5762\n",
            "Epoch [12340], val_loss: 6089.6768\n",
            "Epoch [12360], val_loss: 6089.5146\n",
            "Epoch [12380], val_loss: 6089.5000\n",
            "Epoch [12400], val_loss: 6089.5273\n",
            "Epoch [12420], val_loss: 6089.4004\n",
            "Epoch [12440], val_loss: 6089.3721\n",
            "Epoch [12460], val_loss: 6089.2261\n",
            "Epoch [12480], val_loss: 6089.1006\n",
            "Epoch [12500], val_loss: 6089.0562\n",
            "Epoch [12520], val_loss: 6088.8594\n",
            "Epoch [12540], val_loss: 6088.9136\n",
            "Epoch [12560], val_loss: 6088.8623\n",
            "Epoch [12580], val_loss: 6088.6221\n",
            "Epoch [12600], val_loss: 6088.6426\n",
            "Epoch [12620], val_loss: 6088.5410\n",
            "Epoch [12640], val_loss: 6088.4917\n",
            "Epoch [12660], val_loss: 6088.5381\n",
            "Epoch [12680], val_loss: 6088.3809\n",
            "Epoch [12700], val_loss: 6088.2427\n",
            "Epoch [12720], val_loss: 6088.1890\n",
            "Epoch [12740], val_loss: 6088.0488\n",
            "Epoch [12760], val_loss: 6088.0669\n",
            "Epoch [12780], val_loss: 6088.0098\n",
            "Epoch [12800], val_loss: 6087.9102\n",
            "Epoch [12820], val_loss: 6087.6851\n",
            "Epoch [12840], val_loss: 6087.7773\n",
            "Epoch [12860], val_loss: 6087.7080\n",
            "Epoch [12880], val_loss: 6087.5005\n",
            "Epoch [12900], val_loss: 6087.4756\n",
            "Epoch [12920], val_loss: 6087.4629\n",
            "Epoch [12940], val_loss: 6087.3271\n",
            "Epoch [12960], val_loss: 6087.2168\n",
            "Epoch [12980], val_loss: 6087.1855\n",
            "Epoch [13000], val_loss: 6086.9951\n",
            "Epoch [13020], val_loss: 6086.9629\n",
            "Epoch [13040], val_loss: 6086.8936\n",
            "Epoch [13060], val_loss: 6086.8574\n",
            "Epoch [13080], val_loss: 6086.7686\n",
            "Epoch [13100], val_loss: 6086.7236\n",
            "Epoch [13120], val_loss: 6086.3252\n",
            "Epoch [13140], val_loss: 6086.4316\n",
            "Epoch [13160], val_loss: 6086.3877\n",
            "Epoch [13180], val_loss: 6086.2681\n",
            "Epoch [13200], val_loss: 6086.2144\n",
            "Epoch [13220], val_loss: 6086.0703\n",
            "Epoch [13240], val_loss: 6086.2520\n",
            "Epoch [13260], val_loss: 6085.9492\n",
            "Epoch [13280], val_loss: 6085.8379\n",
            "Epoch [13300], val_loss: 6085.7881\n",
            "Epoch [13320], val_loss: 6085.6221\n",
            "Epoch [13340], val_loss: 6085.4526\n",
            "Epoch [13360], val_loss: 6085.4814\n",
            "Epoch [13380], val_loss: 6085.4829\n",
            "Epoch [13400], val_loss: 6085.4785\n",
            "Epoch [13420], val_loss: 6085.3740\n",
            "Epoch [13440], val_loss: 6085.2700\n",
            "Epoch [13460], val_loss: 6085.1855\n",
            "Epoch [13480], val_loss: 6085.1123\n",
            "Epoch [13500], val_loss: 6085.0527\n",
            "Epoch [13520], val_loss: 6085.0205\n",
            "Epoch [13540], val_loss: 6084.8740\n",
            "Epoch [13560], val_loss: 6084.7217\n",
            "Epoch [13580], val_loss: 6084.5879\n",
            "Epoch [13600], val_loss: 6084.7217\n",
            "Epoch [13620], val_loss: 6084.3682\n",
            "Epoch [13640], val_loss: 6084.4180\n",
            "Epoch [13660], val_loss: 6084.3438\n",
            "Epoch [13680], val_loss: 6084.2529\n",
            "Epoch [13700], val_loss: 6084.2383\n",
            "Epoch [13720], val_loss: 6084.0264\n",
            "Epoch [13740], val_loss: 6083.9492\n",
            "Epoch [13760], val_loss: 6083.8604\n",
            "Epoch [13780], val_loss: 6083.7080\n",
            "Epoch [13800], val_loss: 6083.6338\n",
            "Epoch [13820], val_loss: 6083.6753\n",
            "Epoch [13840], val_loss: 6083.5518\n",
            "Epoch [13860], val_loss: 6083.5000\n",
            "Epoch [13880], val_loss: 6083.4893\n",
            "Epoch [13900], val_loss: 6083.3452\n",
            "Epoch [13920], val_loss: 6083.1211\n",
            "Epoch [13940], val_loss: 6083.2573\n",
            "Epoch [13960], val_loss: 6083.1484\n",
            "Epoch [13980], val_loss: 6083.1162\n",
            "Epoch [14000], val_loss: 6082.9751\n",
            "Epoch [14020], val_loss: 6082.9302\n",
            "Epoch [14040], val_loss: 6082.8984\n",
            "Epoch [14060], val_loss: 6082.7812\n",
            "Epoch [14080], val_loss: 6082.7363\n",
            "Epoch [14100], val_loss: 6082.6201\n",
            "Epoch [14120], val_loss: 6082.4683\n",
            "Epoch [14140], val_loss: 6082.4434\n",
            "Epoch [14160], val_loss: 6082.2627\n",
            "Epoch [14180], val_loss: 6082.4922\n",
            "Epoch [14200], val_loss: 6082.1289\n",
            "Epoch [14220], val_loss: 6082.0298\n",
            "Epoch [14240], val_loss: 6082.1094\n",
            "Epoch [14260], val_loss: 6081.9673\n",
            "Epoch [14280], val_loss: 6081.6748\n",
            "Epoch [14300], val_loss: 6081.8691\n",
            "Epoch [14320], val_loss: 6081.6270\n",
            "Epoch [14340], val_loss: 6081.6104\n",
            "Epoch [14360], val_loss: 6081.4385\n",
            "Epoch [14380], val_loss: 6081.5034\n",
            "Epoch [14400], val_loss: 6081.3311\n",
            "Epoch [14420], val_loss: 6081.3369\n",
            "Epoch [14440], val_loss: 6081.1719\n",
            "Epoch [14460], val_loss: 6080.9717\n",
            "Epoch [14480], val_loss: 6081.0811\n",
            "Epoch [14500], val_loss: 6080.9414\n",
            "Epoch [14520], val_loss: 6080.8442\n",
            "Epoch [14540], val_loss: 6080.6797\n",
            "Epoch [14560], val_loss: 6080.5107\n",
            "Epoch [14580], val_loss: 6080.5352\n",
            "Epoch [14600], val_loss: 6080.4629\n",
            "Epoch [14620], val_loss: 6080.4468\n",
            "Epoch [14640], val_loss: 6080.3779\n",
            "Epoch [14660], val_loss: 6080.3418\n",
            "Epoch [14680], val_loss: 6080.0791\n",
            "Epoch [14700], val_loss: 6080.0449\n",
            "Epoch [14720], val_loss: 6079.9580\n",
            "Epoch [14740], val_loss: 6079.8506\n",
            "Epoch [14760], val_loss: 6079.8999\n",
            "Epoch [14780], val_loss: 6079.7090\n",
            "Epoch [14800], val_loss: 6079.7617\n",
            "Epoch [14820], val_loss: 6079.5166\n",
            "Epoch [14840], val_loss: 6079.4868\n",
            "Epoch [14860], val_loss: 6079.5957\n",
            "Epoch [14880], val_loss: 6079.3184\n",
            "Epoch [14900], val_loss: 6079.3662\n",
            "Epoch [14920], val_loss: 6079.1758\n",
            "Epoch [14940], val_loss: 6079.0664\n",
            "Epoch [14960], val_loss: 6079.0439\n",
            "Epoch [14980], val_loss: 6078.9482\n",
            "Epoch [15000], val_loss: 6078.8823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va9dWoJW1iRm",
        "outputId": "13ee0de6-9d51-48e8-918b-ecb3a9fb01f7"
      },
      "source": [
        "epochs = 10000\n",
        "lr = 1e-1\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6077.2529\n",
            "Epoch [40], val_loss: 6079.9248\n",
            "Epoch [60], val_loss: 6074.3047\n",
            "Epoch [80], val_loss: 6076.2144\n",
            "Epoch [100], val_loss: 6074.0576\n",
            "Epoch [120], val_loss: 6073.5137\n",
            "Epoch [140], val_loss: 6070.6621\n",
            "Epoch [160], val_loss: 6072.7012\n",
            "Epoch [180], val_loss: 6069.3364\n",
            "Epoch [200], val_loss: 6072.1021\n",
            "Epoch [220], val_loss: 6069.4883\n",
            "Epoch [240], val_loss: 6068.7051\n",
            "Epoch [260], val_loss: 6066.1836\n",
            "Epoch [280], val_loss: 6069.3965\n",
            "Epoch [300], val_loss: 6066.2803\n",
            "Epoch [320], val_loss: 6064.1519\n",
            "Epoch [340], val_loss: 6066.7100\n",
            "Epoch [360], val_loss: 6062.8687\n",
            "Epoch [380], val_loss: 6062.4043\n",
            "Epoch [400], val_loss: 6062.5635\n",
            "Epoch [420], val_loss: 6061.0142\n",
            "Epoch [440], val_loss: 6059.1719\n",
            "Epoch [460], val_loss: 6057.2383\n",
            "Epoch [480], val_loss: 6058.9893\n",
            "Epoch [500], val_loss: 6055.6465\n",
            "Epoch [520], val_loss: 6056.9053\n",
            "Epoch [540], val_loss: 6058.1641\n",
            "Epoch [560], val_loss: 6055.4424\n",
            "Epoch [580], val_loss: 6054.1211\n",
            "Epoch [600], val_loss: 6055.2314\n",
            "Epoch [620], val_loss: 6053.4014\n",
            "Epoch [640], val_loss: 6050.6387\n",
            "Epoch [660], val_loss: 6052.0840\n",
            "Epoch [680], val_loss: 6049.9482\n",
            "Epoch [700], val_loss: 6050.9287\n",
            "Epoch [720], val_loss: 6049.9141\n",
            "Epoch [740], val_loss: 6049.2061\n",
            "Epoch [760], val_loss: 6048.8115\n",
            "Epoch [780], val_loss: 6046.8066\n",
            "Epoch [800], val_loss: 6045.7368\n",
            "Epoch [820], val_loss: 6045.3145\n",
            "Epoch [840], val_loss: 6043.5010\n",
            "Epoch [860], val_loss: 6044.4644\n",
            "Epoch [880], val_loss: 6043.0039\n",
            "Epoch [900], val_loss: 6040.3784\n",
            "Epoch [920], val_loss: 6041.1963\n",
            "Epoch [940], val_loss: 6040.5176\n",
            "Epoch [960], val_loss: 6037.8984\n",
            "Epoch [980], val_loss: 6038.9233\n",
            "Epoch [1000], val_loss: 6036.9487\n",
            "Epoch [1020], val_loss: 6035.4043\n",
            "Epoch [1040], val_loss: 6033.7783\n",
            "Epoch [1060], val_loss: 6035.0244\n",
            "Epoch [1080], val_loss: 6034.2715\n",
            "Epoch [1100], val_loss: 6033.9390\n",
            "Epoch [1120], val_loss: 6033.1108\n",
            "Epoch [1140], val_loss: 6030.9355\n",
            "Epoch [1160], val_loss: 6031.2031\n",
            "Epoch [1180], val_loss: 6031.2529\n",
            "Epoch [1200], val_loss: 6027.9419\n",
            "Epoch [1220], val_loss: 6027.8721\n",
            "Epoch [1240], val_loss: 6027.0083\n",
            "Epoch [1260], val_loss: 6026.9678\n",
            "Epoch [1280], val_loss: 6027.2070\n",
            "Epoch [1300], val_loss: 6024.3960\n",
            "Epoch [1320], val_loss: 6024.7563\n",
            "Epoch [1340], val_loss: 6022.6733\n",
            "Epoch [1360], val_loss: 6023.1953\n",
            "Epoch [1380], val_loss: 6019.4116\n",
            "Epoch [1400], val_loss: 6020.3403\n",
            "Epoch [1420], val_loss: 6020.3535\n",
            "Epoch [1440], val_loss: 6018.4375\n",
            "Epoch [1460], val_loss: 6018.7305\n",
            "Epoch [1480], val_loss: 6020.5762\n",
            "Epoch [1500], val_loss: 6015.5684\n",
            "Epoch [1520], val_loss: 6015.7563\n",
            "Epoch [1540], val_loss: 6017.1357\n",
            "Epoch [1560], val_loss: 6013.6084\n",
            "Epoch [1580], val_loss: 6012.7642\n",
            "Epoch [1600], val_loss: 6014.1895\n",
            "Epoch [1620], val_loss: 6012.6934\n",
            "Epoch [1640], val_loss: 6011.8291\n",
            "Epoch [1660], val_loss: 6010.0439\n",
            "Epoch [1680], val_loss: 6008.1377\n",
            "Epoch [1700], val_loss: 6009.1602\n",
            "Epoch [1720], val_loss: 6007.6704\n",
            "Epoch [1740], val_loss: 6006.2627\n",
            "Epoch [1760], val_loss: 6007.4985\n",
            "Epoch [1780], val_loss: 6007.8535\n",
            "Epoch [1800], val_loss: 6005.4863\n",
            "Epoch [1820], val_loss: 6003.9795\n",
            "Epoch [1840], val_loss: 6001.5332\n",
            "Epoch [1860], val_loss: 6001.3506\n",
            "Epoch [1880], val_loss: 6000.9248\n",
            "Epoch [1900], val_loss: 6002.2559\n",
            "Epoch [1920], val_loss: 6001.5674\n",
            "Epoch [1940], val_loss: 5997.1250\n",
            "Epoch [1960], val_loss: 5997.7886\n",
            "Epoch [1980], val_loss: 5998.6802\n",
            "Epoch [2000], val_loss: 5997.7192\n",
            "Epoch [2020], val_loss: 5996.2310\n",
            "Epoch [2040], val_loss: 5995.9238\n",
            "Epoch [2060], val_loss: 5995.0786\n",
            "Epoch [2080], val_loss: 5992.7466\n",
            "Epoch [2100], val_loss: 5992.3262\n",
            "Epoch [2120], val_loss: 5991.1904\n",
            "Epoch [2140], val_loss: 5991.2998\n",
            "Epoch [2160], val_loss: 5992.5488\n",
            "Epoch [2180], val_loss: 5987.9854\n",
            "Epoch [2200], val_loss: 5990.0767\n",
            "Epoch [2220], val_loss: 5987.7637\n",
            "Epoch [2240], val_loss: 5986.6646\n",
            "Epoch [2260], val_loss: 5985.4980\n",
            "Epoch [2280], val_loss: 5986.2378\n",
            "Epoch [2300], val_loss: 5985.1304\n",
            "Epoch [2320], val_loss: 5983.6709\n",
            "Epoch [2340], val_loss: 5981.2803\n",
            "Epoch [2360], val_loss: 5983.2744\n",
            "Epoch [2380], val_loss: 5980.8564\n",
            "Epoch [2400], val_loss: 5981.5679\n",
            "Epoch [2420], val_loss: 5980.5586\n",
            "Epoch [2440], val_loss: 5976.5850\n",
            "Epoch [2460], val_loss: 5976.9463\n",
            "Epoch [2480], val_loss: 5978.1997\n",
            "Epoch [2500], val_loss: 5976.3169\n",
            "Epoch [2520], val_loss: 5977.6919\n",
            "Epoch [2540], val_loss: 5974.6182\n",
            "Epoch [2560], val_loss: 5975.0913\n",
            "Epoch [2580], val_loss: 5973.2959\n",
            "Epoch [2600], val_loss: 5973.1611\n",
            "Epoch [2620], val_loss: 5970.1025\n",
            "Epoch [2640], val_loss: 5971.0879\n",
            "Epoch [2660], val_loss: 5970.4141\n",
            "Epoch [2680], val_loss: 5968.7969\n",
            "Epoch [2700], val_loss: 5967.1875\n",
            "Epoch [2720], val_loss: 5967.5776\n",
            "Epoch [2740], val_loss: 5966.8809\n",
            "Epoch [2760], val_loss: 5968.0518\n",
            "Epoch [2780], val_loss: 5965.5527\n",
            "Epoch [2800], val_loss: 5964.6035\n",
            "Epoch [2820], val_loss: 5963.4102\n",
            "Epoch [2840], val_loss: 5963.4902\n",
            "Epoch [2860], val_loss: 5963.8281\n",
            "Epoch [2880], val_loss: 5960.1924\n",
            "Epoch [2900], val_loss: 5960.8232\n",
            "Epoch [2920], val_loss: 5962.7100\n",
            "Epoch [2940], val_loss: 5960.1816\n",
            "Epoch [2960], val_loss: 5957.9668\n",
            "Epoch [2980], val_loss: 5956.5161\n",
            "Epoch [3000], val_loss: 5956.1104\n",
            "Epoch [3020], val_loss: 5955.7578\n",
            "Epoch [3040], val_loss: 5953.4263\n",
            "Epoch [3060], val_loss: 5953.5874\n",
            "Epoch [3080], val_loss: 5954.0518\n",
            "Epoch [3100], val_loss: 5950.9307\n",
            "Epoch [3120], val_loss: 5953.1050\n",
            "Epoch [3140], val_loss: 5950.1455\n",
            "Epoch [3160], val_loss: 5952.2637\n",
            "Epoch [3180], val_loss: 5949.8770\n",
            "Epoch [3200], val_loss: 5947.9155\n",
            "Epoch [3220], val_loss: 5947.7368\n",
            "Epoch [3240], val_loss: 5947.9810\n",
            "Epoch [3260], val_loss: 5947.5044\n",
            "Epoch [3280], val_loss: 5945.4502\n",
            "Epoch [3300], val_loss: 5944.2969\n",
            "Epoch [3320], val_loss: 5942.4863\n",
            "Epoch [3340], val_loss: 5942.4980\n",
            "Epoch [3360], val_loss: 5941.7925\n",
            "Epoch [3380], val_loss: 5941.1528\n",
            "Epoch [3400], val_loss: 5940.0645\n",
            "Epoch [3420], val_loss: 5938.4341\n",
            "Epoch [3440], val_loss: 5939.5781\n",
            "Epoch [3460], val_loss: 5937.4634\n",
            "Epoch [3480], val_loss: 5937.2437\n",
            "Epoch [3500], val_loss: 5936.0459\n",
            "Epoch [3520], val_loss: 5936.8481\n",
            "Epoch [3540], val_loss: 5934.9521\n",
            "Epoch [3560], val_loss: 5932.5615\n",
            "Epoch [3580], val_loss: 5935.6265\n",
            "Epoch [3600], val_loss: 5933.7051\n",
            "Epoch [3620], val_loss: 5930.0210\n",
            "Epoch [3640], val_loss: 5930.5908\n",
            "Epoch [3660], val_loss: 5929.8721\n",
            "Epoch [3680], val_loss: 5929.0059\n",
            "Epoch [3700], val_loss: 5928.8545\n",
            "Epoch [3720], val_loss: 5927.2207\n",
            "Epoch [3740], val_loss: 5926.4746\n",
            "Epoch [3760], val_loss: 5926.2783\n",
            "Epoch [3780], val_loss: 5925.7339\n",
            "Epoch [3800], val_loss: 5926.2729\n",
            "Epoch [3820], val_loss: 5923.0381\n",
            "Epoch [3840], val_loss: 5923.1611\n",
            "Epoch [3860], val_loss: 5920.5332\n",
            "Epoch [3880], val_loss: 5921.4956\n",
            "Epoch [3900], val_loss: 5920.9785\n",
            "Epoch [3920], val_loss: 5918.8848\n",
            "Epoch [3940], val_loss: 5918.2969\n",
            "Epoch [3960], val_loss: 5917.4873\n",
            "Epoch [3980], val_loss: 5916.1748\n",
            "Epoch [4000], val_loss: 5916.0869\n",
            "Epoch [4020], val_loss: 5916.5908\n",
            "Epoch [4040], val_loss: 5915.5088\n",
            "Epoch [4060], val_loss: 5914.3018\n",
            "Epoch [4080], val_loss: 5913.6733\n",
            "Epoch [4100], val_loss: 5913.8105\n",
            "Epoch [4120], val_loss: 5911.9375\n",
            "Epoch [4140], val_loss: 5911.9590\n",
            "Epoch [4160], val_loss: 5909.5796\n",
            "Epoch [4180], val_loss: 5911.1304\n",
            "Epoch [4200], val_loss: 5909.3188\n",
            "Epoch [4220], val_loss: 5907.3506\n",
            "Epoch [4240], val_loss: 5906.9912\n",
            "Epoch [4260], val_loss: 5905.0391\n",
            "Epoch [4280], val_loss: 5907.0283\n",
            "Epoch [4300], val_loss: 5903.1045\n",
            "Epoch [4320], val_loss: 5902.8936\n",
            "Epoch [4340], val_loss: 5902.1943\n",
            "Epoch [4360], val_loss: 5902.1030\n",
            "Epoch [4380], val_loss: 5900.6035\n",
            "Epoch [4400], val_loss: 5901.2085\n",
            "Epoch [4420], val_loss: 5900.2383\n",
            "Epoch [4440], val_loss: 5898.8057\n",
            "Epoch [4460], val_loss: 5897.6709\n",
            "Epoch [4480], val_loss: 5895.8262\n",
            "Epoch [4500], val_loss: 5896.9805\n",
            "Epoch [4520], val_loss: 5894.9531\n",
            "Epoch [4540], val_loss: 5894.7368\n",
            "Epoch [4560], val_loss: 5893.3584\n",
            "Epoch [4580], val_loss: 5890.6465\n",
            "Epoch [4600], val_loss: 5893.5664\n",
            "Epoch [4620], val_loss: 5892.6729\n",
            "Epoch [4640], val_loss: 5890.3252\n",
            "Epoch [4660], val_loss: 5889.5684\n",
            "Epoch [4680], val_loss: 5891.1328\n",
            "Epoch [4700], val_loss: 5887.2725\n",
            "Epoch [4720], val_loss: 5886.2871\n",
            "Epoch [4740], val_loss: 5884.2041\n",
            "Epoch [4760], val_loss: 5887.8867\n",
            "Epoch [4780], val_loss: 5887.4414\n",
            "Epoch [4800], val_loss: 5886.8467\n",
            "Epoch [4820], val_loss: 5884.5918\n",
            "Epoch [4840], val_loss: 5881.5098\n",
            "Epoch [4860], val_loss: 5885.5342\n",
            "Epoch [4880], val_loss: 5880.3828\n",
            "Epoch [4900], val_loss: 5878.7759\n",
            "Epoch [4920], val_loss: 5879.3662\n",
            "Epoch [4940], val_loss: 5877.9434\n",
            "Epoch [4960], val_loss: 5876.1797\n",
            "Epoch [4980], val_loss: 5877.0977\n",
            "Epoch [5000], val_loss: 5876.5156\n",
            "Epoch [5020], val_loss: 5877.1943\n",
            "Epoch [5040], val_loss: 5875.5420\n",
            "Epoch [5060], val_loss: 5873.2305\n",
            "Epoch [5080], val_loss: 5870.4932\n",
            "Epoch [5100], val_loss: 5871.6357\n",
            "Epoch [5120], val_loss: 5872.3853\n",
            "Epoch [5140], val_loss: 5872.0923\n",
            "Epoch [5160], val_loss: 5870.4990\n",
            "Epoch [5180], val_loss: 5869.1553\n",
            "Epoch [5200], val_loss: 5870.2178\n",
            "Epoch [5220], val_loss: 5868.3999\n",
            "Epoch [5240], val_loss: 5865.8687\n",
            "Epoch [5260], val_loss: 5868.1558\n",
            "Epoch [5280], val_loss: 5866.0884\n",
            "Epoch [5300], val_loss: 5864.1797\n",
            "Epoch [5320], val_loss: 5864.6289\n",
            "Epoch [5340], val_loss: 5863.5127\n",
            "Epoch [5360], val_loss: 5862.2725\n",
            "Epoch [5380], val_loss: 5862.4170\n",
            "Epoch [5400], val_loss: 5862.1855\n",
            "Epoch [5420], val_loss: 5862.0947\n",
            "Epoch [5440], val_loss: 5858.4702\n",
            "Epoch [5460], val_loss: 5858.9600\n",
            "Epoch [5480], val_loss: 5860.3604\n",
            "Epoch [5500], val_loss: 5857.6621\n",
            "Epoch [5520], val_loss: 5855.2002\n",
            "Epoch [5540], val_loss: 5854.6914\n",
            "Epoch [5560], val_loss: 5856.2783\n",
            "Epoch [5580], val_loss: 5855.4570\n",
            "Epoch [5600], val_loss: 5852.8062\n",
            "Epoch [5620], val_loss: 5850.6982\n",
            "Epoch [5640], val_loss: 5850.3711\n",
            "Epoch [5660], val_loss: 5850.5317\n",
            "Epoch [5680], val_loss: 5851.7109\n",
            "Epoch [5700], val_loss: 5847.9565\n",
            "Epoch [5720], val_loss: 5848.1831\n",
            "Epoch [5740], val_loss: 5845.5317\n",
            "Epoch [5760], val_loss: 5845.0239\n",
            "Epoch [5780], val_loss: 5846.2612\n",
            "Epoch [5800], val_loss: 5845.5879\n",
            "Epoch [5820], val_loss: 5846.5859\n",
            "Epoch [5840], val_loss: 5843.0518\n",
            "Epoch [5860], val_loss: 5842.1567\n",
            "Epoch [5880], val_loss: 5841.0449\n",
            "Epoch [5900], val_loss: 5841.4219\n",
            "Epoch [5920], val_loss: 5837.7646\n",
            "Epoch [5940], val_loss: 5838.8076\n",
            "Epoch [5960], val_loss: 5836.7637\n",
            "Epoch [5980], val_loss: 5838.9961\n",
            "Epoch [6000], val_loss: 5837.0713\n",
            "Epoch [6020], val_loss: 5837.9033\n",
            "Epoch [6040], val_loss: 5834.6416\n",
            "Epoch [6060], val_loss: 5833.9170\n",
            "Epoch [6080], val_loss: 5833.7334\n",
            "Epoch [6100], val_loss: 5833.8691\n",
            "Epoch [6120], val_loss: 5834.5894\n",
            "Epoch [6140], val_loss: 5831.6064\n",
            "Epoch [6160], val_loss: 5828.9575\n",
            "Epoch [6180], val_loss: 5826.9229\n",
            "Epoch [6200], val_loss: 5829.3457\n",
            "Epoch [6220], val_loss: 5830.1519\n",
            "Epoch [6240], val_loss: 5827.1768\n",
            "Epoch [6260], val_loss: 5827.1533\n",
            "Epoch [6280], val_loss: 5825.7803\n",
            "Epoch [6300], val_loss: 5825.2686\n",
            "Epoch [6320], val_loss: 5821.9756\n",
            "Epoch [6340], val_loss: 5825.5376\n",
            "Epoch [6360], val_loss: 5824.1055\n",
            "Epoch [6380], val_loss: 5822.6245\n",
            "Epoch [6400], val_loss: 5820.6514\n",
            "Epoch [6420], val_loss: 5820.4375\n",
            "Epoch [6440], val_loss: 5818.6484\n",
            "Epoch [6460], val_loss: 5817.0552\n",
            "Epoch [6480], val_loss: 5819.6152\n",
            "Epoch [6500], val_loss: 5817.0332\n",
            "Epoch [6520], val_loss: 5815.8208\n",
            "Epoch [6540], val_loss: 5815.2988\n",
            "Epoch [6560], val_loss: 5812.9355\n",
            "Epoch [6580], val_loss: 5813.2617\n",
            "Epoch [6600], val_loss: 5813.2490\n",
            "Epoch [6620], val_loss: 5812.7383\n",
            "Epoch [6640], val_loss: 5809.8389\n",
            "Epoch [6660], val_loss: 5809.1816\n",
            "Epoch [6680], val_loss: 5809.8369\n",
            "Epoch [6700], val_loss: 5811.6514\n",
            "Epoch [6720], val_loss: 5808.8379\n",
            "Epoch [6740], val_loss: 5807.7715\n",
            "Epoch [6760], val_loss: 5806.0410\n",
            "Epoch [6780], val_loss: 5807.5200\n",
            "Epoch [6800], val_loss: 5805.8467\n",
            "Epoch [6820], val_loss: 5803.5625\n",
            "Epoch [6840], val_loss: 5804.8350\n",
            "Epoch [6860], val_loss: 5802.7520\n",
            "Epoch [6880], val_loss: 5803.3706\n",
            "Epoch [6900], val_loss: 5803.2314\n",
            "Epoch [6920], val_loss: 5802.0352\n",
            "Epoch [6940], val_loss: 5798.0898\n",
            "Epoch [6960], val_loss: 5799.5596\n",
            "Epoch [6980], val_loss: 5799.8408\n",
            "Epoch [7000], val_loss: 5794.9873\n",
            "Epoch [7020], val_loss: 5794.1509\n",
            "Epoch [7040], val_loss: 5794.6221\n",
            "Epoch [7060], val_loss: 5792.6318\n",
            "Epoch [7080], val_loss: 5793.5547\n",
            "Epoch [7100], val_loss: 5792.2227\n",
            "Epoch [7120], val_loss: 5795.6704\n",
            "Epoch [7140], val_loss: 5791.6025\n",
            "Epoch [7160], val_loss: 5792.8203\n",
            "Epoch [7180], val_loss: 5790.2100\n",
            "Epoch [7200], val_loss: 5790.3828\n",
            "Epoch [7220], val_loss: 5789.7041\n",
            "Epoch [7240], val_loss: 5788.7764\n",
            "Epoch [7260], val_loss: 5788.6240\n",
            "Epoch [7280], val_loss: 5786.7764\n",
            "Epoch [7300], val_loss: 5787.3350\n",
            "Epoch [7320], val_loss: 5787.8047\n",
            "Epoch [7340], val_loss: 5784.1440\n",
            "Epoch [7360], val_loss: 5785.5078\n",
            "Epoch [7380], val_loss: 5782.5000\n",
            "Epoch [7400], val_loss: 5781.6777\n",
            "Epoch [7420], val_loss: 5779.3682\n",
            "Epoch [7440], val_loss: 5779.6704\n",
            "Epoch [7460], val_loss: 5778.1416\n",
            "Epoch [7480], val_loss: 5780.8398\n",
            "Epoch [7500], val_loss: 5780.6846\n",
            "Epoch [7520], val_loss: 5778.1929\n",
            "Epoch [7540], val_loss: 5775.6094\n",
            "Epoch [7560], val_loss: 5774.7114\n",
            "Epoch [7580], val_loss: 5774.7720\n",
            "Epoch [7600], val_loss: 5772.3770\n",
            "Epoch [7620], val_loss: 5770.8682\n",
            "Epoch [7640], val_loss: 5771.5552\n",
            "Epoch [7660], val_loss: 5769.6455\n",
            "Epoch [7680], val_loss: 5773.0449\n",
            "Epoch [7700], val_loss: 5771.1426\n",
            "Epoch [7720], val_loss: 5770.6533\n",
            "Epoch [7740], val_loss: 5766.7646\n",
            "Epoch [7760], val_loss: 5766.4463\n",
            "Epoch [7780], val_loss: 5765.6475\n",
            "Epoch [7800], val_loss: 5767.2886\n",
            "Epoch [7820], val_loss: 5767.1660\n",
            "Epoch [7840], val_loss: 5762.1743\n",
            "Epoch [7860], val_loss: 5766.3071\n",
            "Epoch [7880], val_loss: 5764.7969\n",
            "Epoch [7900], val_loss: 5764.7891\n",
            "Epoch [7920], val_loss: 5763.5703\n",
            "Epoch [7940], val_loss: 5759.8809\n",
            "Epoch [7960], val_loss: 5761.5186\n",
            "Epoch [7980], val_loss: 5759.4619\n",
            "Epoch [8000], val_loss: 5758.9292\n",
            "Epoch [8020], val_loss: 5757.7817\n",
            "Epoch [8040], val_loss: 5759.0176\n",
            "Epoch [8060], val_loss: 5755.8208\n",
            "Epoch [8080], val_loss: 5755.5088\n",
            "Epoch [8100], val_loss: 5755.4336\n",
            "Epoch [8120], val_loss: 5754.8008\n",
            "Epoch [8140], val_loss: 5752.9121\n",
            "Epoch [8160], val_loss: 5751.4478\n",
            "Epoch [8180], val_loss: 5753.8062\n",
            "Epoch [8200], val_loss: 5749.1934\n",
            "Epoch [8220], val_loss: 5748.0059\n",
            "Epoch [8240], val_loss: 5752.0566\n",
            "Epoch [8260], val_loss: 5746.7969\n",
            "Epoch [8280], val_loss: 5747.2285\n",
            "Epoch [8300], val_loss: 5745.3564\n",
            "Epoch [8320], val_loss: 5746.6289\n",
            "Epoch [8340], val_loss: 5746.6445\n",
            "Epoch [8360], val_loss: 5744.9199\n",
            "Epoch [8380], val_loss: 5741.8545\n",
            "Epoch [8400], val_loss: 5739.7568\n",
            "Epoch [8420], val_loss: 5739.7441\n",
            "Epoch [8440], val_loss: 5740.0728\n",
            "Epoch [8460], val_loss: 5738.5352\n",
            "Epoch [8480], val_loss: 5737.7109\n",
            "Epoch [8500], val_loss: 5738.7148\n",
            "Epoch [8520], val_loss: 5738.0127\n",
            "Epoch [8540], val_loss: 5737.0879\n",
            "Epoch [8560], val_loss: 5735.7036\n",
            "Epoch [8580], val_loss: 5736.4097\n",
            "Epoch [8600], val_loss: 5735.1128\n",
            "Epoch [8620], val_loss: 5736.7256\n",
            "Epoch [8640], val_loss: 5734.3135\n",
            "Epoch [8660], val_loss: 5733.6494\n",
            "Epoch [8680], val_loss: 5733.2109\n",
            "Epoch [8700], val_loss: 5730.1348\n",
            "Epoch [8720], val_loss: 5728.4351\n",
            "Epoch [8740], val_loss: 5730.1309\n",
            "Epoch [8760], val_loss: 5727.8247\n",
            "Epoch [8780], val_loss: 5728.8418\n",
            "Epoch [8800], val_loss: 5726.4175\n",
            "Epoch [8820], val_loss: 5727.4175\n",
            "Epoch [8840], val_loss: 5724.5928\n",
            "Epoch [8860], val_loss: 5724.1597\n",
            "Epoch [8880], val_loss: 5721.3164\n",
            "Epoch [8900], val_loss: 5723.7695\n",
            "Epoch [8920], val_loss: 5722.1792\n",
            "Epoch [8940], val_loss: 5722.1392\n",
            "Epoch [8960], val_loss: 5721.9473\n",
            "Epoch [8980], val_loss: 5719.7603\n",
            "Epoch [9000], val_loss: 5718.4717\n",
            "Epoch [9020], val_loss: 5721.0952\n",
            "Epoch [9040], val_loss: 5718.6650\n",
            "Epoch [9060], val_loss: 5715.9346\n",
            "Epoch [9080], val_loss: 5715.8555\n",
            "Epoch [9100], val_loss: 5716.3174\n",
            "Epoch [9120], val_loss: 5713.6289\n",
            "Epoch [9140], val_loss: 5711.3379\n",
            "Epoch [9160], val_loss: 5710.1318\n",
            "Epoch [9180], val_loss: 5713.5635\n",
            "Epoch [9200], val_loss: 5712.2578\n",
            "Epoch [9220], val_loss: 5711.4487\n",
            "Epoch [9240], val_loss: 5707.3105\n",
            "Epoch [9260], val_loss: 5709.1348\n",
            "Epoch [9280], val_loss: 5707.0781\n",
            "Epoch [9300], val_loss: 5708.9814\n",
            "Epoch [9320], val_loss: 5706.9727\n",
            "Epoch [9340], val_loss: 5705.2622\n",
            "Epoch [9360], val_loss: 5702.6572\n",
            "Epoch [9380], val_loss: 5704.3623\n",
            "Epoch [9400], val_loss: 5703.1338\n",
            "Epoch [9420], val_loss: 5703.3281\n",
            "Epoch [9440], val_loss: 5702.8379\n",
            "Epoch [9460], val_loss: 5698.7363\n",
            "Epoch [9480], val_loss: 5700.2148\n",
            "Epoch [9500], val_loss: 5699.6982\n",
            "Epoch [9520], val_loss: 5698.6636\n",
            "Epoch [9540], val_loss: 5696.8784\n",
            "Epoch [9560], val_loss: 5696.9941\n",
            "Epoch [9580], val_loss: 5695.6118\n",
            "Epoch [9600], val_loss: 5696.1191\n",
            "Epoch [9620], val_loss: 5695.5068\n",
            "Epoch [9640], val_loss: 5691.7002\n",
            "Epoch [9660], val_loss: 5693.5303\n",
            "Epoch [9680], val_loss: 5692.2920\n",
            "Epoch [9700], val_loss: 5692.9404\n",
            "Epoch [9720], val_loss: 5693.7349\n",
            "Epoch [9740], val_loss: 5690.1992\n",
            "Epoch [9760], val_loss: 5687.8379\n",
            "Epoch [9780], val_loss: 5687.8359\n",
            "Epoch [9800], val_loss: 5688.4819\n",
            "Epoch [9820], val_loss: 5687.9395\n",
            "Epoch [9840], val_loss: 5685.9458\n",
            "Epoch [9860], val_loss: 5684.3535\n",
            "Epoch [9880], val_loss: 5684.9561\n",
            "Epoch [9900], val_loss: 5684.0728\n",
            "Epoch [9920], val_loss: 5684.4863\n",
            "Epoch [9940], val_loss: 5681.7812\n",
            "Epoch [9960], val_loss: 5680.0854\n",
            "Epoch [9980], val_loss: 5679.4785\n",
            "Epoch [10000], val_loss: 5678.7920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5GHfsOkAE-H",
        "outputId": "3571ebcd-2872-4b1c-968f-6aa70de81295"
      },
      "source": [
        "epochs = 5000\r\n",
        "lr = 1e-1\r\n",
        "history6 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5680.2080\n",
            "Epoch [40], val_loss: 5679.6704\n",
            "Epoch [60], val_loss: 5676.8994\n",
            "Epoch [80], val_loss: 5679.3623\n",
            "Epoch [100], val_loss: 5676.4155\n",
            "Epoch [120], val_loss: 5676.3320\n",
            "Epoch [140], val_loss: 5676.6499\n",
            "Epoch [160], val_loss: 5673.9424\n",
            "Epoch [180], val_loss: 5673.3838\n",
            "Epoch [200], val_loss: 5672.3125\n",
            "Epoch [220], val_loss: 5671.3730\n",
            "Epoch [240], val_loss: 5669.2988\n",
            "Epoch [260], val_loss: 5670.2744\n",
            "Epoch [280], val_loss: 5668.5273\n",
            "Epoch [300], val_loss: 5667.5518\n",
            "Epoch [320], val_loss: 5669.3770\n",
            "Epoch [340], val_loss: 5666.6113\n",
            "Epoch [360], val_loss: 5665.4619\n",
            "Epoch [380], val_loss: 5666.9189\n",
            "Epoch [400], val_loss: 5663.6670\n",
            "Epoch [420], val_loss: 5663.9082\n",
            "Epoch [440], val_loss: 5661.5537\n",
            "Epoch [460], val_loss: 5659.6167\n",
            "Epoch [480], val_loss: 5662.1157\n",
            "Epoch [500], val_loss: 5658.5132\n",
            "Epoch [520], val_loss: 5658.7788\n",
            "Epoch [540], val_loss: 5659.3848\n",
            "Epoch [560], val_loss: 5657.9014\n",
            "Epoch [580], val_loss: 5656.3369\n",
            "Epoch [600], val_loss: 5655.0825\n",
            "Epoch [620], val_loss: 5655.5474\n",
            "Epoch [640], val_loss: 5653.1250\n",
            "Epoch [660], val_loss: 5655.0898\n",
            "Epoch [680], val_loss: 5652.9180\n",
            "Epoch [700], val_loss: 5653.5615\n",
            "Epoch [720], val_loss: 5650.7373\n",
            "Epoch [740], val_loss: 5651.5522\n",
            "Epoch [760], val_loss: 5652.9785\n",
            "Epoch [780], val_loss: 5652.1138\n",
            "Epoch [800], val_loss: 5649.8662\n",
            "Epoch [820], val_loss: 5648.6870\n",
            "Epoch [840], val_loss: 5647.0625\n",
            "Epoch [860], val_loss: 5647.1895\n",
            "Epoch [880], val_loss: 5647.0684\n",
            "Epoch [900], val_loss: 5644.6924\n",
            "Epoch [920], val_loss: 5642.5654\n",
            "Epoch [940], val_loss: 5645.6250\n",
            "Epoch [960], val_loss: 5641.5469\n",
            "Epoch [980], val_loss: 5640.8779\n",
            "Epoch [1000], val_loss: 5640.7578\n",
            "Epoch [1020], val_loss: 5640.3218\n",
            "Epoch [1040], val_loss: 5638.4980\n",
            "Epoch [1060], val_loss: 5638.5479\n",
            "Epoch [1080], val_loss: 5639.8716\n",
            "Epoch [1100], val_loss: 5636.5288\n",
            "Epoch [1120], val_loss: 5636.2832\n",
            "Epoch [1140], val_loss: 5635.0820\n",
            "Epoch [1160], val_loss: 5634.5142\n",
            "Epoch [1180], val_loss: 5633.4351\n",
            "Epoch [1200], val_loss: 5631.2393\n",
            "Epoch [1220], val_loss: 5632.7236\n",
            "Epoch [1240], val_loss: 5631.9883\n",
            "Epoch [1260], val_loss: 5630.7070\n",
            "Epoch [1280], val_loss: 5629.2412\n",
            "Epoch [1300], val_loss: 5629.6582\n",
            "Epoch [1320], val_loss: 5628.0269\n",
            "Epoch [1340], val_loss: 5628.3267\n",
            "Epoch [1360], val_loss: 5626.1216\n",
            "Epoch [1380], val_loss: 5624.7041\n",
            "Epoch [1400], val_loss: 5625.7637\n",
            "Epoch [1420], val_loss: 5623.7715\n",
            "Epoch [1440], val_loss: 5626.7578\n",
            "Epoch [1460], val_loss: 5622.3926\n",
            "Epoch [1480], val_loss: 5621.5688\n",
            "Epoch [1500], val_loss: 5623.9673\n",
            "Epoch [1520], val_loss: 5619.6733\n",
            "Epoch [1540], val_loss: 5621.4248\n",
            "Epoch [1560], val_loss: 5617.7988\n",
            "Epoch [1580], val_loss: 5617.2949\n",
            "Epoch [1600], val_loss: 5618.9111\n",
            "Epoch [1620], val_loss: 5615.5146\n",
            "Epoch [1640], val_loss: 5616.3423\n",
            "Epoch [1660], val_loss: 5615.2056\n",
            "Epoch [1680], val_loss: 5617.0977\n",
            "Epoch [1700], val_loss: 5615.2930\n",
            "Epoch [1720], val_loss: 5611.2451\n",
            "Epoch [1740], val_loss: 5611.4111\n",
            "Epoch [1760], val_loss: 5610.4849\n",
            "Epoch [1780], val_loss: 5608.6436\n",
            "Epoch [1800], val_loss: 5609.2861\n",
            "Epoch [1820], val_loss: 5608.6592\n",
            "Epoch [1840], val_loss: 5608.7041\n",
            "Epoch [1860], val_loss: 5606.1797\n",
            "Epoch [1880], val_loss: 5607.0728\n",
            "Epoch [1900], val_loss: 5606.9028\n",
            "Epoch [1920], val_loss: 5604.7222\n",
            "Epoch [1940], val_loss: 5604.9199\n",
            "Epoch [1960], val_loss: 5604.6602\n",
            "Epoch [1980], val_loss: 5604.2388\n",
            "Epoch [2000], val_loss: 5602.3569\n",
            "Epoch [2020], val_loss: 5603.0742\n",
            "Epoch [2040], val_loss: 5602.1602\n",
            "Epoch [2060], val_loss: 5599.2236\n",
            "Epoch [2080], val_loss: 5597.8730\n",
            "Epoch [2100], val_loss: 5599.1816\n",
            "Epoch [2120], val_loss: 5596.1772\n",
            "Epoch [2140], val_loss: 5599.1104\n",
            "Epoch [2160], val_loss: 5595.4731\n",
            "Epoch [2180], val_loss: 5596.3242\n",
            "Epoch [2200], val_loss: 5593.1016\n",
            "Epoch [2220], val_loss: 5594.6328\n",
            "Epoch [2240], val_loss: 5592.7026\n",
            "Epoch [2260], val_loss: 5592.4912\n",
            "Epoch [2280], val_loss: 5593.4512\n",
            "Epoch [2300], val_loss: 5590.4971\n",
            "Epoch [2320], val_loss: 5589.0586\n",
            "Epoch [2340], val_loss: 5590.0210\n",
            "Epoch [2360], val_loss: 5589.6440\n",
            "Epoch [2380], val_loss: 5586.2344\n",
            "Epoch [2400], val_loss: 5584.5068\n",
            "Epoch [2420], val_loss: 5585.0117\n",
            "Epoch [2440], val_loss: 5585.2520\n",
            "Epoch [2460], val_loss: 5584.6216\n",
            "Epoch [2480], val_loss: 5582.5283\n",
            "Epoch [2500], val_loss: 5583.3857\n",
            "Epoch [2520], val_loss: 5581.4043\n",
            "Epoch [2540], val_loss: 5581.7368\n",
            "Epoch [2560], val_loss: 5580.5483\n",
            "Epoch [2580], val_loss: 5577.2715\n",
            "Epoch [2600], val_loss: 5577.6211\n",
            "Epoch [2620], val_loss: 5577.5645\n",
            "Epoch [2640], val_loss: 5576.4448\n",
            "Epoch [2660], val_loss: 5577.9375\n",
            "Epoch [2680], val_loss: 5574.1631\n",
            "Epoch [2700], val_loss: 5575.3545\n",
            "Epoch [2720], val_loss: 5574.9580\n",
            "Epoch [2740], val_loss: 5572.5664\n",
            "Epoch [2760], val_loss: 5573.5723\n",
            "Epoch [2780], val_loss: 5572.5254\n",
            "Epoch [2800], val_loss: 5569.4678\n",
            "Epoch [2820], val_loss: 5570.9546\n",
            "Epoch [2840], val_loss: 5571.3281\n",
            "Epoch [2860], val_loss: 5566.3711\n",
            "Epoch [2880], val_loss: 5570.2012\n",
            "Epoch [2900], val_loss: 5566.7715\n",
            "Epoch [2920], val_loss: 5568.8555\n",
            "Epoch [2940], val_loss: 5565.8945\n",
            "Epoch [2960], val_loss: 5564.6274\n",
            "Epoch [2980], val_loss: 5562.3672\n",
            "Epoch [3000], val_loss: 5564.7783\n",
            "Epoch [3020], val_loss: 5560.7451\n",
            "Epoch [3040], val_loss: 5561.1963\n",
            "Epoch [3060], val_loss: 5560.3584\n",
            "Epoch [3080], val_loss: 5560.0879\n",
            "Epoch [3100], val_loss: 5557.8496\n",
            "Epoch [3120], val_loss: 5561.6494\n",
            "Epoch [3140], val_loss: 5557.2559\n",
            "Epoch [3160], val_loss: 5557.0430\n",
            "Epoch [3180], val_loss: 5557.5947\n",
            "Epoch [3200], val_loss: 5555.7686\n",
            "Epoch [3220], val_loss: 5555.0371\n",
            "Epoch [3240], val_loss: 5555.2764\n",
            "Epoch [3260], val_loss: 5550.7471\n",
            "Epoch [3280], val_loss: 5554.1895\n",
            "Epoch [3300], val_loss: 5555.3994\n",
            "Epoch [3320], val_loss: 5550.9155\n",
            "Epoch [3340], val_loss: 5551.3262\n",
            "Epoch [3360], val_loss: 5551.4839\n",
            "Epoch [3380], val_loss: 5548.0845\n",
            "Epoch [3400], val_loss: 5547.4058\n",
            "Epoch [3420], val_loss: 5546.6699\n",
            "Epoch [3440], val_loss: 5544.1084\n",
            "Epoch [3460], val_loss: 5544.6289\n",
            "Epoch [3480], val_loss: 5545.2227\n",
            "Epoch [3500], val_loss: 5545.4624\n",
            "Epoch [3520], val_loss: 5542.3594\n",
            "Epoch [3540], val_loss: 5542.5420\n",
            "Epoch [3560], val_loss: 5540.3066\n",
            "Epoch [3580], val_loss: 5540.4009\n",
            "Epoch [3600], val_loss: 5539.3633\n",
            "Epoch [3620], val_loss: 5541.0269\n",
            "Epoch [3640], val_loss: 5537.1670\n",
            "Epoch [3660], val_loss: 5536.6660\n",
            "Epoch [3680], val_loss: 5537.7212\n",
            "Epoch [3700], val_loss: 5535.1943\n",
            "Epoch [3720], val_loss: 5534.7705\n",
            "Epoch [3740], val_loss: 5537.3213\n",
            "Epoch [3760], val_loss: 5536.5146\n",
            "Epoch [3780], val_loss: 5533.8154\n",
            "Epoch [3800], val_loss: 5535.0239\n",
            "Epoch [3820], val_loss: 5532.1191\n",
            "Epoch [3840], val_loss: 5531.4053\n",
            "Epoch [3860], val_loss: 5530.1748\n",
            "Epoch [3880], val_loss: 5529.5752\n",
            "Epoch [3900], val_loss: 5529.0361\n",
            "Epoch [3920], val_loss: 5529.4395\n",
            "Epoch [3940], val_loss: 5526.7568\n",
            "Epoch [3960], val_loss: 5524.8213\n",
            "Epoch [3980], val_loss: 5523.7471\n",
            "Epoch [4000], val_loss: 5526.2222\n",
            "Epoch [4020], val_loss: 5524.0801\n",
            "Epoch [4040], val_loss: 5522.2031\n",
            "Epoch [4060], val_loss: 5521.7773\n",
            "Epoch [4080], val_loss: 5519.9590\n",
            "Epoch [4100], val_loss: 5522.2598\n",
            "Epoch [4120], val_loss: 5520.9326\n",
            "Epoch [4140], val_loss: 5520.8516\n",
            "Epoch [4160], val_loss: 5516.9990\n",
            "Epoch [4180], val_loss: 5518.6553\n",
            "Epoch [4200], val_loss: 5518.8877\n",
            "Epoch [4220], val_loss: 5514.5859\n",
            "Epoch [4240], val_loss: 5515.0127\n",
            "Epoch [4260], val_loss: 5514.6553\n",
            "Epoch [4280], val_loss: 5514.4360\n",
            "Epoch [4300], val_loss: 5513.5591\n",
            "Epoch [4320], val_loss: 5513.3447\n",
            "Epoch [4340], val_loss: 5513.8208\n",
            "Epoch [4360], val_loss: 5512.9028\n",
            "Epoch [4380], val_loss: 5510.2412\n",
            "Epoch [4400], val_loss: 5508.7324\n",
            "Epoch [4420], val_loss: 5510.2412\n",
            "Epoch [4440], val_loss: 5508.2109\n",
            "Epoch [4460], val_loss: 5507.4277\n",
            "Epoch [4480], val_loss: 5507.6152\n",
            "Epoch [4500], val_loss: 5506.7759\n",
            "Epoch [4520], val_loss: 5506.8286\n",
            "Epoch [4540], val_loss: 5505.3145\n",
            "Epoch [4560], val_loss: 5504.7617\n",
            "Epoch [4580], val_loss: 5501.6777\n",
            "Epoch [4600], val_loss: 5501.6567\n",
            "Epoch [4620], val_loss: 5501.9990\n",
            "Epoch [4640], val_loss: 5503.4800\n",
            "Epoch [4660], val_loss: 5498.4600\n",
            "Epoch [4680], val_loss: 5500.6221\n",
            "Epoch [4700], val_loss: 5497.1816\n",
            "Epoch [4720], val_loss: 5499.2939\n",
            "Epoch [4740], val_loss: 5497.1387\n",
            "Epoch [4760], val_loss: 5495.9961\n",
            "Epoch [4780], val_loss: 5494.6157\n",
            "Epoch [4800], val_loss: 5495.5444\n",
            "Epoch [4820], val_loss: 5492.5586\n",
            "Epoch [4840], val_loss: 5492.1143\n",
            "Epoch [4860], val_loss: 5491.5605\n",
            "Epoch [4880], val_loss: 5489.4648\n",
            "Epoch [4900], val_loss: 5490.1240\n",
            "Epoch [4920], val_loss: 5488.3105\n",
            "Epoch [4940], val_loss: 5489.8618\n",
            "Epoch [4960], val_loss: 5486.9258\n",
            "Epoch [4980], val_loss: 5486.2500\n",
            "Epoch [5000], val_loss: 5486.6748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRwUze8_Arok",
        "outputId": "d2b34c8a-1444-473c-92a6-916336fddd6a"
      },
      "source": [
        "epochs = 10000\r\n",
        "lr = 1e-1\r\n",
        "history7 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5485.3838\n",
            "Epoch [40], val_loss: 5483.7744\n",
            "Epoch [60], val_loss: 5482.2051\n",
            "Epoch [80], val_loss: 5483.1182\n",
            "Epoch [100], val_loss: 5482.3867\n",
            "Epoch [120], val_loss: 5483.1650\n",
            "Epoch [140], val_loss: 5481.1938\n",
            "Epoch [160], val_loss: 5480.6660\n",
            "Epoch [180], val_loss: 5479.9390\n",
            "Epoch [200], val_loss: 5478.7837\n",
            "Epoch [220], val_loss: 5477.2598\n",
            "Epoch [240], val_loss: 5478.3657\n",
            "Epoch [260], val_loss: 5476.3623\n",
            "Epoch [280], val_loss: 5476.7500\n",
            "Epoch [300], val_loss: 5475.6616\n",
            "Epoch [320], val_loss: 5477.2217\n",
            "Epoch [340], val_loss: 5472.3296\n",
            "Epoch [360], val_loss: 5473.0420\n",
            "Epoch [380], val_loss: 5471.8130\n",
            "Epoch [400], val_loss: 5472.7139\n",
            "Epoch [420], val_loss: 5469.8477\n",
            "Epoch [440], val_loss: 5469.6152\n",
            "Epoch [460], val_loss: 5468.4580\n",
            "Epoch [480], val_loss: 5467.7217\n",
            "Epoch [500], val_loss: 5469.6753\n",
            "Epoch [520], val_loss: 5466.4932\n",
            "Epoch [540], val_loss: 5463.7461\n",
            "Epoch [560], val_loss: 5464.9277\n",
            "Epoch [580], val_loss: 5464.1914\n",
            "Epoch [600], val_loss: 5463.1162\n",
            "Epoch [620], val_loss: 5461.3691\n",
            "Epoch [640], val_loss: 5463.3232\n",
            "Epoch [660], val_loss: 5461.1973\n",
            "Epoch [680], val_loss: 5458.6865\n",
            "Epoch [700], val_loss: 5458.6914\n",
            "Epoch [720], val_loss: 5457.3354\n",
            "Epoch [740], val_loss: 5460.3198\n",
            "Epoch [760], val_loss: 5456.9155\n",
            "Epoch [780], val_loss: 5455.7031\n",
            "Epoch [800], val_loss: 5457.2070\n",
            "Epoch [820], val_loss: 5456.9185\n",
            "Epoch [840], val_loss: 5454.0938\n",
            "Epoch [860], val_loss: 5454.0825\n",
            "Epoch [880], val_loss: 5451.1733\n",
            "Epoch [900], val_loss: 5452.3271\n",
            "Epoch [920], val_loss: 5450.0830\n",
            "Epoch [940], val_loss: 5449.8359\n",
            "Epoch [960], val_loss: 5450.6440\n",
            "Epoch [980], val_loss: 5448.3994\n",
            "Epoch [1000], val_loss: 5448.3389\n",
            "Epoch [1020], val_loss: 5446.4595\n",
            "Epoch [1040], val_loss: 5445.8687\n",
            "Epoch [1060], val_loss: 5445.8462\n",
            "Epoch [1080], val_loss: 5445.2930\n",
            "Epoch [1100], val_loss: 5443.2310\n",
            "Epoch [1120], val_loss: 5444.2744\n",
            "Epoch [1140], val_loss: 5440.1924\n",
            "Epoch [1160], val_loss: 5440.0117\n",
            "Epoch [1180], val_loss: 5440.8032\n",
            "Epoch [1200], val_loss: 5441.2510\n",
            "Epoch [1220], val_loss: 5438.9580\n",
            "Epoch [1240], val_loss: 5441.1997\n",
            "Epoch [1260], val_loss: 5436.5596\n",
            "Epoch [1280], val_loss: 5436.1299\n",
            "Epoch [1300], val_loss: 5436.2471\n",
            "Epoch [1320], val_loss: 5437.2217\n",
            "Epoch [1340], val_loss: 5435.1240\n",
            "Epoch [1360], val_loss: 5432.3296\n",
            "Epoch [1380], val_loss: 5436.3452\n",
            "Epoch [1400], val_loss: 5433.9146\n",
            "Epoch [1420], val_loss: 5430.3320\n",
            "Epoch [1440], val_loss: 5432.8521\n",
            "Epoch [1460], val_loss: 5430.5439\n",
            "Epoch [1480], val_loss: 5427.1143\n",
            "Epoch [1500], val_loss: 5429.1221\n",
            "Epoch [1520], val_loss: 5427.6455\n",
            "Epoch [1540], val_loss: 5425.6445\n",
            "Epoch [1560], val_loss: 5427.8955\n",
            "Epoch [1580], val_loss: 5426.9365\n",
            "Epoch [1600], val_loss: 5424.2383\n",
            "Epoch [1620], val_loss: 5426.1060\n",
            "Epoch [1640], val_loss: 5423.7939\n",
            "Epoch [1660], val_loss: 5421.9023\n",
            "Epoch [1680], val_loss: 5423.2964\n",
            "Epoch [1700], val_loss: 5418.3809\n",
            "Epoch [1720], val_loss: 5421.9814\n",
            "Epoch [1740], val_loss: 5420.4214\n",
            "Epoch [1760], val_loss: 5420.2793\n",
            "Epoch [1780], val_loss: 5417.9912\n",
            "Epoch [1800], val_loss: 5417.3350\n",
            "Epoch [1820], val_loss: 5415.0356\n",
            "Epoch [1840], val_loss: 5416.0210\n",
            "Epoch [1860], val_loss: 5415.5518\n",
            "Epoch [1880], val_loss: 5416.5967\n",
            "Epoch [1900], val_loss: 5413.8003\n",
            "Epoch [1920], val_loss: 5411.1807\n",
            "Epoch [1940], val_loss: 5414.3506\n",
            "Epoch [1960], val_loss: 5410.0688\n",
            "Epoch [1980], val_loss: 5411.1436\n",
            "Epoch [2000], val_loss: 5409.3374\n",
            "Epoch [2020], val_loss: 5408.0933\n",
            "Epoch [2040], val_loss: 5407.1201\n",
            "Epoch [2060], val_loss: 5407.3262\n",
            "Epoch [2080], val_loss: 5407.7729\n",
            "Epoch [2100], val_loss: 5407.2959\n",
            "Epoch [2120], val_loss: 5403.0674\n",
            "Epoch [2140], val_loss: 5402.2158\n",
            "Epoch [2160], val_loss: 5403.9160\n",
            "Epoch [2180], val_loss: 5401.6123\n",
            "Epoch [2200], val_loss: 5401.4258\n",
            "Epoch [2220], val_loss: 5399.9082\n",
            "Epoch [2240], val_loss: 5402.0938\n",
            "Epoch [2260], val_loss: 5398.9995\n",
            "Epoch [2280], val_loss: 5397.9956\n",
            "Epoch [2300], val_loss: 5398.2817\n",
            "Epoch [2320], val_loss: 5395.9365\n",
            "Epoch [2340], val_loss: 5394.0508\n",
            "Epoch [2360], val_loss: 5395.3804\n",
            "Epoch [2380], val_loss: 5397.6143\n",
            "Epoch [2400], val_loss: 5394.2754\n",
            "Epoch [2420], val_loss: 5392.8481\n",
            "Epoch [2440], val_loss: 5392.6211\n",
            "Epoch [2460], val_loss: 5391.0264\n",
            "Epoch [2480], val_loss: 5391.5762\n",
            "Epoch [2500], val_loss: 5390.2085\n",
            "Epoch [2520], val_loss: 5387.9521\n",
            "Epoch [2540], val_loss: 5387.8022\n",
            "Epoch [2560], val_loss: 5387.3735\n",
            "Epoch [2580], val_loss: 5388.7979\n",
            "Epoch [2600], val_loss: 5387.0000\n",
            "Epoch [2620], val_loss: 5384.7549\n",
            "Epoch [2640], val_loss: 5384.7886\n",
            "Epoch [2660], val_loss: 5383.1729\n",
            "Epoch [2680], val_loss: 5386.2329\n",
            "Epoch [2700], val_loss: 5381.8018\n",
            "Epoch [2720], val_loss: 5383.7432\n",
            "Epoch [2740], val_loss: 5381.2979\n",
            "Epoch [2760], val_loss: 5380.2124\n",
            "Epoch [2780], val_loss: 5379.5562\n",
            "Epoch [2800], val_loss: 5377.9785\n",
            "Epoch [2820], val_loss: 5376.9883\n",
            "Epoch [2840], val_loss: 5377.3428\n",
            "Epoch [2860], val_loss: 5373.9785\n",
            "Epoch [2880], val_loss: 5379.4365\n",
            "Epoch [2900], val_loss: 5376.6104\n",
            "Epoch [2920], val_loss: 5373.3350\n",
            "Epoch [2940], val_loss: 5373.0166\n",
            "Epoch [2960], val_loss: 5374.7188\n",
            "Epoch [2980], val_loss: 5371.3984\n",
            "Epoch [3000], val_loss: 5371.2812\n",
            "Epoch [3020], val_loss: 5370.2524\n",
            "Epoch [3040], val_loss: 5370.6182\n",
            "Epoch [3060], val_loss: 5369.3589\n",
            "Epoch [3080], val_loss: 5369.5459\n",
            "Epoch [3100], val_loss: 5368.5054\n",
            "Epoch [3120], val_loss: 5365.7969\n",
            "Epoch [3140], val_loss: 5366.2559\n",
            "Epoch [3160], val_loss: 5363.5859\n",
            "Epoch [3180], val_loss: 5364.4434\n",
            "Epoch [3200], val_loss: 5365.1152\n",
            "Epoch [3220], val_loss: 5361.6978\n",
            "Epoch [3240], val_loss: 5362.2856\n",
            "Epoch [3260], val_loss: 5362.1689\n",
            "Epoch [3280], val_loss: 5362.1729\n",
            "Epoch [3300], val_loss: 5360.3242\n",
            "Epoch [3320], val_loss: 5357.9141\n",
            "Epoch [3340], val_loss: 5360.0488\n",
            "Epoch [3360], val_loss: 5355.3647\n",
            "Epoch [3380], val_loss: 5358.5518\n",
            "Epoch [3400], val_loss: 5356.8506\n",
            "Epoch [3420], val_loss: 5356.0713\n",
            "Epoch [3440], val_loss: 5351.9004\n",
            "Epoch [3460], val_loss: 5355.5161\n",
            "Epoch [3480], val_loss: 5352.9106\n",
            "Epoch [3500], val_loss: 5350.6304\n",
            "Epoch [3520], val_loss: 5351.3184\n",
            "Epoch [3540], val_loss: 5351.5000\n",
            "Epoch [3560], val_loss: 5349.2202\n",
            "Epoch [3580], val_loss: 5347.8936\n",
            "Epoch [3600], val_loss: 5347.2295\n",
            "Epoch [3620], val_loss: 5346.4180\n",
            "Epoch [3640], val_loss: 5346.9272\n",
            "Epoch [3660], val_loss: 5345.3242\n",
            "Epoch [3680], val_loss: 5347.3008\n",
            "Epoch [3700], val_loss: 5343.2539\n",
            "Epoch [3720], val_loss: 5343.0156\n",
            "Epoch [3740], val_loss: 5341.6768\n",
            "Epoch [3760], val_loss: 5340.1948\n",
            "Epoch [3780], val_loss: 5340.5146\n",
            "Epoch [3800], val_loss: 5339.7837\n",
            "Epoch [3820], val_loss: 5341.3433\n",
            "Epoch [3840], val_loss: 5339.8633\n",
            "Epoch [3860], val_loss: 5339.2100\n",
            "Epoch [3880], val_loss: 5339.7891\n",
            "Epoch [3900], val_loss: 5337.2476\n",
            "Epoch [3920], val_loss: 5335.3350\n",
            "Epoch [3940], val_loss: 5335.7334\n",
            "Epoch [3960], val_loss: 5334.3135\n",
            "Epoch [3980], val_loss: 5332.5615\n",
            "Epoch [4000], val_loss: 5331.3809\n",
            "Epoch [4020], val_loss: 5332.8184\n",
            "Epoch [4040], val_loss: 5331.5322\n",
            "Epoch [4060], val_loss: 5330.4346\n",
            "Epoch [4080], val_loss: 5330.6201\n",
            "Epoch [4100], val_loss: 5328.4521\n",
            "Epoch [4120], val_loss: 5327.5918\n",
            "Epoch [4140], val_loss: 5327.9829\n",
            "Epoch [4160], val_loss: 5327.8110\n",
            "Epoch [4180], val_loss: 5332.4121\n",
            "Epoch [4200], val_loss: 5327.1460\n",
            "Epoch [4220], val_loss: 5325.5713\n",
            "Epoch [4240], val_loss: 5325.3203\n",
            "Epoch [4260], val_loss: 5321.6509\n",
            "Epoch [4280], val_loss: 5320.3945\n",
            "Epoch [4300], val_loss: 5322.7788\n",
            "Epoch [4320], val_loss: 5323.3535\n",
            "Epoch [4340], val_loss: 5319.9126\n",
            "Epoch [4360], val_loss: 5318.1196\n",
            "Epoch [4380], val_loss: 5318.8447\n",
            "Epoch [4400], val_loss: 5319.8271\n",
            "Epoch [4420], val_loss: 5318.0586\n",
            "Epoch [4440], val_loss: 5315.2617\n",
            "Epoch [4460], val_loss: 5315.1074\n",
            "Epoch [4480], val_loss: 5314.2451\n",
            "Epoch [4500], val_loss: 5314.3867\n",
            "Epoch [4520], val_loss: 5310.9854\n",
            "Epoch [4540], val_loss: 5312.6426\n",
            "Epoch [4560], val_loss: 5313.1514\n",
            "Epoch [4580], val_loss: 5311.2520\n",
            "Epoch [4600], val_loss: 5308.2949\n",
            "Epoch [4620], val_loss: 5308.4795\n",
            "Epoch [4640], val_loss: 5311.5186\n",
            "Epoch [4660], val_loss: 5308.3032\n",
            "Epoch [4680], val_loss: 5304.8779\n",
            "Epoch [4700], val_loss: 5305.2251\n",
            "Epoch [4720], val_loss: 5307.6753\n",
            "Epoch [4740], val_loss: 5303.2842\n",
            "Epoch [4760], val_loss: 5302.0693\n",
            "Epoch [4780], val_loss: 5300.9907\n",
            "Epoch [4800], val_loss: 5302.5156\n",
            "Epoch [4820], val_loss: 5300.7744\n",
            "Epoch [4840], val_loss: 5302.7456\n",
            "Epoch [4860], val_loss: 5302.0732\n",
            "Epoch [4880], val_loss: 5298.2666\n",
            "Epoch [4900], val_loss: 5297.6870\n",
            "Epoch [4920], val_loss: 5296.0850\n",
            "Epoch [4940], val_loss: 5298.5850\n",
            "Epoch [4960], val_loss: 5296.8350\n",
            "Epoch [4980], val_loss: 5295.7041\n",
            "Epoch [5000], val_loss: 5294.1396\n",
            "Epoch [5020], val_loss: 5293.2949\n",
            "Epoch [5040], val_loss: 5293.7139\n",
            "Epoch [5060], val_loss: 5292.9023\n",
            "Epoch [5080], val_loss: 5292.2393\n",
            "Epoch [5100], val_loss: 5289.4023\n",
            "Epoch [5120], val_loss: 5289.4072\n",
            "Epoch [5140], val_loss: 5288.5586\n",
            "Epoch [5160], val_loss: 5289.2485\n",
            "Epoch [5180], val_loss: 5287.9424\n",
            "Epoch [5200], val_loss: 5288.0879\n",
            "Epoch [5220], val_loss: 5285.1855\n",
            "Epoch [5240], val_loss: 5285.4277\n",
            "Epoch [5260], val_loss: 5283.3750\n",
            "Epoch [5280], val_loss: 5286.3687\n",
            "Epoch [5300], val_loss: 5283.0234\n",
            "Epoch [5320], val_loss: 5282.3281\n",
            "Epoch [5340], val_loss: 5281.5645\n",
            "Epoch [5360], val_loss: 5280.3711\n",
            "Epoch [5380], val_loss: 5281.4053\n",
            "Epoch [5400], val_loss: 5279.5146\n",
            "Epoch [5420], val_loss: 5278.9570\n",
            "Epoch [5440], val_loss: 5275.6499\n",
            "Epoch [5460], val_loss: 5280.0186\n",
            "Epoch [5480], val_loss: 5275.0801\n",
            "Epoch [5500], val_loss: 5273.3477\n",
            "Epoch [5520], val_loss: 5277.0234\n",
            "Epoch [5540], val_loss: 5273.8188\n",
            "Epoch [5560], val_loss: 5271.9795\n",
            "Epoch [5580], val_loss: 5274.2124\n",
            "Epoch [5600], val_loss: 5269.9395\n",
            "Epoch [5620], val_loss: 5271.3252\n",
            "Epoch [5640], val_loss: 5271.9824\n",
            "Epoch [5660], val_loss: 5267.5317\n",
            "Epoch [5680], val_loss: 5267.6367\n",
            "Epoch [5700], val_loss: 5268.7891\n",
            "Epoch [5720], val_loss: 5265.2559\n",
            "Epoch [5740], val_loss: 5266.0801\n",
            "Epoch [5760], val_loss: 5267.5771\n",
            "Epoch [5780], val_loss: 5263.7012\n",
            "Epoch [5800], val_loss: 5263.0093\n",
            "Epoch [5820], val_loss: 5266.0430\n",
            "Epoch [5840], val_loss: 5263.9551\n",
            "Epoch [5860], val_loss: 5260.0576\n",
            "Epoch [5880], val_loss: 5261.3740\n",
            "Epoch [5900], val_loss: 5262.9229\n",
            "Epoch [5920], val_loss: 5261.3813\n",
            "Epoch [5940], val_loss: 5259.9893\n",
            "Epoch [5960], val_loss: 5256.5703\n",
            "Epoch [5980], val_loss: 5258.9443\n",
            "Epoch [6000], val_loss: 5257.5479\n",
            "Epoch [6020], val_loss: 5257.1060\n",
            "Epoch [6040], val_loss: 5254.1611\n",
            "Epoch [6060], val_loss: 5253.2871\n",
            "Epoch [6080], val_loss: 5251.5557\n",
            "Epoch [6100], val_loss: 5252.4551\n",
            "Epoch [6120], val_loss: 5250.7559\n",
            "Epoch [6140], val_loss: 5252.7422\n",
            "Epoch [6160], val_loss: 5250.6855\n",
            "Epoch [6180], val_loss: 5250.9839\n",
            "Epoch [6200], val_loss: 5248.2197\n",
            "Epoch [6220], val_loss: 5248.7324\n",
            "Epoch [6240], val_loss: 5247.8774\n",
            "Epoch [6260], val_loss: 5247.8501\n",
            "Epoch [6280], val_loss: 5246.6396\n",
            "Epoch [6300], val_loss: 5244.8838\n",
            "Epoch [6320], val_loss: 5244.9678\n",
            "Epoch [6340], val_loss: 5243.7725\n",
            "Epoch [6360], val_loss: 5244.8052\n",
            "Epoch [6380], val_loss: 5241.9062\n",
            "Epoch [6400], val_loss: 5238.8672\n",
            "Epoch [6420], val_loss: 5240.4863\n",
            "Epoch [6440], val_loss: 5241.5654\n",
            "Epoch [6460], val_loss: 5239.7295\n",
            "Epoch [6480], val_loss: 5237.2705\n",
            "Epoch [6500], val_loss: 5239.8447\n",
            "Epoch [6520], val_loss: 5236.6416\n",
            "Epoch [6540], val_loss: 5234.1162\n",
            "Epoch [6560], val_loss: 5235.9844\n",
            "Epoch [6580], val_loss: 5236.1592\n",
            "Epoch [6600], val_loss: 5232.4697\n",
            "Epoch [6620], val_loss: 5233.4775\n",
            "Epoch [6640], val_loss: 5232.8857\n",
            "Epoch [6660], val_loss: 5229.0190\n",
            "Epoch [6680], val_loss: 5228.2549\n",
            "Epoch [6700], val_loss: 5228.3276\n",
            "Epoch [6720], val_loss: 5229.8516\n",
            "Epoch [6740], val_loss: 5229.6938\n",
            "Epoch [6760], val_loss: 5225.9185\n",
            "Epoch [6780], val_loss: 5226.9668\n",
            "Epoch [6800], val_loss: 5225.9736\n",
            "Epoch [6820], val_loss: 5225.2651\n",
            "Epoch [6840], val_loss: 5225.4492\n",
            "Epoch [6860], val_loss: 5225.3916\n",
            "Epoch [6880], val_loss: 5223.3486\n",
            "Epoch [6900], val_loss: 5220.7896\n",
            "Epoch [6920], val_loss: 5221.0757\n",
            "Epoch [6940], val_loss: 5220.9380\n",
            "Epoch [6960], val_loss: 5220.5117\n",
            "Epoch [6980], val_loss: 5218.2700\n",
            "Epoch [7000], val_loss: 5218.7876\n",
            "Epoch [7020], val_loss: 5217.4150\n",
            "Epoch [7040], val_loss: 5216.9805\n",
            "Epoch [7060], val_loss: 5216.9844\n",
            "Epoch [7080], val_loss: 5215.4922\n",
            "Epoch [7100], val_loss: 5212.3457\n",
            "Epoch [7120], val_loss: 5212.8076\n",
            "Epoch [7140], val_loss: 5212.2275\n",
            "Epoch [7160], val_loss: 5212.5449\n",
            "Epoch [7180], val_loss: 5210.1914\n",
            "Epoch [7200], val_loss: 5211.7344\n",
            "Epoch [7220], val_loss: 5210.0176\n",
            "Epoch [7240], val_loss: 5207.1880\n",
            "Epoch [7260], val_loss: 5208.0156\n",
            "Epoch [7280], val_loss: 5207.6357\n",
            "Epoch [7300], val_loss: 5207.4077\n",
            "Epoch [7320], val_loss: 5205.0312\n",
            "Epoch [7340], val_loss: 5205.2119\n",
            "Epoch [7360], val_loss: 5206.4556\n",
            "Epoch [7380], val_loss: 5203.4883\n",
            "Epoch [7400], val_loss: 5203.2686\n",
            "Epoch [7420], val_loss: 5202.7427\n",
            "Epoch [7440], val_loss: 5201.9648\n",
            "Epoch [7460], val_loss: 5198.7524\n",
            "Epoch [7480], val_loss: 5200.5957\n",
            "Epoch [7500], val_loss: 5200.0312\n",
            "Epoch [7520], val_loss: 5198.2041\n",
            "Epoch [7540], val_loss: 5198.3359\n",
            "Epoch [7560], val_loss: 5197.3804\n",
            "Epoch [7580], val_loss: 5194.9976\n",
            "Epoch [7600], val_loss: 5194.0283\n",
            "Epoch [7620], val_loss: 5193.9385\n",
            "Epoch [7640], val_loss: 5192.8613\n",
            "Epoch [7660], val_loss: 5195.9707\n",
            "Epoch [7680], val_loss: 5191.9980\n",
            "Epoch [7700], val_loss: 5192.1978\n",
            "Epoch [7720], val_loss: 5190.6074\n",
            "Epoch [7740], val_loss: 5191.1929\n",
            "Epoch [7760], val_loss: 5189.6089\n",
            "Epoch [7780], val_loss: 5190.0786\n",
            "Epoch [7800], val_loss: 5190.2734\n",
            "Epoch [7820], val_loss: 5188.7480\n",
            "Epoch [7840], val_loss: 5185.3740\n",
            "Epoch [7860], val_loss: 5186.6396\n",
            "Epoch [7880], val_loss: 5184.7012\n",
            "Epoch [7900], val_loss: 5184.0244\n",
            "Epoch [7920], val_loss: 5181.7549\n",
            "Epoch [7940], val_loss: 5182.6074\n",
            "Epoch [7960], val_loss: 5179.8110\n",
            "Epoch [7980], val_loss: 5179.4893\n",
            "Epoch [8000], val_loss: 5183.0332\n",
            "Epoch [8020], val_loss: 5180.6826\n",
            "Epoch [8040], val_loss: 5177.9258\n",
            "Epoch [8060], val_loss: 5178.3027\n",
            "Epoch [8080], val_loss: 5176.2783\n",
            "Epoch [8100], val_loss: 5174.1006\n",
            "Epoch [8120], val_loss: 5174.8418\n",
            "Epoch [8140], val_loss: 5173.2383\n",
            "Epoch [8160], val_loss: 5173.9380\n",
            "Epoch [8180], val_loss: 5172.5596\n",
            "Epoch [8200], val_loss: 5172.3652\n",
            "Epoch [8220], val_loss: 5173.5420\n",
            "Epoch [8240], val_loss: 5172.2002\n",
            "Epoch [8260], val_loss: 5171.3853\n",
            "Epoch [8280], val_loss: 5167.8550\n",
            "Epoch [8300], val_loss: 5171.9062\n",
            "Epoch [8320], val_loss: 5166.6851\n",
            "Epoch [8340], val_loss: 5165.9824\n",
            "Epoch [8360], val_loss: 5169.7285\n",
            "Epoch [8380], val_loss: 5166.4648\n",
            "Epoch [8400], val_loss: 5165.8438\n",
            "Epoch [8420], val_loss: 5162.3311\n",
            "Epoch [8440], val_loss: 5164.4072\n",
            "Epoch [8460], val_loss: 5162.8486\n",
            "Epoch [8480], val_loss: 5164.0908\n",
            "Epoch [8500], val_loss: 5161.0615\n",
            "Epoch [8520], val_loss: 5164.2070\n",
            "Epoch [8540], val_loss: 5159.4561\n",
            "Epoch [8560], val_loss: 5158.8223\n",
            "Epoch [8580], val_loss: 5160.1255\n",
            "Epoch [8600], val_loss: 5155.1157\n",
            "Epoch [8620], val_loss: 5158.6201\n",
            "Epoch [8640], val_loss: 5154.9463\n",
            "Epoch [8660], val_loss: 5156.6348\n",
            "Epoch [8680], val_loss: 5154.7632\n",
            "Epoch [8700], val_loss: 5151.4932\n",
            "Epoch [8720], val_loss: 5153.2119\n",
            "Epoch [8740], val_loss: 5151.2202\n",
            "Epoch [8760], val_loss: 5149.6475\n",
            "Epoch [8780], val_loss: 5151.1265\n",
            "Epoch [8800], val_loss: 5147.5195\n",
            "Epoch [8820], val_loss: 5148.2852\n",
            "Epoch [8840], val_loss: 5149.0781\n",
            "Epoch [8860], val_loss: 5148.3877\n",
            "Epoch [8880], val_loss: 5146.4019\n",
            "Epoch [8900], val_loss: 5143.8398\n",
            "Epoch [8920], val_loss: 5146.6465\n",
            "Epoch [8940], val_loss: 5146.1890\n",
            "Epoch [8960], val_loss: 5142.7788\n",
            "Epoch [8980], val_loss: 5143.0435\n",
            "Epoch [9000], val_loss: 5140.8613\n",
            "Epoch [9020], val_loss: 5141.1641\n",
            "Epoch [9040], val_loss: 5142.7471\n",
            "Epoch [9060], val_loss: 5137.6362\n",
            "Epoch [9080], val_loss: 5138.0146\n",
            "Epoch [9100], val_loss: 5142.1875\n",
            "Epoch [9120], val_loss: 5137.9268\n",
            "Epoch [9140], val_loss: 5138.2378\n",
            "Epoch [9160], val_loss: 5136.8896\n",
            "Epoch [9180], val_loss: 5133.1045\n",
            "Epoch [9200], val_loss: 5136.4688\n",
            "Epoch [9220], val_loss: 5132.7827\n",
            "Epoch [9240], val_loss: 5132.7568\n",
            "Epoch [9260], val_loss: 5129.9458\n",
            "Epoch [9280], val_loss: 5130.7007\n",
            "Epoch [9300], val_loss: 5130.0044\n",
            "Epoch [9320], val_loss: 5130.7500\n",
            "Epoch [9340], val_loss: 5127.9263\n",
            "Epoch [9360], val_loss: 5127.4775\n",
            "Epoch [9380], val_loss: 5128.1836\n",
            "Epoch [9400], val_loss: 5126.0479\n",
            "Epoch [9420], val_loss: 5125.3936\n",
            "Epoch [9440], val_loss: 5124.5547\n",
            "Epoch [9460], val_loss: 5124.2261\n",
            "Epoch [9480], val_loss: 5123.1338\n",
            "Epoch [9500], val_loss: 5123.2656\n",
            "Epoch [9520], val_loss: 5122.5679\n",
            "Epoch [9540], val_loss: 5119.6289\n",
            "Epoch [9560], val_loss: 5121.3511\n",
            "Epoch [9580], val_loss: 5120.4355\n",
            "Epoch [9600], val_loss: 5119.1138\n",
            "Epoch [9620], val_loss: 5118.3687\n",
            "Epoch [9640], val_loss: 5117.9590\n",
            "Epoch [9660], val_loss: 5118.2119\n",
            "Epoch [9680], val_loss: 5117.7725\n",
            "Epoch [9700], val_loss: 5114.4229\n",
            "Epoch [9720], val_loss: 5116.7192\n",
            "Epoch [9740], val_loss: 5113.2231\n",
            "Epoch [9760], val_loss: 5113.3110\n",
            "Epoch [9780], val_loss: 5112.4492\n",
            "Epoch [9800], val_loss: 5113.1201\n",
            "Epoch [9820], val_loss: 5109.4478\n",
            "Epoch [9840], val_loss: 5109.3711\n",
            "Epoch [9860], val_loss: 5107.7583\n",
            "Epoch [9880], val_loss: 5108.8164\n",
            "Epoch [9900], val_loss: 5108.4263\n",
            "Epoch [9920], val_loss: 5106.8174\n",
            "Epoch [9940], val_loss: 5103.9717\n",
            "Epoch [9960], val_loss: 5107.1313\n",
            "Epoch [9980], val_loss: 5105.7012\n",
            "Epoch [10000], val_loss: 5103.0791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc-AvGirBrdF",
        "outputId": "ecba0690-b231-41c0-9f51-f3951336fc38"
      },
      "source": [
        "epochs = 30000\r\n",
        "lr = 1e-1\r\n",
        "history7 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5104.0537\n",
            "Epoch [40], val_loss: 5103.3311\n",
            "Epoch [60], val_loss: 5102.5220\n",
            "Epoch [80], val_loss: 5100.1860\n",
            "Epoch [100], val_loss: 5099.6875\n",
            "Epoch [120], val_loss: 5100.8096\n",
            "Epoch [140], val_loss: 5097.5537\n",
            "Epoch [160], val_loss: 5097.7344\n",
            "Epoch [180], val_loss: 5098.1274\n",
            "Epoch [200], val_loss: 5099.5137\n",
            "Epoch [220], val_loss: 5097.1934\n",
            "Epoch [240], val_loss: 5095.9209\n",
            "Epoch [260], val_loss: 5095.1387\n",
            "Epoch [280], val_loss: 5092.2061\n",
            "Epoch [300], val_loss: 5092.2520\n",
            "Epoch [320], val_loss: 5092.8281\n",
            "Epoch [340], val_loss: 5094.2612\n",
            "Epoch [360], val_loss: 5093.8130\n",
            "Epoch [380], val_loss: 5087.6660\n",
            "Epoch [400], val_loss: 5087.0664\n",
            "Epoch [420], val_loss: 5088.0898\n",
            "Epoch [440], val_loss: 5086.9844\n",
            "Epoch [460], val_loss: 5089.1748\n",
            "Epoch [480], val_loss: 5084.2031\n",
            "Epoch [500], val_loss: 5086.3203\n",
            "Epoch [520], val_loss: 5082.1919\n",
            "Epoch [540], val_loss: 5083.0938\n",
            "Epoch [560], val_loss: 5081.9214\n",
            "Epoch [580], val_loss: 5080.6641\n",
            "Epoch [600], val_loss: 5080.9551\n",
            "Epoch [620], val_loss: 5081.2607\n",
            "Epoch [640], val_loss: 5080.2515\n",
            "Epoch [660], val_loss: 5080.3301\n",
            "Epoch [680], val_loss: 5079.8262\n",
            "Epoch [700], val_loss: 5078.8633\n",
            "Epoch [720], val_loss: 5078.3979\n",
            "Epoch [740], val_loss: 5079.2373\n",
            "Epoch [760], val_loss: 5074.7656\n",
            "Epoch [780], val_loss: 5072.5229\n",
            "Epoch [800], val_loss: 5075.1631\n",
            "Epoch [820], val_loss: 5074.6738\n",
            "Epoch [840], val_loss: 5072.4580\n",
            "Epoch [860], val_loss: 5070.9531\n",
            "Epoch [880], val_loss: 5070.3892\n",
            "Epoch [900], val_loss: 5069.4590\n",
            "Epoch [920], val_loss: 5068.0928\n",
            "Epoch [940], val_loss: 5071.7310\n",
            "Epoch [960], val_loss: 5067.8945\n",
            "Epoch [980], val_loss: 5066.9629\n",
            "Epoch [1000], val_loss: 5063.5820\n",
            "Epoch [1020], val_loss: 5063.8867\n",
            "Epoch [1040], val_loss: 5063.8574\n",
            "Epoch [1060], val_loss: 5064.3628\n",
            "Epoch [1080], val_loss: 5061.6895\n",
            "Epoch [1100], val_loss: 5061.4390\n",
            "Epoch [1120], val_loss: 5061.6304\n",
            "Epoch [1140], val_loss: 5059.0381\n",
            "Epoch [1160], val_loss: 5060.4761\n",
            "Epoch [1180], val_loss: 5060.6035\n",
            "Epoch [1200], val_loss: 5056.3701\n",
            "Epoch [1220], val_loss: 5058.0376\n",
            "Epoch [1240], val_loss: 5058.1250\n",
            "Epoch [1260], val_loss: 5056.1406\n",
            "Epoch [1280], val_loss: 5056.5396\n",
            "Epoch [1300], val_loss: 5054.2227\n",
            "Epoch [1320], val_loss: 5054.2451\n",
            "Epoch [1340], val_loss: 5053.3291\n",
            "Epoch [1360], val_loss: 5053.4805\n",
            "Epoch [1380], val_loss: 5049.1489\n",
            "Epoch [1400], val_loss: 5051.9756\n",
            "Epoch [1420], val_loss: 5047.7446\n",
            "Epoch [1440], val_loss: 5050.5107\n",
            "Epoch [1460], val_loss: 5048.9229\n",
            "Epoch [1480], val_loss: 5050.8281\n",
            "Epoch [1500], val_loss: 5047.3335\n",
            "Epoch [1520], val_loss: 5044.3193\n",
            "Epoch [1540], val_loss: 5045.5244\n",
            "Epoch [1560], val_loss: 5046.0029\n",
            "Epoch [1580], val_loss: 5042.9170\n",
            "Epoch [1600], val_loss: 5042.9277\n",
            "Epoch [1620], val_loss: 5041.6992\n",
            "Epoch [1640], val_loss: 5041.4727\n",
            "Epoch [1660], val_loss: 5041.7725\n",
            "Epoch [1680], val_loss: 5039.2490\n",
            "Epoch [1700], val_loss: 5040.2422\n",
            "Epoch [1720], val_loss: 5038.6230\n",
            "Epoch [1740], val_loss: 5036.0771\n",
            "Epoch [1760], val_loss: 5038.4380\n",
            "Epoch [1780], val_loss: 5038.1572\n",
            "Epoch [1800], val_loss: 5035.2998\n",
            "Epoch [1820], val_loss: 5037.8984\n",
            "Epoch [1840], val_loss: 5036.0312\n",
            "Epoch [1860], val_loss: 5032.4014\n",
            "Epoch [1880], val_loss: 5031.2925\n",
            "Epoch [1900], val_loss: 5032.1807\n",
            "Epoch [1920], val_loss: 5029.4058\n",
            "Epoch [1940], val_loss: 5028.6553\n",
            "Epoch [1960], val_loss: 5028.3848\n",
            "Epoch [1980], val_loss: 5027.8398\n",
            "Epoch [2000], val_loss: 5029.4126\n",
            "Epoch [2020], val_loss: 5028.4653\n",
            "Epoch [2040], val_loss: 5029.8169\n",
            "Epoch [2060], val_loss: 5023.9893\n",
            "Epoch [2080], val_loss: 5025.2021\n",
            "Epoch [2100], val_loss: 5023.4790\n",
            "Epoch [2120], val_loss: 5023.5820\n",
            "Epoch [2140], val_loss: 5023.3535\n",
            "Epoch [2160], val_loss: 5022.9189\n",
            "Epoch [2180], val_loss: 5019.3540\n",
            "Epoch [2200], val_loss: 5021.8496\n",
            "Epoch [2220], val_loss: 5019.5903\n",
            "Epoch [2240], val_loss: 5019.7490\n",
            "Epoch [2260], val_loss: 5018.5898\n",
            "Epoch [2280], val_loss: 5017.9624\n",
            "Epoch [2300], val_loss: 5016.3013\n",
            "Epoch [2320], val_loss: 5013.7803\n",
            "Epoch [2340], val_loss: 5014.7197\n",
            "Epoch [2360], val_loss: 5015.1357\n",
            "Epoch [2380], val_loss: 5015.4756\n",
            "Epoch [2400], val_loss: 5014.5068\n",
            "Epoch [2420], val_loss: 5013.5781\n",
            "Epoch [2440], val_loss: 5012.2739\n",
            "Epoch [2460], val_loss: 5008.1982\n",
            "Epoch [2480], val_loss: 5009.2129\n",
            "Epoch [2500], val_loss: 5008.7559\n",
            "Epoch [2520], val_loss: 5009.1382\n",
            "Epoch [2540], val_loss: 5005.5459\n",
            "Epoch [2560], val_loss: 5005.6587\n",
            "Epoch [2580], val_loss: 5003.7637\n",
            "Epoch [2600], val_loss: 5004.8179\n",
            "Epoch [2620], val_loss: 5004.4204\n",
            "Epoch [2640], val_loss: 5005.6084\n",
            "Epoch [2660], val_loss: 5003.2798\n",
            "Epoch [2680], val_loss: 5003.0850\n",
            "Epoch [2700], val_loss: 5000.9482\n",
            "Epoch [2720], val_loss: 5000.4434\n",
            "Epoch [2740], val_loss: 4998.9150\n",
            "Epoch [2760], val_loss: 4998.6787\n",
            "Epoch [2780], val_loss: 5000.5327\n",
            "Epoch [2800], val_loss: 4996.5322\n",
            "Epoch [2820], val_loss: 4995.7847\n",
            "Epoch [2840], val_loss: 4993.8311\n",
            "Epoch [2860], val_loss: 4993.0977\n",
            "Epoch [2880], val_loss: 4994.2031\n",
            "Epoch [2900], val_loss: 4993.0630\n",
            "Epoch [2920], val_loss: 4993.7041\n",
            "Epoch [2940], val_loss: 4992.6836\n",
            "Epoch [2960], val_loss: 4991.5898\n",
            "Epoch [2980], val_loss: 4992.5049\n",
            "Epoch [3000], val_loss: 4989.8369\n",
            "Epoch [3020], val_loss: 4991.0757\n",
            "Epoch [3040], val_loss: 4986.7437\n",
            "Epoch [3060], val_loss: 4987.6680\n",
            "Epoch [3080], val_loss: 4987.5806\n",
            "Epoch [3100], val_loss: 4986.7227\n",
            "Epoch [3120], val_loss: 4984.3877\n",
            "Epoch [3140], val_loss: 4987.2227\n",
            "Epoch [3160], val_loss: 4981.5142\n",
            "Epoch [3180], val_loss: 4984.2129\n",
            "Epoch [3200], val_loss: 4983.1670\n",
            "Epoch [3220], val_loss: 4981.4531\n",
            "Epoch [3240], val_loss: 4980.9883\n",
            "Epoch [3260], val_loss: 4979.1680\n",
            "Epoch [3280], val_loss: 4977.1250\n",
            "Epoch [3300], val_loss: 4980.6240\n",
            "Epoch [3320], val_loss: 4975.3081\n",
            "Epoch [3340], val_loss: 4975.5093\n",
            "Epoch [3360], val_loss: 4974.0420\n",
            "Epoch [3380], val_loss: 4973.7153\n",
            "Epoch [3400], val_loss: 4974.1016\n",
            "Epoch [3420], val_loss: 4972.7617\n",
            "Epoch [3440], val_loss: 4971.1611\n",
            "Epoch [3460], val_loss: 4971.1440\n",
            "Epoch [3480], val_loss: 4969.2256\n",
            "Epoch [3500], val_loss: 4970.5576\n",
            "Epoch [3520], val_loss: 4970.0801\n",
            "Epoch [3540], val_loss: 4970.3965\n",
            "Epoch [3560], val_loss: 4970.0869\n",
            "Epoch [3580], val_loss: 4966.0000\n",
            "Epoch [3600], val_loss: 4966.9185\n",
            "Epoch [3620], val_loss: 4965.9688\n",
            "Epoch [3640], val_loss: 4968.7729\n",
            "Epoch [3660], val_loss: 4962.5889\n",
            "Epoch [3680], val_loss: 4966.7930\n",
            "Epoch [3700], val_loss: 4963.9858\n",
            "Epoch [3720], val_loss: 4961.7793\n",
            "Epoch [3740], val_loss: 4962.9062\n",
            "Epoch [3760], val_loss: 4961.0664\n",
            "Epoch [3780], val_loss: 4958.0498\n",
            "Epoch [3800], val_loss: 4960.2549\n",
            "Epoch [3820], val_loss: 4960.4658\n",
            "Epoch [3840], val_loss: 4958.5762\n",
            "Epoch [3860], val_loss: 4957.6523\n",
            "Epoch [3880], val_loss: 4956.3711\n",
            "Epoch [3900], val_loss: 4957.0781\n",
            "Epoch [3920], val_loss: 4958.0996\n",
            "Epoch [3940], val_loss: 4954.5352\n",
            "Epoch [3960], val_loss: 4956.4541\n",
            "Epoch [3980], val_loss: 4953.5225\n",
            "Epoch [4000], val_loss: 4953.4395\n",
            "Epoch [4020], val_loss: 4949.3613\n",
            "Epoch [4040], val_loss: 4949.5449\n",
            "Epoch [4060], val_loss: 4948.6333\n",
            "Epoch [4080], val_loss: 4949.7769\n",
            "Epoch [4100], val_loss: 4946.0518\n",
            "Epoch [4120], val_loss: 4945.3252\n",
            "Epoch [4140], val_loss: 4947.0078\n",
            "Epoch [4160], val_loss: 4944.5762\n",
            "Epoch [4180], val_loss: 4943.4414\n",
            "Epoch [4200], val_loss: 4943.8403\n",
            "Epoch [4220], val_loss: 4941.5391\n",
            "Epoch [4240], val_loss: 4942.5054\n",
            "Epoch [4260], val_loss: 4939.6113\n",
            "Epoch [4280], val_loss: 4938.8706\n",
            "Epoch [4300], val_loss: 4941.4502\n",
            "Epoch [4320], val_loss: 4937.5986\n",
            "Epoch [4340], val_loss: 4939.8916\n",
            "Epoch [4360], val_loss: 4939.5962\n",
            "Epoch [4380], val_loss: 4936.1084\n",
            "Epoch [4400], val_loss: 4937.9160\n",
            "Epoch [4420], val_loss: 4934.3252\n",
            "Epoch [4440], val_loss: 4936.8594\n",
            "Epoch [4460], val_loss: 4934.3271\n",
            "Epoch [4480], val_loss: 4933.8984\n",
            "Epoch [4500], val_loss: 4934.9941\n",
            "Epoch [4520], val_loss: 4930.9570\n",
            "Epoch [4540], val_loss: 4930.7119\n",
            "Epoch [4560], val_loss: 4932.3086\n",
            "Epoch [4580], val_loss: 4930.9580\n",
            "Epoch [4600], val_loss: 4930.0420\n",
            "Epoch [4620], val_loss: 4929.6182\n",
            "Epoch [4640], val_loss: 4927.8418\n",
            "Epoch [4660], val_loss: 4925.4863\n",
            "Epoch [4680], val_loss: 4926.5947\n",
            "Epoch [4700], val_loss: 4924.7026\n",
            "Epoch [4720], val_loss: 4925.6499\n",
            "Epoch [4740], val_loss: 4921.3311\n",
            "Epoch [4760], val_loss: 4924.0586\n",
            "Epoch [4780], val_loss: 4923.0488\n",
            "Epoch [4800], val_loss: 4921.9580\n",
            "Epoch [4820], val_loss: 4920.7300\n",
            "Epoch [4840], val_loss: 4920.4980\n",
            "Epoch [4860], val_loss: 4917.9673\n",
            "Epoch [4880], val_loss: 4919.1567\n",
            "Epoch [4900], val_loss: 4916.9189\n",
            "Epoch [4920], val_loss: 4916.0811\n",
            "Epoch [4940], val_loss: 4914.6758\n",
            "Epoch [4960], val_loss: 4913.3174\n",
            "Epoch [4980], val_loss: 4914.8066\n",
            "Epoch [5000], val_loss: 4912.5273\n",
            "Epoch [5020], val_loss: 4912.6777\n",
            "Epoch [5040], val_loss: 4910.0557\n",
            "Epoch [5060], val_loss: 4912.1748\n",
            "Epoch [5080], val_loss: 4911.6133\n",
            "Epoch [5100], val_loss: 4911.3281\n",
            "Epoch [5120], val_loss: 4908.6484\n",
            "Epoch [5140], val_loss: 4908.8770\n",
            "Epoch [5160], val_loss: 4907.8760\n",
            "Epoch [5180], val_loss: 4907.2744\n",
            "Epoch [5200], val_loss: 4904.0654\n",
            "Epoch [5220], val_loss: 4903.7764\n",
            "Epoch [5240], val_loss: 4903.6084\n",
            "Epoch [5260], val_loss: 4902.9785\n",
            "Epoch [5280], val_loss: 4904.4160\n",
            "Epoch [5300], val_loss: 4904.3760\n",
            "Epoch [5320], val_loss: 4901.4414\n",
            "Epoch [5340], val_loss: 4900.4609\n",
            "Epoch [5360], val_loss: 4899.9209\n",
            "Epoch [5380], val_loss: 4901.5527\n",
            "Epoch [5400], val_loss: 4896.0596\n",
            "Epoch [5420], val_loss: 4897.2119\n",
            "Epoch [5440], val_loss: 4895.9658\n",
            "Epoch [5460], val_loss: 4896.6807\n",
            "Epoch [5480], val_loss: 4895.5840\n",
            "Epoch [5500], val_loss: 4894.4980\n",
            "Epoch [5520], val_loss: 4898.1016\n",
            "Epoch [5540], val_loss: 4892.6152\n",
            "Epoch [5560], val_loss: 4890.9902\n",
            "Epoch [5580], val_loss: 4893.0938\n",
            "Epoch [5600], val_loss: 4890.2744\n",
            "Epoch [5620], val_loss: 4893.0718\n",
            "Epoch [5640], val_loss: 4892.2988\n",
            "Epoch [5660], val_loss: 4887.1455\n",
            "Epoch [5680], val_loss: 4888.9570\n",
            "Epoch [5700], val_loss: 4889.6060\n",
            "Epoch [5720], val_loss: 4884.7754\n",
            "Epoch [5740], val_loss: 4883.3311\n",
            "Epoch [5760], val_loss: 4885.8896\n",
            "Epoch [5780], val_loss: 4883.6001\n",
            "Epoch [5800], val_loss: 4886.9946\n",
            "Epoch [5820], val_loss: 4881.2578\n",
            "Epoch [5840], val_loss: 4880.4736\n",
            "Epoch [5860], val_loss: 4882.4658\n",
            "Epoch [5880], val_loss: 4879.8477\n",
            "Epoch [5900], val_loss: 4877.8281\n",
            "Epoch [5920], val_loss: 4879.8496\n",
            "Epoch [5940], val_loss: 4876.7148\n",
            "Epoch [5960], val_loss: 4877.6016\n",
            "Epoch [5980], val_loss: 4877.5742\n",
            "Epoch [6000], val_loss: 4878.1367\n",
            "Epoch [6020], val_loss: 4874.4629\n",
            "Epoch [6040], val_loss: 4872.2764\n",
            "Epoch [6060], val_loss: 4873.1206\n",
            "Epoch [6080], val_loss: 4874.6572\n",
            "Epoch [6100], val_loss: 4872.6157\n",
            "Epoch [6120], val_loss: 4874.2588\n",
            "Epoch [6140], val_loss: 4872.8501\n",
            "Epoch [6160], val_loss: 4869.4663\n",
            "Epoch [6180], val_loss: 4866.4639\n",
            "Epoch [6200], val_loss: 4868.4038\n",
            "Epoch [6220], val_loss: 4868.4971\n",
            "Epoch [6240], val_loss: 4865.6816\n",
            "Epoch [6260], val_loss: 4864.2969\n",
            "Epoch [6280], val_loss: 4863.1030\n",
            "Epoch [6300], val_loss: 4863.1465\n",
            "Epoch [6320], val_loss: 4862.6514\n",
            "Epoch [6340], val_loss: 4861.1191\n",
            "Epoch [6360], val_loss: 4861.5859\n",
            "Epoch [6380], val_loss: 4858.9082\n",
            "Epoch [6400], val_loss: 4858.0625\n",
            "Epoch [6420], val_loss: 4857.2803\n",
            "Epoch [6440], val_loss: 4858.2031\n",
            "Epoch [6460], val_loss: 4855.8267\n",
            "Epoch [6480], val_loss: 4856.7549\n",
            "Epoch [6500], val_loss: 4858.3862\n",
            "Epoch [6520], val_loss: 4853.5869\n",
            "Epoch [6540], val_loss: 4854.5796\n",
            "Epoch [6560], val_loss: 4857.9761\n",
            "Epoch [6580], val_loss: 4851.2100\n",
            "Epoch [6600], val_loss: 4852.6064\n",
            "Epoch [6620], val_loss: 4852.7236\n",
            "Epoch [6640], val_loss: 4851.2021\n",
            "Epoch [6660], val_loss: 4849.6152\n",
            "Epoch [6680], val_loss: 4850.6426\n",
            "Epoch [6700], val_loss: 4850.6445\n",
            "Epoch [6720], val_loss: 4849.7500\n",
            "Epoch [6740], val_loss: 4848.5977\n",
            "Epoch [6760], val_loss: 4849.0649\n",
            "Epoch [6780], val_loss: 4844.4502\n",
            "Epoch [6800], val_loss: 4844.5479\n",
            "Epoch [6820], val_loss: 4845.1553\n",
            "Epoch [6840], val_loss: 4847.3765\n",
            "Epoch [6860], val_loss: 4842.3174\n",
            "Epoch [6880], val_loss: 4844.1689\n",
            "Epoch [6900], val_loss: 4841.5967\n",
            "Epoch [6920], val_loss: 4841.9961\n",
            "Epoch [6940], val_loss: 4841.4004\n",
            "Epoch [6960], val_loss: 4837.8086\n",
            "Epoch [6980], val_loss: 4836.8857\n",
            "Epoch [7000], val_loss: 4837.0518\n",
            "Epoch [7020], val_loss: 4838.5010\n",
            "Epoch [7040], val_loss: 4835.9258\n",
            "Epoch [7060], val_loss: 4835.2207\n",
            "Epoch [7080], val_loss: 4835.1641\n",
            "Epoch [7100], val_loss: 4835.2051\n",
            "Epoch [7120], val_loss: 4832.6113\n",
            "Epoch [7140], val_loss: 4831.3838\n",
            "Epoch [7160], val_loss: 4829.1709\n",
            "Epoch [7180], val_loss: 4830.2432\n",
            "Epoch [7200], val_loss: 4832.0654\n",
            "Epoch [7220], val_loss: 4829.3643\n",
            "Epoch [7240], val_loss: 4829.7383\n",
            "Epoch [7260], val_loss: 4828.9238\n",
            "Epoch [7280], val_loss: 4827.4043\n",
            "Epoch [7300], val_loss: 4826.2451\n",
            "Epoch [7320], val_loss: 4824.7842\n",
            "Epoch [7340], val_loss: 4825.8271\n",
            "Epoch [7360], val_loss: 4822.6055\n",
            "Epoch [7380], val_loss: 4825.1240\n",
            "Epoch [7400], val_loss: 4820.1494\n",
            "Epoch [7420], val_loss: 4822.8677\n",
            "Epoch [7440], val_loss: 4818.6523\n",
            "Epoch [7460], val_loss: 4819.7178\n",
            "Epoch [7480], val_loss: 4819.1323\n",
            "Epoch [7500], val_loss: 4818.1909\n",
            "Epoch [7520], val_loss: 4817.3271\n",
            "Epoch [7540], val_loss: 4816.1357\n",
            "Epoch [7560], val_loss: 4817.5376\n",
            "Epoch [7580], val_loss: 4817.2305\n",
            "Epoch [7600], val_loss: 4813.9102\n",
            "Epoch [7620], val_loss: 4813.4067\n",
            "Epoch [7640], val_loss: 4810.9316\n",
            "Epoch [7660], val_loss: 4812.4253\n",
            "Epoch [7680], val_loss: 4814.4873\n",
            "Epoch [7700], val_loss: 4812.2773\n",
            "Epoch [7720], val_loss: 4810.4429\n",
            "Epoch [7740], val_loss: 4813.1377\n",
            "Epoch [7760], val_loss: 4810.0986\n",
            "Epoch [7780], val_loss: 4806.4868\n",
            "Epoch [7800], val_loss: 4807.0610\n",
            "Epoch [7820], val_loss: 4808.5000\n",
            "Epoch [7840], val_loss: 4803.7822\n",
            "Epoch [7860], val_loss: 4804.9653\n",
            "Epoch [7880], val_loss: 4807.3691\n",
            "Epoch [7900], val_loss: 4804.1943\n",
            "Epoch [7920], val_loss: 4800.6133\n",
            "Epoch [7940], val_loss: 4800.7314\n",
            "Epoch [7960], val_loss: 4799.6123\n",
            "Epoch [7980], val_loss: 4798.0703\n",
            "Epoch [8000], val_loss: 4799.9580\n",
            "Epoch [8020], val_loss: 4798.2041\n",
            "Epoch [8040], val_loss: 4800.1030\n",
            "Epoch [8060], val_loss: 4797.7173\n",
            "Epoch [8080], val_loss: 4795.4180\n",
            "Epoch [8100], val_loss: 4795.6567\n",
            "Epoch [8120], val_loss: 4795.2920\n",
            "Epoch [8140], val_loss: 4795.4209\n",
            "Epoch [8160], val_loss: 4795.1675\n",
            "Epoch [8180], val_loss: 4790.5400\n",
            "Epoch [8200], val_loss: 4791.8872\n",
            "Epoch [8220], val_loss: 4788.8994\n",
            "Epoch [8240], val_loss: 4791.9883\n",
            "Epoch [8260], val_loss: 4789.7861\n",
            "Epoch [8280], val_loss: 4786.8408\n",
            "Epoch [8300], val_loss: 4787.9648\n",
            "Epoch [8320], val_loss: 4786.4297\n",
            "Epoch [8340], val_loss: 4786.3125\n",
            "Epoch [8360], val_loss: 4787.5938\n",
            "Epoch [8380], val_loss: 4785.0977\n",
            "Epoch [8400], val_loss: 4783.7720\n",
            "Epoch [8420], val_loss: 4787.1641\n",
            "Epoch [8440], val_loss: 4782.8037\n",
            "Epoch [8460], val_loss: 4779.9980\n",
            "Epoch [8480], val_loss: 4780.9277\n",
            "Epoch [8500], val_loss: 4779.8359\n",
            "Epoch [8520], val_loss: 4779.2959\n",
            "Epoch [8540], val_loss: 4779.0400\n",
            "Epoch [8560], val_loss: 4778.7007\n",
            "Epoch [8580], val_loss: 4779.1084\n",
            "Epoch [8600], val_loss: 4776.7158\n",
            "Epoch [8620], val_loss: 4773.7871\n",
            "Epoch [8640], val_loss: 4775.2622\n",
            "Epoch [8660], val_loss: 4772.3213\n",
            "Epoch [8680], val_loss: 4774.2549\n",
            "Epoch [8700], val_loss: 4775.4121\n",
            "Epoch [8720], val_loss: 4771.5879\n",
            "Epoch [8740], val_loss: 4773.2061\n",
            "Epoch [8760], val_loss: 4772.1992\n",
            "Epoch [8780], val_loss: 4769.2109\n",
            "Epoch [8800], val_loss: 4768.5693\n",
            "Epoch [8820], val_loss: 4768.6318\n",
            "Epoch [8840], val_loss: 4769.2539\n",
            "Epoch [8860], val_loss: 4765.6738\n",
            "Epoch [8880], val_loss: 4768.0127\n",
            "Epoch [8900], val_loss: 4766.4473\n",
            "Epoch [8920], val_loss: 4764.5410\n",
            "Epoch [8940], val_loss: 4763.4990\n",
            "Epoch [8960], val_loss: 4764.5967\n",
            "Epoch [8980], val_loss: 4762.4473\n",
            "Epoch [9000], val_loss: 4760.9824\n",
            "Epoch [9020], val_loss: 4761.0435\n",
            "Epoch [9040], val_loss: 4758.0010\n",
            "Epoch [9060], val_loss: 4758.9028\n",
            "Epoch [9080], val_loss: 4760.7832\n",
            "Epoch [9100], val_loss: 4758.6030\n",
            "Epoch [9120], val_loss: 4757.9849\n",
            "Epoch [9140], val_loss: 4755.4370\n",
            "Epoch [9160], val_loss: 4755.1123\n",
            "Epoch [9180], val_loss: 4753.4263\n",
            "Epoch [9200], val_loss: 4757.5137\n",
            "Epoch [9220], val_loss: 4752.2939\n",
            "Epoch [9240], val_loss: 4751.9385\n",
            "Epoch [9260], val_loss: 4753.6895\n",
            "Epoch [9280], val_loss: 4753.1182\n",
            "Epoch [9300], val_loss: 4748.1016\n",
            "Epoch [9320], val_loss: 4748.1797\n",
            "Epoch [9340], val_loss: 4746.7017\n",
            "Epoch [9360], val_loss: 4750.3535\n",
            "Epoch [9380], val_loss: 4745.2920\n",
            "Epoch [9400], val_loss: 4746.1689\n",
            "Epoch [9420], val_loss: 4745.4277\n",
            "Epoch [9440], val_loss: 4745.6992\n",
            "Epoch [9460], val_loss: 4746.5654\n",
            "Epoch [9480], val_loss: 4741.4805\n",
            "Epoch [9500], val_loss: 4743.5659\n",
            "Epoch [9520], val_loss: 4744.0938\n",
            "Epoch [9540], val_loss: 4739.1401\n",
            "Epoch [9560], val_loss: 4744.6846\n",
            "Epoch [9580], val_loss: 4741.0005\n",
            "Epoch [9600], val_loss: 4738.1064\n",
            "Epoch [9620], val_loss: 4739.6230\n",
            "Epoch [9640], val_loss: 4736.0327\n",
            "Epoch [9660], val_loss: 4735.1836\n",
            "Epoch [9680], val_loss: 4738.1128\n",
            "Epoch [9700], val_loss: 4733.0400\n",
            "Epoch [9720], val_loss: 4735.1685\n",
            "Epoch [9740], val_loss: 4734.2168\n",
            "Epoch [9760], val_loss: 4731.8691\n",
            "Epoch [9780], val_loss: 4730.7886\n",
            "Epoch [9800], val_loss: 4730.0259\n",
            "Epoch [9820], val_loss: 4729.8633\n",
            "Epoch [9840], val_loss: 4730.4082\n",
            "Epoch [9860], val_loss: 4730.4072\n",
            "Epoch [9880], val_loss: 4726.8330\n",
            "Epoch [9900], val_loss: 4725.8721\n",
            "Epoch [9920], val_loss: 4729.4023\n",
            "Epoch [9940], val_loss: 4724.3701\n",
            "Epoch [9960], val_loss: 4725.9985\n",
            "Epoch [9980], val_loss: 4728.1611\n",
            "Epoch [10000], val_loss: 4723.0371\n",
            "Epoch [10020], val_loss: 4725.0791\n",
            "Epoch [10040], val_loss: 4721.6611\n",
            "Epoch [10060], val_loss: 4719.5127\n",
            "Epoch [10080], val_loss: 4722.8931\n",
            "Epoch [10100], val_loss: 4719.7524\n",
            "Epoch [10120], val_loss: 4717.2393\n",
            "Epoch [10140], val_loss: 4717.7861\n",
            "Epoch [10160], val_loss: 4716.1523\n",
            "Epoch [10180], val_loss: 4714.9302\n",
            "Epoch [10200], val_loss: 4716.7725\n",
            "Epoch [10220], val_loss: 4717.8330\n",
            "Epoch [10240], val_loss: 4715.4326\n",
            "Epoch [10260], val_loss: 4713.0166\n",
            "Epoch [10280], val_loss: 4713.0234\n",
            "Epoch [10300], val_loss: 4711.4961\n",
            "Epoch [10320], val_loss: 4709.7246\n",
            "Epoch [10340], val_loss: 4711.3311\n",
            "Epoch [10360], val_loss: 4712.8066\n",
            "Epoch [10380], val_loss: 4710.6787\n",
            "Epoch [10400], val_loss: 4708.1089\n",
            "Epoch [10420], val_loss: 4706.0811\n",
            "Epoch [10440], val_loss: 4707.2822\n",
            "Epoch [10460], val_loss: 4704.2939\n",
            "Epoch [10480], val_loss: 4705.6045\n",
            "Epoch [10500], val_loss: 4705.3931\n",
            "Epoch [10520], val_loss: 4702.0781\n",
            "Epoch [10540], val_loss: 4702.6504\n",
            "Epoch [10560], val_loss: 4703.7026\n",
            "Epoch [10580], val_loss: 4703.4746\n",
            "Epoch [10600], val_loss: 4703.1221\n",
            "Epoch [10620], val_loss: 4700.1152\n",
            "Epoch [10640], val_loss: 4698.9443\n",
            "Epoch [10660], val_loss: 4699.5840\n",
            "Epoch [10680], val_loss: 4698.9487\n",
            "Epoch [10700], val_loss: 4696.1279\n",
            "Epoch [10720], val_loss: 4695.0195\n",
            "Epoch [10740], val_loss: 4695.8232\n",
            "Epoch [10760], val_loss: 4695.8418\n",
            "Epoch [10780], val_loss: 4695.0381\n",
            "Epoch [10800], val_loss: 4692.5361\n",
            "Epoch [10820], val_loss: 4695.9062\n",
            "Epoch [10840], val_loss: 4694.2666\n",
            "Epoch [10860], val_loss: 4694.8887\n",
            "Epoch [10880], val_loss: 4692.6626\n",
            "Epoch [10900], val_loss: 4689.3291\n",
            "Epoch [10920], val_loss: 4690.4302\n",
            "Epoch [10940], val_loss: 4687.8135\n",
            "Epoch [10960], val_loss: 4685.7803\n",
            "Epoch [10980], val_loss: 4685.1758\n",
            "Epoch [11000], val_loss: 4686.2529\n",
            "Epoch [11020], val_loss: 4683.5493\n",
            "Epoch [11040], val_loss: 4683.3418\n",
            "Epoch [11060], val_loss: 4683.2129\n",
            "Epoch [11080], val_loss: 4683.0020\n",
            "Epoch [11100], val_loss: 4682.0317\n",
            "Epoch [11120], val_loss: 4681.1396\n",
            "Epoch [11140], val_loss: 4678.8130\n",
            "Epoch [11160], val_loss: 4678.9072\n",
            "Epoch [11180], val_loss: 4680.9004\n",
            "Epoch [11200], val_loss: 4678.8140\n",
            "Epoch [11220], val_loss: 4680.7949\n",
            "Epoch [11240], val_loss: 4677.3672\n",
            "Epoch [11260], val_loss: 4674.9873\n",
            "Epoch [11280], val_loss: 4677.2485\n",
            "Epoch [11300], val_loss: 4675.0464\n",
            "Epoch [11320], val_loss: 4674.1338\n",
            "Epoch [11340], val_loss: 4673.7500\n",
            "Epoch [11360], val_loss: 4673.4336\n",
            "Epoch [11380], val_loss: 4673.4487\n",
            "Epoch [11400], val_loss: 4671.0947\n",
            "Epoch [11420], val_loss: 4671.3560\n",
            "Epoch [11440], val_loss: 4668.8711\n",
            "Epoch [11460], val_loss: 4669.6636\n",
            "Epoch [11480], val_loss: 4670.1035\n",
            "Epoch [11500], val_loss: 4665.1143\n",
            "Epoch [11520], val_loss: 4666.9756\n",
            "Epoch [11540], val_loss: 4663.8818\n",
            "Epoch [11560], val_loss: 4664.1523\n",
            "Epoch [11580], val_loss: 4663.4512\n",
            "Epoch [11600], val_loss: 4664.6758\n",
            "Epoch [11620], val_loss: 4660.6538\n",
            "Epoch [11640], val_loss: 4661.6924\n",
            "Epoch [11660], val_loss: 4660.3813\n",
            "Epoch [11680], val_loss: 4659.2510\n",
            "Epoch [11700], val_loss: 4661.5996\n",
            "Epoch [11720], val_loss: 4660.7407\n",
            "Epoch [11740], val_loss: 4658.0742\n",
            "Epoch [11760], val_loss: 4657.9062\n",
            "Epoch [11780], val_loss: 4657.6768\n",
            "Epoch [11800], val_loss: 4656.8691\n",
            "Epoch [11820], val_loss: 4656.3340\n",
            "Epoch [11840], val_loss: 4655.1230\n",
            "Epoch [11860], val_loss: 4652.3379\n",
            "Epoch [11880], val_loss: 4652.4194\n",
            "Epoch [11900], val_loss: 4654.6318\n",
            "Epoch [11920], val_loss: 4651.7051\n",
            "Epoch [11940], val_loss: 4650.3779\n",
            "Epoch [11960], val_loss: 4649.5288\n",
            "Epoch [11980], val_loss: 4648.6719\n",
            "Epoch [12000], val_loss: 4647.4360\n",
            "Epoch [12020], val_loss: 4649.3584\n",
            "Epoch [12040], val_loss: 4646.6689\n",
            "Epoch [12060], val_loss: 4646.4961\n",
            "Epoch [12080], val_loss: 4643.3081\n",
            "Epoch [12100], val_loss: 4643.3872\n",
            "Epoch [12120], val_loss: 4642.5420\n",
            "Epoch [12140], val_loss: 4642.7822\n",
            "Epoch [12160], val_loss: 4641.1636\n",
            "Epoch [12180], val_loss: 4642.6553\n",
            "Epoch [12200], val_loss: 4641.9746\n",
            "Epoch [12220], val_loss: 4639.6572\n",
            "Epoch [12240], val_loss: 4640.4521\n",
            "Epoch [12260], val_loss: 4636.5205\n",
            "Epoch [12280], val_loss: 4639.3037\n",
            "Epoch [12300], val_loss: 4637.1250\n",
            "Epoch [12320], val_loss: 4637.6543\n",
            "Epoch [12340], val_loss: 4635.0161\n",
            "Epoch [12360], val_loss: 4638.4111\n",
            "Epoch [12380], val_loss: 4634.2393\n",
            "Epoch [12400], val_loss: 4635.7451\n",
            "Epoch [12420], val_loss: 4632.0806\n",
            "Epoch [12440], val_loss: 4634.1973\n",
            "Epoch [12460], val_loss: 4630.1118\n",
            "Epoch [12480], val_loss: 4629.6367\n",
            "Epoch [12500], val_loss: 4629.4395\n",
            "Epoch [12520], val_loss: 4630.9243\n",
            "Epoch [12540], val_loss: 4629.5771\n",
            "Epoch [12560], val_loss: 4629.1875\n",
            "Epoch [12580], val_loss: 4625.6768\n",
            "Epoch [12600], val_loss: 4626.0596\n",
            "Epoch [12620], val_loss: 4625.5586\n",
            "Epoch [12640], val_loss: 4622.2642\n",
            "Epoch [12660], val_loss: 4622.0449\n",
            "Epoch [12680], val_loss: 4620.7070\n",
            "Epoch [12700], val_loss: 4623.4922\n",
            "Epoch [12720], val_loss: 4622.7656\n",
            "Epoch [12740], val_loss: 4618.1470\n",
            "Epoch [12760], val_loss: 4618.3047\n",
            "Epoch [12780], val_loss: 4620.5571\n",
            "Epoch [12800], val_loss: 4616.0635\n",
            "Epoch [12820], val_loss: 4617.2773\n",
            "Epoch [12840], val_loss: 4615.3965\n",
            "Epoch [12860], val_loss: 4614.6533\n",
            "Epoch [12880], val_loss: 4613.4990\n",
            "Epoch [12900], val_loss: 4614.7520\n",
            "Epoch [12920], val_loss: 4612.6084\n",
            "Epoch [12940], val_loss: 4612.7915\n",
            "Epoch [12960], val_loss: 4611.0474\n",
            "Epoch [12980], val_loss: 4610.7866\n",
            "Epoch [13000], val_loss: 4611.9639\n",
            "Epoch [13020], val_loss: 4607.9258\n",
            "Epoch [13040], val_loss: 4608.7817\n",
            "Epoch [13060], val_loss: 4608.7100\n",
            "Epoch [13080], val_loss: 4607.1699\n",
            "Epoch [13100], val_loss: 4607.4629\n",
            "Epoch [13120], val_loss: 4604.7935\n",
            "Epoch [13140], val_loss: 4607.3711\n",
            "Epoch [13160], val_loss: 4605.6162\n",
            "Epoch [13180], val_loss: 4604.6230\n",
            "Epoch [13200], val_loss: 4600.9902\n",
            "Epoch [13220], val_loss: 4603.2666\n",
            "Epoch [13240], val_loss: 4600.9531\n",
            "Epoch [13260], val_loss: 4601.2061\n",
            "Epoch [13280], val_loss: 4598.1768\n",
            "Epoch [13300], val_loss: 4599.0225\n",
            "Epoch [13320], val_loss: 4597.1812\n",
            "Epoch [13340], val_loss: 4599.9561\n",
            "Epoch [13360], val_loss: 4595.8042\n",
            "Epoch [13380], val_loss: 4594.3486\n",
            "Epoch [13400], val_loss: 4596.6357\n",
            "Epoch [13420], val_loss: 4592.7183\n",
            "Epoch [13440], val_loss: 4597.7988\n",
            "Epoch [13460], val_loss: 4594.3940\n",
            "Epoch [13480], val_loss: 4594.9277\n",
            "Epoch [13500], val_loss: 4590.9385\n",
            "Epoch [13520], val_loss: 4589.1782\n",
            "Epoch [13540], val_loss: 4588.3799\n",
            "Epoch [13560], val_loss: 4590.1968\n",
            "Epoch [13580], val_loss: 4590.0332\n",
            "Epoch [13600], val_loss: 4585.8145\n",
            "Epoch [13620], val_loss: 4588.5391\n",
            "Epoch [13640], val_loss: 4585.4805\n",
            "Epoch [13660], val_loss: 4583.6592\n",
            "Epoch [13680], val_loss: 4583.4346\n",
            "Epoch [13700], val_loss: 4587.1436\n",
            "Epoch [13720], val_loss: 4582.4009\n",
            "Epoch [13740], val_loss: 4582.8291\n",
            "Epoch [13760], val_loss: 4580.1104\n",
            "Epoch [13780], val_loss: 4579.6455\n",
            "Epoch [13800], val_loss: 4581.8076\n",
            "Epoch [13820], val_loss: 4581.4995\n",
            "Epoch [13840], val_loss: 4580.1431\n",
            "Epoch [13860], val_loss: 4578.0498\n",
            "Epoch [13880], val_loss: 4575.4229\n",
            "Epoch [13900], val_loss: 4578.7671\n",
            "Epoch [13920], val_loss: 4574.9253\n",
            "Epoch [13940], val_loss: 4575.0708\n",
            "Epoch [13960], val_loss: 4572.4736\n",
            "Epoch [13980], val_loss: 4573.7793\n",
            "Epoch [14000], val_loss: 4571.9482\n",
            "Epoch [14020], val_loss: 4573.2266\n",
            "Epoch [14040], val_loss: 4571.5049\n",
            "Epoch [14060], val_loss: 4572.5771\n",
            "Epoch [14080], val_loss: 4570.7256\n",
            "Epoch [14100], val_loss: 4567.1104\n",
            "Epoch [14120], val_loss: 4566.4907\n",
            "Epoch [14140], val_loss: 4567.5840\n",
            "Epoch [14160], val_loss: 4566.3457\n",
            "Epoch [14180], val_loss: 4564.5327\n",
            "Epoch [14200], val_loss: 4565.5303\n",
            "Epoch [14220], val_loss: 4564.3291\n",
            "Epoch [14240], val_loss: 4563.9941\n",
            "Epoch [14260], val_loss: 4561.2275\n",
            "Epoch [14280], val_loss: 4564.5195\n",
            "Epoch [14300], val_loss: 4559.7061\n",
            "Epoch [14320], val_loss: 4558.9697\n",
            "Epoch [14340], val_loss: 4559.7046\n",
            "Epoch [14360], val_loss: 4560.1338\n",
            "Epoch [14380], val_loss: 4558.4956\n",
            "Epoch [14400], val_loss: 4556.8467\n",
            "Epoch [14420], val_loss: 4558.0957\n",
            "Epoch [14440], val_loss: 4555.5908\n",
            "Epoch [14460], val_loss: 4556.5605\n",
            "Epoch [14480], val_loss: 4552.8247\n",
            "Epoch [14500], val_loss: 4555.0693\n",
            "Epoch [14520], val_loss: 4554.5986\n",
            "Epoch [14540], val_loss: 4553.5298\n",
            "Epoch [14560], val_loss: 4552.0957\n",
            "Epoch [14580], val_loss: 4551.7412\n",
            "Epoch [14600], val_loss: 4550.3965\n",
            "Epoch [14620], val_loss: 4548.1963\n",
            "Epoch [14640], val_loss: 4550.0859\n",
            "Epoch [14660], val_loss: 4546.5645\n",
            "Epoch [14680], val_loss: 4549.2563\n",
            "Epoch [14700], val_loss: 4547.6113\n",
            "Epoch [14720], val_loss: 4545.6558\n",
            "Epoch [14740], val_loss: 4543.1777\n",
            "Epoch [14760], val_loss: 4542.2534\n",
            "Epoch [14780], val_loss: 4541.5205\n",
            "Epoch [14800], val_loss: 4540.8223\n",
            "Epoch [14820], val_loss: 4544.5513\n",
            "Epoch [14840], val_loss: 4540.0762\n",
            "Epoch [14860], val_loss: 4538.9785\n",
            "Epoch [14880], val_loss: 4541.6943\n",
            "Epoch [14900], val_loss: 4536.9805\n",
            "Epoch [14920], val_loss: 4536.9727\n",
            "Epoch [14940], val_loss: 4535.7119\n",
            "Epoch [14960], val_loss: 4535.5332\n",
            "Epoch [14980], val_loss: 4534.8677\n",
            "Epoch [15000], val_loss: 4535.0713\n",
            "Epoch [15020], val_loss: 4534.1616\n",
            "Epoch [15040], val_loss: 4533.0483\n",
            "Epoch [15060], val_loss: 4532.6787\n",
            "Epoch [15080], val_loss: 4530.8613\n",
            "Epoch [15100], val_loss: 4530.0547\n",
            "Epoch [15120], val_loss: 4531.3652\n",
            "Epoch [15140], val_loss: 4530.0186\n",
            "Epoch [15160], val_loss: 4528.4229\n",
            "Epoch [15180], val_loss: 4528.2817\n",
            "Epoch [15200], val_loss: 4526.1021\n",
            "Epoch [15220], val_loss: 4529.7109\n",
            "Epoch [15240], val_loss: 4524.3823\n",
            "Epoch [15260], val_loss: 4525.1992\n",
            "Epoch [15280], val_loss: 4522.8604\n",
            "Epoch [15300], val_loss: 4526.2036\n",
            "Epoch [15320], val_loss: 4522.0195\n",
            "Epoch [15340], val_loss: 4522.1338\n",
            "Epoch [15360], val_loss: 4522.7441\n",
            "Epoch [15380], val_loss: 4520.1367\n",
            "Epoch [15400], val_loss: 4519.1416\n",
            "Epoch [15420], val_loss: 4520.0684\n",
            "Epoch [15440], val_loss: 4520.7012\n",
            "Epoch [15460], val_loss: 4516.5537\n",
            "Epoch [15480], val_loss: 4518.7959\n",
            "Epoch [15500], val_loss: 4515.8267\n",
            "Epoch [15520], val_loss: 4515.7690\n",
            "Epoch [15540], val_loss: 4517.0664\n",
            "Epoch [15560], val_loss: 4513.6240\n",
            "Epoch [15580], val_loss: 4512.0273\n",
            "Epoch [15600], val_loss: 4512.6855\n",
            "Epoch [15620], val_loss: 4513.3730\n",
            "Epoch [15640], val_loss: 4510.4966\n",
            "Epoch [15660], val_loss: 4509.6357\n",
            "Epoch [15680], val_loss: 4509.0615\n",
            "Epoch [15700], val_loss: 4507.1855\n",
            "Epoch [15720], val_loss: 4507.1211\n",
            "Epoch [15740], val_loss: 4507.7852\n",
            "Epoch [15760], val_loss: 4505.6846\n",
            "Epoch [15780], val_loss: 4504.4375\n",
            "Epoch [15800], val_loss: 4505.2256\n",
            "Epoch [15820], val_loss: 4504.5762\n",
            "Epoch [15840], val_loss: 4504.8940\n",
            "Epoch [15860], val_loss: 4501.5649\n",
            "Epoch [15880], val_loss: 4501.8867\n",
            "Epoch [15900], val_loss: 4503.0859\n",
            "Epoch [15920], val_loss: 4502.7217\n",
            "Epoch [15940], val_loss: 4501.1636\n",
            "Epoch [15960], val_loss: 4501.6265\n",
            "Epoch [15980], val_loss: 4497.1968\n",
            "Epoch [16000], val_loss: 4498.0166\n",
            "Epoch [16020], val_loss: 4497.3560\n",
            "Epoch [16040], val_loss: 4496.4736\n",
            "Epoch [16060], val_loss: 4495.7783\n",
            "Epoch [16080], val_loss: 4495.2568\n",
            "Epoch [16100], val_loss: 4495.1924\n",
            "Epoch [16120], val_loss: 4495.7207\n",
            "Epoch [16140], val_loss: 4495.6753\n",
            "Epoch [16160], val_loss: 4493.3857\n",
            "Epoch [16180], val_loss: 4492.9404\n",
            "Epoch [16200], val_loss: 4491.2520\n",
            "Epoch [16220], val_loss: 4487.9004\n",
            "Epoch [16240], val_loss: 4487.2778\n",
            "Epoch [16260], val_loss: 4486.3750\n",
            "Epoch [16280], val_loss: 4485.9648\n",
            "Epoch [16300], val_loss: 4487.4468\n",
            "Epoch [16320], val_loss: 4486.3306\n",
            "Epoch [16340], val_loss: 4484.5010\n",
            "Epoch [16360], val_loss: 4484.6943\n",
            "Epoch [16380], val_loss: 4482.6807\n",
            "Epoch [16400], val_loss: 4481.9683\n",
            "Epoch [16420], val_loss: 4483.6777\n",
            "Epoch [16440], val_loss: 4480.2329\n",
            "Epoch [16460], val_loss: 4481.1104\n",
            "Epoch [16480], val_loss: 4480.9209\n",
            "Epoch [16500], val_loss: 4477.5635\n",
            "Epoch [16520], val_loss: 4476.7100\n",
            "Epoch [16540], val_loss: 4476.0322\n",
            "Epoch [16560], val_loss: 4478.0806\n",
            "Epoch [16580], val_loss: 4477.3438\n",
            "Epoch [16600], val_loss: 4474.1265\n",
            "Epoch [16620], val_loss: 4476.6382\n",
            "Epoch [16640], val_loss: 4475.1299\n",
            "Epoch [16660], val_loss: 4472.8076\n",
            "Epoch [16680], val_loss: 4471.3516\n",
            "Epoch [16700], val_loss: 4473.1387\n",
            "Epoch [16720], val_loss: 4471.0547\n",
            "Epoch [16740], val_loss: 4469.8174\n",
            "Epoch [16760], val_loss: 4470.5859\n",
            "Epoch [16780], val_loss: 4467.1338\n",
            "Epoch [16800], val_loss: 4466.3647\n",
            "Epoch [16820], val_loss: 4466.3843\n",
            "Epoch [16840], val_loss: 4467.1768\n",
            "Epoch [16860], val_loss: 4464.1372\n",
            "Epoch [16880], val_loss: 4463.4355\n",
            "Epoch [16900], val_loss: 4463.0161\n",
            "Epoch [16920], val_loss: 4464.9380\n",
            "Epoch [16940], val_loss: 4461.3174\n",
            "Epoch [16960], val_loss: 4461.3740\n",
            "Epoch [16980], val_loss: 4461.6787\n",
            "Epoch [17000], val_loss: 4460.5679\n",
            "Epoch [17020], val_loss: 4461.3828\n",
            "Epoch [17040], val_loss: 4458.3779\n",
            "Epoch [17060], val_loss: 4456.6895\n",
            "Epoch [17080], val_loss: 4455.7168\n",
            "Epoch [17100], val_loss: 4455.4316\n",
            "Epoch [17120], val_loss: 4457.7480\n",
            "Epoch [17140], val_loss: 4454.7046\n",
            "Epoch [17160], val_loss: 4453.1523\n",
            "Epoch [17180], val_loss: 4452.2949\n",
            "Epoch [17200], val_loss: 4451.4932\n",
            "Epoch [17220], val_loss: 4452.7920\n",
            "Epoch [17240], val_loss: 4452.0996\n",
            "Epoch [17260], val_loss: 4449.8730\n",
            "Epoch [17280], val_loss: 4448.5269\n",
            "Epoch [17300], val_loss: 4450.1860\n",
            "Epoch [17320], val_loss: 4446.9160\n",
            "Epoch [17340], val_loss: 4446.2036\n",
            "Epoch [17360], val_loss: 4445.5957\n",
            "Epoch [17380], val_loss: 4447.8711\n",
            "Epoch [17400], val_loss: 4445.3545\n",
            "Epoch [17420], val_loss: 4445.8306\n",
            "Epoch [17440], val_loss: 4444.6309\n",
            "Epoch [17460], val_loss: 4443.1982\n",
            "Epoch [17480], val_loss: 4442.0771\n",
            "Epoch [17500], val_loss: 4442.5352\n",
            "Epoch [17520], val_loss: 4441.2754\n",
            "Epoch [17540], val_loss: 4440.3193\n",
            "Epoch [17560], val_loss: 4442.6865\n",
            "Epoch [17580], val_loss: 4437.7197\n",
            "Epoch [17600], val_loss: 4439.3672\n",
            "Epoch [17620], val_loss: 4438.7695\n",
            "Epoch [17640], val_loss: 4437.0264\n",
            "Epoch [17660], val_loss: 4434.3184\n",
            "Epoch [17680], val_loss: 4433.8193\n",
            "Epoch [17700], val_loss: 4436.4717\n",
            "Epoch [17720], val_loss: 4435.0420\n",
            "Epoch [17740], val_loss: 4432.2925\n",
            "Epoch [17760], val_loss: 4433.2588\n",
            "Epoch [17780], val_loss: 4432.5352\n",
            "Epoch [17800], val_loss: 4430.1060\n",
            "Epoch [17820], val_loss: 4430.6191\n",
            "Epoch [17840], val_loss: 4432.4473\n",
            "Epoch [17860], val_loss: 4427.0127\n",
            "Epoch [17880], val_loss: 4427.9409\n",
            "Epoch [17900], val_loss: 4427.9102\n",
            "Epoch [17920], val_loss: 4428.0591\n",
            "Epoch [17940], val_loss: 4428.3491\n",
            "Epoch [17960], val_loss: 4426.4551\n",
            "Epoch [17980], val_loss: 4422.6011\n",
            "Epoch [18000], val_loss: 4424.0723\n",
            "Epoch [18020], val_loss: 4424.1406\n",
            "Epoch [18040], val_loss: 4423.0615\n",
            "Epoch [18060], val_loss: 4419.6772\n",
            "Epoch [18080], val_loss: 4422.3242\n",
            "Epoch [18100], val_loss: 4420.2285\n",
            "Epoch [18120], val_loss: 4420.4346\n",
            "Epoch [18140], val_loss: 4421.3145\n",
            "Epoch [18160], val_loss: 4415.9966\n",
            "Epoch [18180], val_loss: 4415.2456\n",
            "Epoch [18200], val_loss: 4417.1855\n",
            "Epoch [18220], val_loss: 4416.0933\n",
            "Epoch [18240], val_loss: 4415.9966\n",
            "Epoch [18260], val_loss: 4416.1191\n",
            "Epoch [18280], val_loss: 4412.4492\n",
            "Epoch [18300], val_loss: 4415.1060\n",
            "Epoch [18320], val_loss: 4414.1758\n",
            "Epoch [18340], val_loss: 4412.0635\n",
            "Epoch [18360], val_loss: 4409.8052\n",
            "Epoch [18380], val_loss: 4410.3926\n",
            "Epoch [18400], val_loss: 4407.9697\n",
            "Epoch [18420], val_loss: 4407.5825\n",
            "Epoch [18440], val_loss: 4406.0791\n",
            "Epoch [18460], val_loss: 4407.2402\n",
            "Epoch [18480], val_loss: 4404.2783\n",
            "Epoch [18500], val_loss: 4407.7769\n",
            "Epoch [18520], val_loss: 4404.9341\n",
            "Epoch [18540], val_loss: 4403.9692\n",
            "Epoch [18560], val_loss: 4402.0508\n",
            "Epoch [18580], val_loss: 4401.9185\n",
            "Epoch [18600], val_loss: 4402.1006\n",
            "Epoch [18620], val_loss: 4400.3926\n",
            "Epoch [18640], val_loss: 4400.4219\n",
            "Epoch [18660], val_loss: 4399.7246\n",
            "Epoch [18680], val_loss: 4398.4434\n",
            "Epoch [18700], val_loss: 4399.8735\n",
            "Epoch [18720], val_loss: 4396.8906\n",
            "Epoch [18740], val_loss: 4395.9268\n",
            "Epoch [18760], val_loss: 4397.5532\n",
            "Epoch [18780], val_loss: 4396.3721\n",
            "Epoch [18800], val_loss: 4396.5835\n",
            "Epoch [18820], val_loss: 4394.0508\n",
            "Epoch [18840], val_loss: 4391.4082\n",
            "Epoch [18860], val_loss: 4393.8428\n",
            "Epoch [18880], val_loss: 4390.5298\n",
            "Epoch [18900], val_loss: 4390.1167\n",
            "Epoch [18920], val_loss: 4389.6396\n",
            "Epoch [18940], val_loss: 4389.7803\n",
            "Epoch [18960], val_loss: 4389.5845\n",
            "Epoch [18980], val_loss: 4388.7783\n",
            "Epoch [19000], val_loss: 4386.4946\n",
            "Epoch [19020], val_loss: 4384.9683\n",
            "Epoch [19040], val_loss: 4386.5664\n",
            "Epoch [19060], val_loss: 4384.4141\n",
            "Epoch [19080], val_loss: 4384.5347\n",
            "Epoch [19100], val_loss: 4382.4863\n",
            "Epoch [19120], val_loss: 4383.0303\n",
            "Epoch [19140], val_loss: 4380.6226\n",
            "Epoch [19160], val_loss: 4384.3560\n",
            "Epoch [19180], val_loss: 4383.1475\n",
            "Epoch [19200], val_loss: 4378.4277\n",
            "Epoch [19220], val_loss: 4381.4727\n",
            "Epoch [19240], val_loss: 4378.5684\n",
            "Epoch [19260], val_loss: 4376.4727\n",
            "Epoch [19280], val_loss: 4379.2988\n",
            "Epoch [19300], val_loss: 4377.0234\n",
            "Epoch [19320], val_loss: 4375.2046\n",
            "Epoch [19340], val_loss: 4375.4434\n",
            "Epoch [19360], val_loss: 4373.9463\n",
            "Epoch [19380], val_loss: 4376.7974\n",
            "Epoch [19400], val_loss: 4373.7207\n",
            "Epoch [19420], val_loss: 4374.5977\n",
            "Epoch [19440], val_loss: 4373.7236\n",
            "Epoch [19460], val_loss: 4369.3472\n",
            "Epoch [19480], val_loss: 4370.0610\n",
            "Epoch [19500], val_loss: 4371.8613\n",
            "Epoch [19520], val_loss: 4366.8931\n",
            "Epoch [19540], val_loss: 4366.6880\n",
            "Epoch [19560], val_loss: 4365.5732\n",
            "Epoch [19580], val_loss: 4367.8687\n",
            "Epoch [19600], val_loss: 4364.0396\n",
            "Epoch [19620], val_loss: 4365.2148\n",
            "Epoch [19640], val_loss: 4363.1001\n",
            "Epoch [19660], val_loss: 4364.2773\n",
            "Epoch [19680], val_loss: 4361.2876\n",
            "Epoch [19700], val_loss: 4361.6113\n",
            "Epoch [19720], val_loss: 4359.7495\n",
            "Epoch [19740], val_loss: 4358.9883\n",
            "Epoch [19760], val_loss: 4362.4062\n",
            "Epoch [19780], val_loss: 4359.1069\n",
            "Epoch [19800], val_loss: 4356.7275\n",
            "Epoch [19820], val_loss: 4356.8916\n",
            "Epoch [19840], val_loss: 4358.9570\n",
            "Epoch [19860], val_loss: 4359.1953\n",
            "Epoch [19880], val_loss: 4354.2959\n",
            "Epoch [19900], val_loss: 4353.6836\n",
            "Epoch [19920], val_loss: 4352.8936\n",
            "Epoch [19940], val_loss: 4353.9893\n",
            "Epoch [19960], val_loss: 4350.8755\n",
            "Epoch [19980], val_loss: 4350.2310\n",
            "Epoch [20000], val_loss: 4352.3604\n",
            "Epoch [20020], val_loss: 4352.3818\n",
            "Epoch [20040], val_loss: 4351.0146\n",
            "Epoch [20060], val_loss: 4351.6455\n",
            "Epoch [20080], val_loss: 4347.7725\n",
            "Epoch [20100], val_loss: 4347.9360\n",
            "Epoch [20120], val_loss: 4348.7715\n",
            "Epoch [20140], val_loss: 4345.7559\n",
            "Epoch [20160], val_loss: 4346.1929\n",
            "Epoch [20180], val_loss: 4343.1650\n",
            "Epoch [20200], val_loss: 4343.0244\n",
            "Epoch [20220], val_loss: 4343.4600\n",
            "Epoch [20240], val_loss: 4341.5107\n",
            "Epoch [20260], val_loss: 4340.2773\n",
            "Epoch [20280], val_loss: 4344.7607\n",
            "Epoch [20300], val_loss: 4340.7378\n",
            "Epoch [20320], val_loss: 4340.7188\n",
            "Epoch [20340], val_loss: 4340.9287\n",
            "Epoch [20360], val_loss: 4337.4780\n",
            "Epoch [20380], val_loss: 4335.9741\n",
            "Epoch [20400], val_loss: 4335.7510\n",
            "Epoch [20420], val_loss: 4335.2827\n",
            "Epoch [20440], val_loss: 4334.0693\n",
            "Epoch [20460], val_loss: 4332.9448\n",
            "Epoch [20480], val_loss: 4332.2329\n",
            "Epoch [20500], val_loss: 4335.5625\n",
            "Epoch [20520], val_loss: 4333.4219\n",
            "Epoch [20540], val_loss: 4333.0913\n",
            "Epoch [20560], val_loss: 4332.8018\n",
            "Epoch [20580], val_loss: 4328.7734\n",
            "Epoch [20600], val_loss: 4328.6357\n",
            "Epoch [20620], val_loss: 4327.1221\n",
            "Epoch [20640], val_loss: 4328.9414\n",
            "Epoch [20660], val_loss: 4327.6631\n",
            "Epoch [20680], val_loss: 4325.4365\n",
            "Epoch [20700], val_loss: 4327.6909\n",
            "Epoch [20720], val_loss: 4324.2686\n",
            "Epoch [20740], val_loss: 4329.4419\n",
            "Epoch [20760], val_loss: 4324.4766\n",
            "Epoch [20780], val_loss: 4321.6299\n",
            "Epoch [20800], val_loss: 4324.8501\n",
            "Epoch [20820], val_loss: 4321.6899\n",
            "Epoch [20840], val_loss: 4320.8232\n",
            "Epoch [20860], val_loss: 4322.1455\n",
            "Epoch [20880], val_loss: 4320.8892\n",
            "Epoch [20900], val_loss: 4320.0957\n",
            "Epoch [20920], val_loss: 4318.4751\n",
            "Epoch [20940], val_loss: 4316.0635\n",
            "Epoch [20960], val_loss: 4317.6812\n",
            "Epoch [20980], val_loss: 4314.4189\n",
            "Epoch [21000], val_loss: 4315.8076\n",
            "Epoch [21020], val_loss: 4313.4175\n",
            "Epoch [21040], val_loss: 4314.3032\n",
            "Epoch [21060], val_loss: 4313.5366\n",
            "Epoch [21080], val_loss: 4313.1616\n",
            "Epoch [21100], val_loss: 4312.2085\n",
            "Epoch [21120], val_loss: 4311.6387\n",
            "Epoch [21140], val_loss: 4308.8901\n",
            "Epoch [21160], val_loss: 4309.8418\n",
            "Epoch [21180], val_loss: 4311.8291\n",
            "Epoch [21200], val_loss: 4307.9414\n",
            "Epoch [21220], val_loss: 4306.3823\n",
            "Epoch [21240], val_loss: 4305.4927\n",
            "Epoch [21260], val_loss: 4306.3960\n",
            "Epoch [21280], val_loss: 4304.7764\n",
            "Epoch [21300], val_loss: 4303.1772\n",
            "Epoch [21320], val_loss: 4302.4590\n",
            "Epoch [21340], val_loss: 4303.3843\n",
            "Epoch [21360], val_loss: 4303.2778\n",
            "Epoch [21380], val_loss: 4300.4897\n",
            "Epoch [21400], val_loss: 4300.1650\n",
            "Epoch [21420], val_loss: 4298.9795\n",
            "Epoch [21440], val_loss: 4301.5010\n",
            "Epoch [21460], val_loss: 4299.4043\n",
            "Epoch [21480], val_loss: 4300.4131\n",
            "Epoch [21500], val_loss: 4296.1138\n",
            "Epoch [21520], val_loss: 4295.2993\n",
            "Epoch [21540], val_loss: 4295.1616\n",
            "Epoch [21560], val_loss: 4294.1655\n",
            "Epoch [21580], val_loss: 4295.8975\n",
            "Epoch [21600], val_loss: 4292.6958\n",
            "Epoch [21620], val_loss: 4292.7705\n",
            "Epoch [21640], val_loss: 4293.4189\n",
            "Epoch [21660], val_loss: 4290.5972\n",
            "Epoch [21680], val_loss: 4290.1655\n",
            "Epoch [21700], val_loss: 4291.3481\n",
            "Epoch [21720], val_loss: 4289.7144\n",
            "Epoch [21740], val_loss: 4287.6240\n",
            "Epoch [21760], val_loss: 4288.3125\n",
            "Epoch [21780], val_loss: 4287.5430\n",
            "Epoch [21800], val_loss: 4287.4448\n",
            "Epoch [21820], val_loss: 4284.9502\n",
            "Epoch [21840], val_loss: 4285.7441\n",
            "Epoch [21860], val_loss: 4283.7954\n",
            "Epoch [21880], val_loss: 4282.7378\n",
            "Epoch [21900], val_loss: 4285.0703\n",
            "Epoch [21920], val_loss: 4282.1338\n",
            "Epoch [21940], val_loss: 4281.7983\n",
            "Epoch [21960], val_loss: 4282.3198\n",
            "Epoch [21980], val_loss: 4280.9956\n",
            "Epoch [22000], val_loss: 4281.1431\n",
            "Epoch [22020], val_loss: 4278.5581\n",
            "Epoch [22040], val_loss: 4277.5190\n",
            "Epoch [22060], val_loss: 4276.5322\n",
            "Epoch [22080], val_loss: 4279.5488\n",
            "Epoch [22100], val_loss: 4276.4126\n",
            "Epoch [22120], val_loss: 4276.1465\n",
            "Epoch [22140], val_loss: 4276.6440\n",
            "Epoch [22160], val_loss: 4275.4253\n",
            "Epoch [22180], val_loss: 4274.9336\n",
            "Epoch [22200], val_loss: 4274.2686\n",
            "Epoch [22220], val_loss: 4271.0850\n",
            "Epoch [22240], val_loss: 4271.0083\n",
            "Epoch [22260], val_loss: 4273.6235\n",
            "Epoch [22280], val_loss: 4270.9385\n",
            "Epoch [22300], val_loss: 4268.6387\n",
            "Epoch [22320], val_loss: 4267.7246\n",
            "Epoch [22340], val_loss: 4268.1123\n",
            "Epoch [22360], val_loss: 4266.5439\n",
            "Epoch [22380], val_loss: 4265.1230\n",
            "Epoch [22400], val_loss: 4266.4082\n",
            "Epoch [22420], val_loss: 4266.2251\n",
            "Epoch [22440], val_loss: 4267.7383\n",
            "Epoch [22460], val_loss: 4266.1367\n",
            "Epoch [22480], val_loss: 4262.8599\n",
            "Epoch [22500], val_loss: 4263.4248\n",
            "Epoch [22520], val_loss: 4260.2832\n",
            "Epoch [22540], val_loss: 4259.6787\n",
            "Epoch [22560], val_loss: 4258.8770\n",
            "Epoch [22580], val_loss: 4258.2397\n",
            "Epoch [22600], val_loss: 4258.3525\n",
            "Epoch [22620], val_loss: 4257.3818\n",
            "Epoch [22640], val_loss: 4257.7490\n",
            "Epoch [22660], val_loss: 4258.0957\n",
            "Epoch [22680], val_loss: 4257.7993\n",
            "Epoch [22700], val_loss: 4256.4556\n",
            "Epoch [22720], val_loss: 4255.1333\n",
            "Epoch [22740], val_loss: 4252.5371\n",
            "Epoch [22760], val_loss: 4251.8320\n",
            "Epoch [22780], val_loss: 4251.7358\n",
            "Epoch [22800], val_loss: 4251.4282\n",
            "Epoch [22820], val_loss: 4250.3833\n",
            "Epoch [22840], val_loss: 4252.6245\n",
            "Epoch [22860], val_loss: 4248.8340\n",
            "Epoch [22880], val_loss: 4247.4922\n",
            "Epoch [22900], val_loss: 4247.8135\n",
            "Epoch [22920], val_loss: 4250.1914\n",
            "Epoch [22940], val_loss: 4246.8228\n",
            "Epoch [22960], val_loss: 4246.9326\n",
            "Epoch [22980], val_loss: 4244.8691\n",
            "Epoch [23000], val_loss: 4247.8896\n",
            "Epoch [23020], val_loss: 4243.4600\n",
            "Epoch [23040], val_loss: 4243.4150\n",
            "Epoch [23060], val_loss: 4241.3154\n",
            "Epoch [23080], val_loss: 4241.3359\n",
            "Epoch [23100], val_loss: 4243.2656\n",
            "Epoch [23120], val_loss: 4239.6323\n",
            "Epoch [23140], val_loss: 4238.3774\n",
            "Epoch [23160], val_loss: 4238.4028\n",
            "Epoch [23180], val_loss: 4241.6953\n",
            "Epoch [23200], val_loss: 4238.7056\n",
            "Epoch [23220], val_loss: 4237.4297\n",
            "Epoch [23240], val_loss: 4234.9360\n",
            "Epoch [23260], val_loss: 4234.7158\n",
            "Epoch [23280], val_loss: 4234.9121\n",
            "Epoch [23300], val_loss: 4233.5210\n",
            "Epoch [23320], val_loss: 4233.8623\n",
            "Epoch [23340], val_loss: 4232.2793\n",
            "Epoch [23360], val_loss: 4230.6445\n",
            "Epoch [23380], val_loss: 4229.8960\n",
            "Epoch [23400], val_loss: 4231.3135\n",
            "Epoch [23420], val_loss: 4229.2588\n",
            "Epoch [23440], val_loss: 4230.1431\n",
            "Epoch [23460], val_loss: 4227.4189\n",
            "Epoch [23480], val_loss: 4226.3848\n",
            "Epoch [23500], val_loss: 4226.0264\n",
            "Epoch [23520], val_loss: 4228.1724\n",
            "Epoch [23540], val_loss: 4228.1729\n",
            "Epoch [23560], val_loss: 4224.1704\n",
            "Epoch [23580], val_loss: 4222.8579\n",
            "Epoch [23600], val_loss: 4225.0869\n",
            "Epoch [23620], val_loss: 4222.9390\n",
            "Epoch [23640], val_loss: 4222.2290\n",
            "Epoch [23660], val_loss: 4220.0386\n",
            "Epoch [23680], val_loss: 4223.5801\n",
            "Epoch [23700], val_loss: 4219.5405\n",
            "Epoch [23720], val_loss: 4219.7808\n",
            "Epoch [23740], val_loss: 4217.7681\n",
            "Epoch [23760], val_loss: 4216.5820\n",
            "Epoch [23780], val_loss: 4217.7422\n",
            "Epoch [23800], val_loss: 4216.9966\n",
            "Epoch [23820], val_loss: 4215.6074\n",
            "Epoch [23840], val_loss: 4213.8374\n",
            "Epoch [23860], val_loss: 4214.5376\n",
            "Epoch [23880], val_loss: 4214.8413\n",
            "Epoch [23900], val_loss: 4211.6729\n",
            "Epoch [23920], val_loss: 4213.9897\n",
            "Epoch [23940], val_loss: 4211.5186\n",
            "Epoch [23960], val_loss: 4210.8232\n",
            "Epoch [23980], val_loss: 4209.2524\n",
            "Epoch [24000], val_loss: 4210.8174\n",
            "Epoch [24020], val_loss: 4208.0771\n",
            "Epoch [24040], val_loss: 4209.1787\n",
            "Epoch [24060], val_loss: 4205.8765\n",
            "Epoch [24080], val_loss: 4210.2349\n",
            "Epoch [24100], val_loss: 4204.5171\n",
            "Epoch [24120], val_loss: 4205.1626\n",
            "Epoch [24140], val_loss: 4203.6885\n",
            "Epoch [24160], val_loss: 4203.5801\n",
            "Epoch [24180], val_loss: 4202.7275\n",
            "Epoch [24200], val_loss: 4201.5830\n",
            "Epoch [24220], val_loss: 4203.5913\n",
            "Epoch [24240], val_loss: 4200.1934\n",
            "Epoch [24260], val_loss: 4199.1387\n",
            "Epoch [24280], val_loss: 4198.5728\n",
            "Epoch [24300], val_loss: 4200.3291\n",
            "Epoch [24320], val_loss: 4199.1655\n",
            "Epoch [24340], val_loss: 4197.0039\n",
            "Epoch [24360], val_loss: 4195.4785\n",
            "Epoch [24380], val_loss: 4194.9814\n",
            "Epoch [24400], val_loss: 4197.8237\n",
            "Epoch [24420], val_loss: 4196.0923\n",
            "Epoch [24440], val_loss: 4192.8818\n",
            "Epoch [24460], val_loss: 4193.1836\n",
            "Epoch [24480], val_loss: 4194.9077\n",
            "Epoch [24500], val_loss: 4193.4688\n",
            "Epoch [24520], val_loss: 4192.1621\n",
            "Epoch [24540], val_loss: 4192.8247\n",
            "Epoch [24560], val_loss: 4191.0742\n",
            "Epoch [24580], val_loss: 4188.9824\n",
            "Epoch [24600], val_loss: 4187.4062\n",
            "Epoch [24620], val_loss: 4189.5522\n",
            "Epoch [24640], val_loss: 4188.3706\n",
            "Epoch [24660], val_loss: 4187.4209\n",
            "Epoch [24680], val_loss: 4186.0278\n",
            "Epoch [24700], val_loss: 4186.6426\n",
            "Epoch [24720], val_loss: 4186.4839\n",
            "Epoch [24740], val_loss: 4185.3735\n",
            "Epoch [24760], val_loss: 4185.0762\n",
            "Epoch [24780], val_loss: 4182.8477\n",
            "Epoch [24800], val_loss: 4181.6338\n",
            "Epoch [24820], val_loss: 4181.9004\n",
            "Epoch [24840], val_loss: 4180.9204\n",
            "Epoch [24860], val_loss: 4178.8643\n",
            "Epoch [24880], val_loss: 4177.8940\n",
            "Epoch [24900], val_loss: 4177.3257\n",
            "Epoch [24920], val_loss: 4177.9282\n",
            "Epoch [24940], val_loss: 4175.8623\n",
            "Epoch [24960], val_loss: 4177.7900\n",
            "Epoch [24980], val_loss: 4175.7939\n",
            "Epoch [25000], val_loss: 4176.1133\n",
            "Epoch [25020], val_loss: 4175.3853\n",
            "Epoch [25040], val_loss: 4173.3916\n",
            "Epoch [25060], val_loss: 4171.9155\n",
            "Epoch [25080], val_loss: 4172.1211\n",
            "Epoch [25100], val_loss: 4171.5176\n",
            "Epoch [25120], val_loss: 4169.7461\n",
            "Epoch [25140], val_loss: 4169.6143\n",
            "Epoch [25160], val_loss: 4169.3955\n",
            "Epoch [25180], val_loss: 4168.8643\n",
            "Epoch [25200], val_loss: 4166.9316\n",
            "Epoch [25220], val_loss: 4170.0010\n",
            "Epoch [25240], val_loss: 4166.3848\n",
            "Epoch [25260], val_loss: 4167.4404\n",
            "Epoch [25280], val_loss: 4164.0996\n",
            "Epoch [25300], val_loss: 4163.3770\n",
            "Epoch [25320], val_loss: 4162.7969\n",
            "Epoch [25340], val_loss: 4164.8145\n",
            "Epoch [25360], val_loss: 4162.7114\n",
            "Epoch [25380], val_loss: 4161.4624\n",
            "Epoch [25400], val_loss: 4162.2837\n",
            "Epoch [25420], val_loss: 4161.4297\n",
            "Epoch [25440], val_loss: 4160.9775\n",
            "Epoch [25460], val_loss: 4163.3101\n",
            "Epoch [25480], val_loss: 4158.6660\n",
            "Epoch [25500], val_loss: 4156.4810\n",
            "Epoch [25520], val_loss: 4157.5298\n",
            "Epoch [25540], val_loss: 4157.4741\n",
            "Epoch [25560], val_loss: 4157.0415\n",
            "Epoch [25580], val_loss: 4156.6982\n",
            "Epoch [25600], val_loss: 4155.5244\n",
            "Epoch [25620], val_loss: 4153.4077\n",
            "Epoch [25640], val_loss: 4152.0684\n",
            "Epoch [25660], val_loss: 4152.4663\n",
            "Epoch [25680], val_loss: 4150.7246\n",
            "Epoch [25700], val_loss: 4152.5337\n",
            "Epoch [25720], val_loss: 4149.7778\n",
            "Epoch [25740], val_loss: 4149.5576\n",
            "Epoch [25760], val_loss: 4148.8555\n",
            "Epoch [25780], val_loss: 4146.8149\n",
            "Epoch [25800], val_loss: 4149.9541\n",
            "Epoch [25820], val_loss: 4146.6611\n",
            "Epoch [25840], val_loss: 4144.8623\n",
            "Epoch [25860], val_loss: 4144.6909\n",
            "Epoch [25880], val_loss: 4145.8066\n",
            "Epoch [25900], val_loss: 4142.6665\n",
            "Epoch [25920], val_loss: 4143.6650\n",
            "Epoch [25940], val_loss: 4142.6621\n",
            "Epoch [25960], val_loss: 4142.7666\n",
            "Epoch [25980], val_loss: 4140.7563\n",
            "Epoch [26000], val_loss: 4140.5620\n",
            "Epoch [26020], val_loss: 4142.8687\n",
            "Epoch [26040], val_loss: 4140.7485\n",
            "Epoch [26060], val_loss: 4137.2969\n",
            "Epoch [26080], val_loss: 4136.6870\n",
            "Epoch [26100], val_loss: 4137.8779\n",
            "Epoch [26120], val_loss: 4138.5615\n",
            "Epoch [26140], val_loss: 4135.6533\n",
            "Epoch [26160], val_loss: 4135.1797\n",
            "Epoch [26180], val_loss: 4134.8970\n",
            "Epoch [26200], val_loss: 4134.5298\n",
            "Epoch [26220], val_loss: 4131.8105\n",
            "Epoch [26240], val_loss: 4133.4604\n",
            "Epoch [26260], val_loss: 4132.4316\n",
            "Epoch [26280], val_loss: 4133.3037\n",
            "Epoch [26300], val_loss: 4131.8115\n",
            "Epoch [26320], val_loss: 4131.1675\n",
            "Epoch [26340], val_loss: 4127.8911\n",
            "Epoch [26360], val_loss: 4131.3916\n",
            "Epoch [26380], val_loss: 4128.9810\n",
            "Epoch [26400], val_loss: 4126.8242\n",
            "Epoch [26420], val_loss: 4125.6133\n",
            "Epoch [26440], val_loss: 4125.1113\n",
            "Epoch [26460], val_loss: 4124.6206\n",
            "Epoch [26480], val_loss: 4125.3403\n",
            "Epoch [26500], val_loss: 4122.3066\n",
            "Epoch [26520], val_loss: 4122.8081\n",
            "Epoch [26540], val_loss: 4120.6724\n",
            "Epoch [26560], val_loss: 4121.4580\n",
            "Epoch [26580], val_loss: 4122.0708\n",
            "Epoch [26600], val_loss: 4119.9268\n",
            "Epoch [26620], val_loss: 4119.8594\n",
            "Epoch [26640], val_loss: 4118.7402\n",
            "Epoch [26660], val_loss: 4117.6621\n",
            "Epoch [26680], val_loss: 4119.2939\n",
            "Epoch [26700], val_loss: 4116.7520\n",
            "Epoch [26720], val_loss: 4117.8022\n",
            "Epoch [26740], val_loss: 4114.3218\n",
            "Epoch [26760], val_loss: 4113.3330\n",
            "Epoch [26780], val_loss: 4114.5327\n",
            "Epoch [26800], val_loss: 4113.0557\n",
            "Epoch [26820], val_loss: 4113.7017\n",
            "Epoch [26840], val_loss: 4112.7700\n",
            "Epoch [26860], val_loss: 4110.8184\n",
            "Epoch [26880], val_loss: 4111.7642\n",
            "Epoch [26900], val_loss: 4109.9375\n",
            "Epoch [26920], val_loss: 4111.2061\n",
            "Epoch [26940], val_loss: 4107.2329\n",
            "Epoch [26960], val_loss: 4107.3379\n",
            "Epoch [26980], val_loss: 4108.0693\n",
            "Epoch [27000], val_loss: 4106.5820\n",
            "Epoch [27020], val_loss: 4104.3613\n",
            "Epoch [27040], val_loss: 4105.0186\n",
            "Epoch [27060], val_loss: 4104.7412\n",
            "Epoch [27080], val_loss: 4102.8892\n",
            "Epoch [27100], val_loss: 4103.9795\n",
            "Epoch [27120], val_loss: 4105.1841\n",
            "Epoch [27140], val_loss: 4103.4009\n",
            "Epoch [27160], val_loss: 4102.7100\n",
            "Epoch [27180], val_loss: 4099.6284\n",
            "Epoch [27200], val_loss: 4098.8965\n",
            "Epoch [27220], val_loss: 4100.8760\n",
            "Epoch [27240], val_loss: 4098.4595\n",
            "Epoch [27260], val_loss: 4096.1318\n",
            "Epoch [27280], val_loss: 4097.6323\n",
            "Epoch [27300], val_loss: 4094.8511\n",
            "Epoch [27320], val_loss: 4095.4111\n",
            "Epoch [27340], val_loss: 4099.3120\n",
            "Epoch [27360], val_loss: 4096.6338\n",
            "Epoch [27380], val_loss: 4093.4224\n",
            "Epoch [27400], val_loss: 4094.8843\n",
            "Epoch [27420], val_loss: 4091.3684\n",
            "Epoch [27440], val_loss: 4092.4819\n",
            "Epoch [27460], val_loss: 4089.5405\n",
            "Epoch [27480], val_loss: 4091.8333\n",
            "Epoch [27500], val_loss: 4090.8076\n",
            "Epoch [27520], val_loss: 4090.2192\n",
            "Epoch [27540], val_loss: 4087.6282\n",
            "Epoch [27560], val_loss: 4089.7593\n",
            "Epoch [27580], val_loss: 4088.3450\n",
            "Epoch [27600], val_loss: 4087.1445\n",
            "Epoch [27620], val_loss: 4084.9463\n",
            "Epoch [27640], val_loss: 4085.7849\n",
            "Epoch [27660], val_loss: 4083.4966\n",
            "Epoch [27680], val_loss: 4084.0000\n",
            "Epoch [27700], val_loss: 4082.4153\n",
            "Epoch [27720], val_loss: 4081.8589\n",
            "Epoch [27740], val_loss: 4081.8523\n",
            "Epoch [27760], val_loss: 4081.0610\n",
            "Epoch [27780], val_loss: 4081.2217\n",
            "Epoch [27800], val_loss: 4081.5273\n",
            "Epoch [27820], val_loss: 4078.5923\n",
            "Epoch [27840], val_loss: 4080.0825\n",
            "Epoch [27860], val_loss: 4077.6831\n",
            "Epoch [27880], val_loss: 4078.6411\n",
            "Epoch [27900], val_loss: 4075.9243\n",
            "Epoch [27920], val_loss: 4075.3335\n",
            "Epoch [27940], val_loss: 4076.0879\n",
            "Epoch [27960], val_loss: 4073.7324\n",
            "Epoch [27980], val_loss: 4072.2319\n",
            "Epoch [28000], val_loss: 4071.7886\n",
            "Epoch [28020], val_loss: 4073.7329\n",
            "Epoch [28040], val_loss: 4073.3013\n",
            "Epoch [28060], val_loss: 4072.8442\n",
            "Epoch [28080], val_loss: 4071.3936\n",
            "Epoch [28100], val_loss: 4069.0850\n",
            "Epoch [28120], val_loss: 4070.7283\n",
            "Epoch [28140], val_loss: 4068.6521\n",
            "Epoch [28160], val_loss: 4066.7095\n",
            "Epoch [28180], val_loss: 4067.2605\n",
            "Epoch [28200], val_loss: 4065.0020\n",
            "Epoch [28220], val_loss: 4066.9956\n",
            "Epoch [28240], val_loss: 4063.8689\n",
            "Epoch [28260], val_loss: 4067.9280\n",
            "Epoch [28280], val_loss: 4066.0107\n",
            "Epoch [28300], val_loss: 4061.7222\n",
            "Epoch [28320], val_loss: 4061.9019\n",
            "Epoch [28340], val_loss: 4061.2046\n",
            "Epoch [28360], val_loss: 4064.1470\n",
            "Epoch [28380], val_loss: 4062.7246\n",
            "Epoch [28400], val_loss: 4059.3479\n",
            "Epoch [28420], val_loss: 4060.9927\n",
            "Epoch [28440], val_loss: 4060.4531\n",
            "Epoch [28460], val_loss: 4058.9312\n",
            "Epoch [28480], val_loss: 4060.6482\n",
            "Epoch [28500], val_loss: 4058.0710\n",
            "Epoch [28520], val_loss: 4058.0586\n",
            "Epoch [28540], val_loss: 4057.4111\n",
            "Epoch [28560], val_loss: 4056.0410\n",
            "Epoch [28580], val_loss: 4054.5039\n",
            "Epoch [28600], val_loss: 4052.1982\n",
            "Epoch [28620], val_loss: 4054.2842\n",
            "Epoch [28640], val_loss: 4052.8940\n",
            "Epoch [28660], val_loss: 4049.8560\n",
            "Epoch [28680], val_loss: 4050.8145\n",
            "Epoch [28700], val_loss: 4050.7705\n",
            "Epoch [28720], val_loss: 4049.6953\n",
            "Epoch [28740], val_loss: 4048.2656\n",
            "Epoch [28760], val_loss: 4049.0957\n",
            "Epoch [28780], val_loss: 4049.1714\n",
            "Epoch [28800], val_loss: 4046.5596\n",
            "Epoch [28820], val_loss: 4047.5283\n",
            "Epoch [28840], val_loss: 4045.6978\n",
            "Epoch [28860], val_loss: 4043.1997\n",
            "Epoch [28880], val_loss: 4044.2073\n",
            "Epoch [28900], val_loss: 4042.5928\n",
            "Epoch [28920], val_loss: 4041.2063\n",
            "Epoch [28940], val_loss: 4042.3701\n",
            "Epoch [28960], val_loss: 4042.7290\n",
            "Epoch [28980], val_loss: 4039.4150\n",
            "Epoch [29000], val_loss: 4041.2041\n",
            "Epoch [29020], val_loss: 4040.8286\n",
            "Epoch [29040], val_loss: 4039.4517\n",
            "Epoch [29060], val_loss: 4036.9792\n",
            "Epoch [29080], val_loss: 4036.0630\n",
            "Epoch [29100], val_loss: 4037.7095\n",
            "Epoch [29120], val_loss: 4040.1543\n",
            "Epoch [29140], val_loss: 4036.3560\n",
            "Epoch [29160], val_loss: 4035.6360\n",
            "Epoch [29180], val_loss: 4035.9570\n",
            "Epoch [29200], val_loss: 4033.2241\n",
            "Epoch [29220], val_loss: 4035.8384\n",
            "Epoch [29240], val_loss: 4031.4790\n",
            "Epoch [29260], val_loss: 4032.7983\n",
            "Epoch [29280], val_loss: 4032.1609\n",
            "Epoch [29300], val_loss: 4029.0249\n",
            "Epoch [29320], val_loss: 4030.9512\n",
            "Epoch [29340], val_loss: 4029.3774\n",
            "Epoch [29360], val_loss: 4027.3286\n",
            "Epoch [29380], val_loss: 4028.4102\n",
            "Epoch [29400], val_loss: 4027.9844\n",
            "Epoch [29420], val_loss: 4027.6785\n",
            "Epoch [29440], val_loss: 4024.2087\n",
            "Epoch [29460], val_loss: 4024.1284\n",
            "Epoch [29480], val_loss: 4024.2188\n",
            "Epoch [29500], val_loss: 4024.8101\n",
            "Epoch [29520], val_loss: 4023.9966\n",
            "Epoch [29540], val_loss: 4024.0957\n",
            "Epoch [29560], val_loss: 4020.2793\n",
            "Epoch [29580], val_loss: 4021.4077\n",
            "Epoch [29600], val_loss: 4018.9351\n",
            "Epoch [29620], val_loss: 4018.2944\n",
            "Epoch [29640], val_loss: 4017.7354\n",
            "Epoch [29660], val_loss: 4018.5020\n",
            "Epoch [29680], val_loss: 4019.1064\n",
            "Epoch [29700], val_loss: 4016.5547\n",
            "Epoch [29720], val_loss: 4016.6821\n",
            "Epoch [29740], val_loss: 4017.8511\n",
            "Epoch [29760], val_loss: 4018.3774\n",
            "Epoch [29780], val_loss: 4016.7490\n",
            "Epoch [29800], val_loss: 4015.5605\n",
            "Epoch [29820], val_loss: 4011.8496\n",
            "Epoch [29840], val_loss: 4014.2974\n",
            "Epoch [29860], val_loss: 4012.3896\n",
            "Epoch [29880], val_loss: 4012.1948\n",
            "Epoch [29900], val_loss: 4010.4854\n",
            "Epoch [29920], val_loss: 4013.2808\n",
            "Epoch [29940], val_loss: 4009.9653\n",
            "Epoch [29960], val_loss: 4010.5737\n",
            "Epoch [29980], val_loss: 4009.7388\n",
            "Epoch [30000], val_loss: 4008.2283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-NmVwJ-Dtch",
        "outputId": "691a7de3-1fe1-41ef-d862-fc5c9198ffdc"
      },
      "source": [
        "epochs = 5000\r\n",
        "lr = 1e-2\r\n",
        "history8 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 3438.9858\n",
            "Epoch [40], val_loss: 3435.0146\n",
            "Epoch [60], val_loss: 3430.5620\n",
            "Epoch [80], val_loss: 3427.0151\n",
            "Epoch [100], val_loss: 3424.1660\n",
            "Epoch [120], val_loss: 3422.4365\n",
            "Epoch [140], val_loss: 3420.5654\n",
            "Epoch [160], val_loss: 3419.3848\n",
            "Epoch [180], val_loss: 3418.2139\n",
            "Epoch [200], val_loss: 3417.3652\n",
            "Epoch [220], val_loss: 3416.3181\n",
            "Epoch [240], val_loss: 3416.0620\n",
            "Epoch [260], val_loss: 3415.6311\n",
            "Epoch [280], val_loss: 3415.4976\n",
            "Epoch [300], val_loss: 3415.3643\n",
            "Epoch [320], val_loss: 3414.7803\n",
            "Epoch [340], val_loss: 3414.8164\n",
            "Epoch [360], val_loss: 3414.7280\n",
            "Epoch [380], val_loss: 3414.5483\n",
            "Epoch [400], val_loss: 3414.4150\n",
            "Epoch [420], val_loss: 3414.4229\n",
            "Epoch [440], val_loss: 3414.2478\n",
            "Epoch [460], val_loss: 3413.9963\n",
            "Epoch [480], val_loss: 3414.1157\n",
            "Epoch [500], val_loss: 3414.1614\n",
            "Epoch [520], val_loss: 3413.9644\n",
            "Epoch [540], val_loss: 3413.9714\n",
            "Epoch [560], val_loss: 3414.1357\n",
            "Epoch [580], val_loss: 3413.9819\n",
            "Epoch [600], val_loss: 3413.8232\n",
            "Epoch [620], val_loss: 3413.9133\n",
            "Epoch [640], val_loss: 3413.6426\n",
            "Epoch [660], val_loss: 3413.6660\n",
            "Epoch [680], val_loss: 3413.8359\n",
            "Epoch [700], val_loss: 3413.8267\n",
            "Epoch [720], val_loss: 3414.0447\n",
            "Epoch [740], val_loss: 3413.6338\n",
            "Epoch [760], val_loss: 3413.6499\n",
            "Epoch [780], val_loss: 3413.5688\n",
            "Epoch [800], val_loss: 3413.9258\n",
            "Epoch [820], val_loss: 3413.9565\n",
            "Epoch [840], val_loss: 3413.6360\n",
            "Epoch [860], val_loss: 3413.6160\n",
            "Epoch [880], val_loss: 3413.6292\n",
            "Epoch [900], val_loss: 3413.8198\n",
            "Epoch [920], val_loss: 3413.5874\n",
            "Epoch [940], val_loss: 3413.6941\n",
            "Epoch [960], val_loss: 3413.7361\n",
            "Epoch [980], val_loss: 3413.7180\n",
            "Epoch [1000], val_loss: 3413.6733\n",
            "Epoch [1020], val_loss: 3413.6140\n",
            "Epoch [1040], val_loss: 3413.5208\n",
            "Epoch [1060], val_loss: 3413.4961\n",
            "Epoch [1080], val_loss: 3413.8157\n",
            "Epoch [1100], val_loss: 3413.7637\n",
            "Epoch [1120], val_loss: 3413.6421\n",
            "Epoch [1140], val_loss: 3413.4961\n",
            "Epoch [1160], val_loss: 3413.5234\n",
            "Epoch [1180], val_loss: 3413.8804\n",
            "Epoch [1200], val_loss: 3413.4795\n",
            "Epoch [1220], val_loss: 3413.9023\n",
            "Epoch [1240], val_loss: 3413.6450\n",
            "Epoch [1260], val_loss: 3413.5386\n",
            "Epoch [1280], val_loss: 3413.4360\n",
            "Epoch [1300], val_loss: 3413.5405\n",
            "Epoch [1320], val_loss: 3413.8479\n",
            "Epoch [1340], val_loss: 3413.7334\n",
            "Epoch [1360], val_loss: 3413.7266\n",
            "Epoch [1380], val_loss: 3413.6108\n",
            "Epoch [1400], val_loss: 3413.5010\n",
            "Epoch [1420], val_loss: 3413.5898\n",
            "Epoch [1440], val_loss: 3413.6160\n",
            "Epoch [1460], val_loss: 3413.7983\n",
            "Epoch [1480], val_loss: 3413.6001\n",
            "Epoch [1500], val_loss: 3413.6074\n",
            "Epoch [1520], val_loss: 3414.0088\n",
            "Epoch [1540], val_loss: 3413.7681\n",
            "Epoch [1560], val_loss: 3413.6455\n",
            "Epoch [1580], val_loss: 3413.6421\n",
            "Epoch [1600], val_loss: 3413.3779\n",
            "Epoch [1620], val_loss: 3413.4851\n",
            "Epoch [1640], val_loss: 3413.4053\n",
            "Epoch [1660], val_loss: 3413.9517\n",
            "Epoch [1680], val_loss: 3413.3618\n",
            "Epoch [1700], val_loss: 3413.4993\n",
            "Epoch [1720], val_loss: 3413.7349\n",
            "Epoch [1740], val_loss: 3413.8359\n",
            "Epoch [1760], val_loss: 3413.4829\n",
            "Epoch [1780], val_loss: 3413.5928\n",
            "Epoch [1800], val_loss: 3413.8721\n",
            "Epoch [1820], val_loss: 3413.6482\n",
            "Epoch [1840], val_loss: 3413.6826\n",
            "Epoch [1860], val_loss: 3413.5894\n",
            "Epoch [1880], val_loss: 3413.3726\n",
            "Epoch [1900], val_loss: 3413.3667\n",
            "Epoch [1920], val_loss: 3413.4702\n",
            "Epoch [1940], val_loss: 3413.6196\n",
            "Epoch [1960], val_loss: 3413.6968\n",
            "Epoch [1980], val_loss: 3413.8311\n",
            "Epoch [2000], val_loss: 3413.5229\n",
            "Epoch [2020], val_loss: 3413.4858\n",
            "Epoch [2040], val_loss: 3413.3696\n",
            "Epoch [2060], val_loss: 3413.8142\n",
            "Epoch [2080], val_loss: 3413.3545\n",
            "Epoch [2100], val_loss: 3413.8577\n",
            "Epoch [2120], val_loss: 3413.6802\n",
            "Epoch [2140], val_loss: 3413.7761\n",
            "Epoch [2160], val_loss: 3413.2368\n",
            "Epoch [2180], val_loss: 3413.3147\n",
            "Epoch [2200], val_loss: 3413.4346\n",
            "Epoch [2220], val_loss: 3413.4712\n",
            "Epoch [2240], val_loss: 3413.4873\n",
            "Epoch [2260], val_loss: 3413.6548\n",
            "Epoch [2280], val_loss: 3413.6077\n",
            "Epoch [2300], val_loss: 3413.3906\n",
            "Epoch [2320], val_loss: 3413.6626\n",
            "Epoch [2340], val_loss: 3413.6509\n",
            "Epoch [2360], val_loss: 3413.4722\n",
            "Epoch [2380], val_loss: 3413.3755\n",
            "Epoch [2400], val_loss: 3413.5283\n",
            "Epoch [2420], val_loss: 3413.4673\n",
            "Epoch [2440], val_loss: 3413.4111\n",
            "Epoch [2460], val_loss: 3413.7192\n",
            "Epoch [2480], val_loss: 3413.4819\n",
            "Epoch [2500], val_loss: 3413.3535\n",
            "Epoch [2520], val_loss: 3413.4976\n",
            "Epoch [2540], val_loss: 3413.3457\n",
            "Epoch [2560], val_loss: 3413.2029\n",
            "Epoch [2580], val_loss: 3413.4878\n",
            "Epoch [2600], val_loss: 3413.4453\n",
            "Epoch [2620], val_loss: 3413.2744\n",
            "Epoch [2640], val_loss: 3413.6414\n",
            "Epoch [2660], val_loss: 3413.7322\n",
            "Epoch [2680], val_loss: 3413.6677\n",
            "Epoch [2700], val_loss: 3413.6604\n",
            "Epoch [2720], val_loss: 3413.5396\n",
            "Epoch [2740], val_loss: 3413.5942\n",
            "Epoch [2760], val_loss: 3413.5630\n",
            "Epoch [2780], val_loss: 3413.3101\n",
            "Epoch [2800], val_loss: 3413.6206\n",
            "Epoch [2820], val_loss: 3413.4368\n",
            "Epoch [2840], val_loss: 3413.5818\n",
            "Epoch [2860], val_loss: 3413.4077\n",
            "Epoch [2880], val_loss: 3413.5825\n",
            "Epoch [2900], val_loss: 3413.8796\n",
            "Epoch [2920], val_loss: 3413.0869\n",
            "Epoch [2940], val_loss: 3413.4104\n",
            "Epoch [2960], val_loss: 3413.4780\n",
            "Epoch [2980], val_loss: 3413.5352\n",
            "Epoch [3000], val_loss: 3413.2593\n",
            "Epoch [3020], val_loss: 3413.2688\n",
            "Epoch [3040], val_loss: 3413.7056\n",
            "Epoch [3060], val_loss: 3413.2881\n",
            "Epoch [3080], val_loss: 3413.4907\n",
            "Epoch [3100], val_loss: 3413.5200\n",
            "Epoch [3120], val_loss: 3413.5166\n",
            "Epoch [3140], val_loss: 3413.4062\n",
            "Epoch [3160], val_loss: 3413.4397\n",
            "Epoch [3180], val_loss: 3413.3423\n",
            "Epoch [3200], val_loss: 3413.4680\n",
            "Epoch [3220], val_loss: 3413.1396\n",
            "Epoch [3240], val_loss: 3413.3887\n",
            "Epoch [3260], val_loss: 3413.5161\n",
            "Epoch [3280], val_loss: 3413.4600\n",
            "Epoch [3300], val_loss: 3413.2559\n",
            "Epoch [3320], val_loss: 3413.3206\n",
            "Epoch [3340], val_loss: 3413.2334\n",
            "Epoch [3360], val_loss: 3413.5210\n",
            "Epoch [3380], val_loss: 3413.4995\n",
            "Epoch [3400], val_loss: 3413.4429\n",
            "Epoch [3420], val_loss: 3413.6636\n",
            "Epoch [3440], val_loss: 3413.2915\n",
            "Epoch [3460], val_loss: 3413.3762\n",
            "Epoch [3480], val_loss: 3413.8428\n",
            "Epoch [3500], val_loss: 3413.3940\n",
            "Epoch [3520], val_loss: 3413.4570\n",
            "Epoch [3540], val_loss: 3413.4783\n",
            "Epoch [3560], val_loss: 3413.5715\n",
            "Epoch [3580], val_loss: 3413.5884\n",
            "Epoch [3600], val_loss: 3413.1821\n",
            "Epoch [3620], val_loss: 3413.5879\n",
            "Epoch [3640], val_loss: 3413.1665\n",
            "Epoch [3660], val_loss: 3413.6929\n",
            "Epoch [3680], val_loss: 3413.4153\n",
            "Epoch [3700], val_loss: 3413.2734\n",
            "Epoch [3720], val_loss: 3413.5039\n",
            "Epoch [3740], val_loss: 3413.4128\n",
            "Epoch [3760], val_loss: 3413.4475\n",
            "Epoch [3780], val_loss: 3413.3633\n",
            "Epoch [3800], val_loss: 3413.3662\n",
            "Epoch [3820], val_loss: 3413.7188\n",
            "Epoch [3840], val_loss: 3413.4709\n",
            "Epoch [3860], val_loss: 3413.4661\n",
            "Epoch [3880], val_loss: 3413.2095\n",
            "Epoch [3900], val_loss: 3413.5146\n",
            "Epoch [3920], val_loss: 3413.3418\n",
            "Epoch [3940], val_loss: 3413.4629\n",
            "Epoch [3960], val_loss: 3413.4595\n",
            "Epoch [3980], val_loss: 3413.6423\n",
            "Epoch [4000], val_loss: 3413.2729\n",
            "Epoch [4020], val_loss: 3413.5767\n",
            "Epoch [4040], val_loss: 3413.4360\n",
            "Epoch [4060], val_loss: 3413.4526\n",
            "Epoch [4080], val_loss: 3413.3677\n",
            "Epoch [4100], val_loss: 3413.6658\n",
            "Epoch [4120], val_loss: 3413.1865\n",
            "Epoch [4140], val_loss: 3413.5020\n",
            "Epoch [4160], val_loss: 3413.4856\n",
            "Epoch [4180], val_loss: 3413.5894\n",
            "Epoch [4200], val_loss: 3413.5005\n",
            "Epoch [4220], val_loss: 3413.4180\n",
            "Epoch [4240], val_loss: 3413.3499\n",
            "Epoch [4260], val_loss: 3413.2529\n",
            "Epoch [4280], val_loss: 3413.4150\n",
            "Epoch [4300], val_loss: 3413.3750\n",
            "Epoch [4320], val_loss: 3413.2935\n",
            "Epoch [4340], val_loss: 3413.4580\n",
            "Epoch [4360], val_loss: 3413.0786\n",
            "Epoch [4380], val_loss: 3413.6145\n",
            "Epoch [4400], val_loss: 3413.5391\n",
            "Epoch [4420], val_loss: 3413.5112\n",
            "Epoch [4440], val_loss: 3413.6262\n",
            "Epoch [4460], val_loss: 3413.3826\n",
            "Epoch [4480], val_loss: 3413.3496\n",
            "Epoch [4500], val_loss: 3413.3633\n",
            "Epoch [4520], val_loss: 3413.4849\n",
            "Epoch [4540], val_loss: 3413.1860\n",
            "Epoch [4560], val_loss: 3413.5010\n",
            "Epoch [4580], val_loss: 3413.7383\n",
            "Epoch [4600], val_loss: 3413.2439\n",
            "Epoch [4620], val_loss: 3413.4294\n",
            "Epoch [4640], val_loss: 3413.6934\n",
            "Epoch [4660], val_loss: 3413.1670\n",
            "Epoch [4680], val_loss: 3413.3196\n",
            "Epoch [4700], val_loss: 3413.5459\n",
            "Epoch [4720], val_loss: 3413.3621\n",
            "Epoch [4740], val_loss: 3413.2524\n",
            "Epoch [4760], val_loss: 3413.5005\n",
            "Epoch [4780], val_loss: 3413.2307\n",
            "Epoch [4800], val_loss: 3413.3252\n",
            "Epoch [4820], val_loss: 3413.3125\n",
            "Epoch [4840], val_loss: 3413.5757\n",
            "Epoch [4860], val_loss: 3413.2900\n",
            "Epoch [4880], val_loss: 3413.1895\n",
            "Epoch [4900], val_loss: 3413.5667\n",
            "Epoch [4920], val_loss: 3413.2886\n",
            "Epoch [4940], val_loss: 3413.4785\n",
            "Epoch [4960], val_loss: 3413.4199\n",
            "Epoch [4980], val_loss: 3413.3054\n",
            "Epoch [5000], val_loss: 3413.5112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYS3bsrb1iRn"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raVLxEpT1iRn"
      },
      "source": [
        "val_loss = evaluate(model, val_loader)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdto3q-gQmH5",
        "outputId": "89f9d4f5-67ed-4fda-a4e6-bde8058d5507"
      },
      "source": [
        "print(val_loss)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 3413.51123046875}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtLOgfs1iRo"
      },
      "source": [
        "Let's log the final validation loss to Jovian and commit the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM4YKo821iRo",
        "outputId": "a38428fb-966d-4c8e-d8f1-2877acd75b54"
      },
      "source": [
        "jovian.log_metrics(val_loss=val_loss)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Metrics logged.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "MbQW1hgq1iRo",
        "outputId": "f263f823-0c17-451f-e435-e6cb0b15c9fd"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/rahulgarg95/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/rahulgarg95/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xCJ5_Jw1iRp"
      },
      "source": [
        "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om4pKmkw1iRp"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCj-jGcx1iRp"
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrPbW6F11iRq",
        "outputId": "b8c40231-9b70-4239-c052-cc30f50e4cad"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([36.0000,  0.0000, 29.0224,  0.0000,  0.0000])\n",
            "Target: tensor([5084.5981])\n",
            "Prediction: tensor([6188.5190])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M0ziv1A1iRq",
        "outputId": "46de2e90-e5dd-4f6d-d0f3-12a2561d8579"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([50.0000,  0.0000, 26.9951,  3.0000,  0.0000])\n",
            "Target: tensor([20539.3594])\n",
            "Prediction: tensor([11202.9199])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIzHWQh1iRr",
        "outputId": "cc2ab56e-9223-43a3-843e-485c919c5e29"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([58.0000,  1.0000, 27.7372,  0.0000,  0.0000])\n",
            "Target: tensor([12205.3145])\n",
            "Prediction: tensor([11864.7969])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cqcI-oR1iRr"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ankP2v1iRr"
      },
      "source": [
        "## (Optional) Step 6: Try another dataset & blog about it\n",
        "\n",
        "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to replicate this notebook for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patterns in machine learning from problem-specific details.You can use one of these starer notebooks (just change the dataset):\n",
        "\n",
        "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
        "\n",
        "Here are some sources to find good datasets:\n",
        "\n",
        "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
        "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
        "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
        "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
        "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
        "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
        "\n",
        "- Interesting title & subtitle\n",
        "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
        "- Downloading & exploring the data\n",
        "- Preparing the data for training\n",
        "- Creating a model using PyTorch\n",
        "- Training the model to fit the data\n",
        "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
        "- Making predictions using the model\n",
        "\n",
        "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
        "\n",
        "Don't forget to share your work on the forum: https://jovian.ai/forum/t/linear-regression-and-logistic-regression-notebooks-and-blog-posts/14039"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxWN7NZi1iRs"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)\n",
        "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJffrZu1iRs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}